{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surgical-vietnam",
   "metadata": {
    "id": "dtcVxQrUVxtS",
    "papermill": {
     "duration": 0.02529,
     "end_time": "2021-05-17T07:58:30.451765",
     "exception": false,
     "start_time": "2021-05-17T07:58:30.426475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TO DO\n",
    "1. Bearm search with log and normalization - copy\n",
    "2. Change structure of test dataset to original\n",
    "3. Test data - max_lngth issue\n",
    "4. Test data - batch greedy and other stuff\n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-sullivan",
   "metadata": {
    "id": "OJUDIplVr2Wi",
    "papermill": {
     "duration": 0.023275,
     "end_time": "2021-05-17T07:58:30.498543",
     "exception": false,
     "start_time": "2021-05-17T07:58:30.475268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TO DO ATTENTION\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boxed-david",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:58:30.565905Z",
     "iopub.status.busy": "2021-05-17T07:58:30.555309Z",
     "iopub.status.idle": "2021-05-17T07:58:43.754049Z",
     "shell.execute_reply": "2021-05-17T07:58:43.752754Z"
    },
    "id": "3tq-TJbQYv9W",
    "outputId": "518c61d7-d16c-482f-9855-0fbb9596bacd",
    "papermill": {
     "duration": 13.232379,
     "end_time": "2021-05-17T07:58:43.754273",
     "exception": false,
     "start_time": "2021-05-17T07:58:30.521894",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting editdistance\r\n",
      "  Downloading editdistance-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 179 kB 1.2 MB/s \r\n",
      "\u001b[?25hInstalling collected packages: editdistance\r\n",
      "Successfully installed editdistance-0.5.3\r\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.10.26)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.3.1)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.0)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.1)\r\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.1.2)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.14)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\r\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\r\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.15.8)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\r\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\r\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install editdistance\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removed-sucking",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:58:43.857723Z",
     "iopub.status.busy": "2021-05-17T07:58:43.854304Z",
     "iopub.status.idle": "2021-05-17T07:58:49.338897Z",
     "shell.execute_reply": "2021-05-17T07:58:49.336450Z"
    },
    "id": "bClAC3xAEhKS",
    "papermill": {
     "duration": 5.537908,
     "end_time": "2021-05-17T07:58:49.339068",
     "exception": false,
     "start_time": "2021-05-17T07:58:43.801160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "import keras\n",
    "import numpy as np\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import pickle\n",
    "from keras import layers\n",
    "from keras.layers import LSTM, Dense, Embedding, Input, TimeDistributed, Dropout\n",
    "from keras.models import Model, save_model, load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tqdm.auto import tqdm\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from math import ceil\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cognitive-browse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:58:49.398272Z",
     "iopub.status.busy": "2021-05-17T07:58:49.397457Z",
     "iopub.status.idle": "2021-05-17T07:58:49.400445Z",
     "shell.execute_reply": "2021-05-17T07:58:49.399842Z"
    },
    "id": "f4KWzWj6vjPV",
    "papermill": {
     "duration": 0.033796,
     "end_time": "2021-05-17T07:58:49.400583",
     "exception": false,
     "start_time": "2021-05-17T07:58:49.366787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dir = '/content'\n",
    "dir = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "peaceful-bridge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:58:49.465782Z",
     "iopub.status.busy": "2021-05-17T07:58:49.464820Z",
     "iopub.status.idle": "2021-05-17T07:59:08.380796Z",
     "shell.execute_reply": "2021-05-17T07:59:08.379736Z"
    },
    "id": "Fs9sbR5xCVo3",
    "outputId": "8219f353-f48b-42a3-a35d-ca20b3197cdf",
    "papermill": {
     "duration": 18.953473,
     "end_time": "2021-05-17T07:59:08.380973",
     "exception": false,
     "start_time": "2021-05-17T07:58:49.427500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-17 07:58:50--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.185.128, 108.177.122.128, 64.233.177.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.185.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2008340480 (1.9G) [application/x-tar]\r\n",
      "Saving to: ‘dakshina_dataset_v1.0.tar’\r\n",
      "\r\n",
      "dakshina_dataset_v1 100%[===================>]   1.87G   190MB/s    in 10s     \r\n",
      "\r\n",
      "2021-05-17 07:59:00 (188 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
    "\n",
    "if not os.path.isdir(dir + '/dakshina_dataset_v1.0'):\n",
    "  tarfile.open(dir + '/dakshina_dataset_v1.0.tar').extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "engaging-hunger",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:08.895229Z",
     "iopub.status.busy": "2021-05-17T07:59:08.894398Z",
     "iopub.status.idle": "2021-05-17T07:59:09.629090Z",
     "shell.execute_reply": "2021-05-17T07:59:09.628621Z"
    },
    "id": "K0fMpPf_BUUK",
    "outputId": "90f4b9e8-0d90-43d9-89f6-c9c7f4ee5fc6",
    "papermill": {
     "duration": 0.840661,
     "end_time": "2021-05-17T07:59:09.629243",
     "exception": false,
     "start_time": "2021-05-17T07:59:08.788582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='14394907543f59ea21931529e34b4d80d2ca8c9c', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-prospect",
   "metadata": {
    "id": "-BstzblcHmd5",
    "papermill": {
     "duration": 2.257279,
     "end_time": "2021-05-17T07:59:13.316150",
     "exception": false,
     "start_time": "2021-05-17T07:59:11.058871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjustable-radio",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:13.515679Z",
     "iopub.status.busy": "2021-05-17T07:59:13.514711Z",
     "iopub.status.idle": "2021-05-17T07:59:13.546524Z",
     "shell.execute_reply": "2021-05-17T07:59:13.547683Z"
    },
    "id": "fNDJrkl5EUHX",
    "papermill": {
     "duration": 0.130224,
     "end_time": "2021-05-17T07:59:13.547911",
     "exception": false,
     "start_time": "2021-05-17T07:59:13.417687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class data_loader():\n",
    "\n",
    "  @staticmethod\n",
    "  def _load_raw_df(languages = ['ta']):\n",
    "    lex = dict()\n",
    "    lex['train'], lex['val'], lex['test'] = [], [], [] \n",
    "    column_names = ['output', 'input', 'count']\n",
    "    \n",
    "    for la in languages:\n",
    "      lex['train'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.train.tsv', sep='\\t', header=None, names=column_names))\n",
    "      lex['val'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.dev.tsv', sep='\\t', header=None, names=column_names))\n",
    "      lex['test'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.test.tsv', sep='\\t', header=None, names=column_names))\n",
    "\n",
    "    lex['train'] = pd.concat(lex['train'])\n",
    "    lex['val'] = pd.concat(lex['val'])\n",
    "    lex['test'] = pd.concat(lex['test'])\n",
    "\n",
    "    return lex    \n",
    "\n",
    "  @staticmethod\n",
    "  def _make_final_df(lex):\n",
    "    \n",
    "    for div in ['train', 'val', 'test']:\n",
    "    \n",
    "      # removing non max transliterations\n",
    "      idx = lex[div].groupby(['input'])['count'].transform(max) == lex[div]['count']\n",
    "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
    "\n",
    "      # calclulating difference in lengths of various transliterations\n",
    "      lex[div]['input_len'] = lex[div].apply(lambda x: len(str(x['input'])), axis=1)\n",
    "      lex[div]['output_len'] = lex[div].apply(lambda y: len(str(y['output'])), axis=1)\n",
    "      lex[div]['mod_dif'] = lex[div].apply(lambda z: abs(z['input_len'] - z['output_len']), axis=1) \n",
    "\n",
    "      # removing transliterations that vary by a lot in length\n",
    "      idx = lex[div].groupby(['input'])['mod_dif'].transform(min) == lex[div]['mod_dif']\n",
    "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
    "\n",
    "      # removing duplicates if any remain\n",
    "      lex[div].drop_duplicates(subset='input', keep='first', inplace=True)\n",
    "\n",
    "      # removing redundant columns\n",
    "      lex[div].drop(labels=['count', 'input_len', 'output_len', 'mod_dif'], inplace=True, axis=1)\n",
    "\n",
    "      # shuffling the dataset i.e. rows of the dataset\n",
    "      lex[div] = lex[div].sample(frac=1)\n",
    "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
    "\n",
    "    return lex\n",
    "\n",
    "  @staticmethod\n",
    "  def _generate_batch(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
    "\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            \n",
    "            # placeholder data structures\n",
    "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, data_dict['max_target_length']),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
    "\n",
    "            # assessing one batch at a time\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "\n",
    "                for t, word in enumerate(input_text):\n",
    "                  encoder_input_data[i, t] = word\n",
    "                for t, word in enumerate(target_text):\n",
    "                    if t<len(target_text)-1:\n",
    "                        # decoder input sequence\n",
    "                        # does not include the <EOW> token\n",
    "                        decoder_input_data[i, t] = word \n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the <SOW> token\n",
    "                        decoder_target_data[i, t - 1, word] = 1.\n",
    "                    \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "\n",
    "  @staticmethod\n",
    "  def _generate_batch_greedy(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
    "\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "\n",
    "            # placeholder data structures\n",
    "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, 1),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
    "            \n",
    "            # assessing one batch at a time\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text):\n",
    "                  encoder_input_data[i, t] = word\n",
    "                for t, word in enumerate(target_text):\n",
    "                    if t==0 :\n",
    "                        decoder_input_data[i, t] = 1 # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        decoder_target_data[i, t - 1, word] = 1.\n",
    "                    \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "supposed-nation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:13.770624Z",
     "iopub.status.busy": "2021-05-17T07:59:13.769678Z",
     "iopub.status.idle": "2021-05-17T07:59:13.784726Z",
     "shell.execute_reply": "2021-05-17T07:59:13.785846Z"
    },
    "id": "rOo1m6s3vDaN",
    "papermill": {
     "duration": 0.127225,
     "end_time": "2021-05-17T07:59:13.786080",
     "exception": false,
     "start_time": "2021-05-17T07:59:13.658855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "\n",
    "  def __init__(self, df):\n",
    "\n",
    "    self.start_token = '<SOW>'\n",
    "    self.stop_token = '<EOW>'\n",
    "    self.unknown_token = '<UNK>'\n",
    "\n",
    "    self.input_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
    "    self.output_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
    "\n",
    "    input_words = df.input.tolist()\n",
    "    output_words = df.output.tolist()\n",
    "\n",
    "    for word in input_words:\n",
    "      tokens = str(word)\n",
    "      for token in tokens:\n",
    "        if token not in self.input_corpus:\n",
    "          self.input_corpus.append(token)\n",
    "\n",
    "    for word in output_words:\n",
    "      tokens = str(word)\n",
    "      for token in tokens:\n",
    "        if token not in self.output_corpus:\n",
    "          self.output_corpus.append(token)\n",
    "    \n",
    "    self.encode_dict_input = {self.input_corpus[i] : i+1 for i in range(len(self.input_corpus))}\n",
    "    self.decode_dict_input = {k:v for v,k in self.encode_dict_input.items()}\n",
    "    \n",
    "    \n",
    "    self.encode_dict_output = {self.output_corpus[i] : i+1 for i in range(len(self.output_corpus))}\n",
    "    self.decode_dict_output = {k:v for v,k in self.encode_dict_output.items()}\n",
    "    self.decode_dict_output.update({2:''})\n",
    "\n",
    "  # takes in lists of words and returns lists of integers\n",
    "  def encode(self, X, mode='input'):\n",
    "\n",
    "    if (mode=='input'):\n",
    "      input_list = []\n",
    "      for word in X:\n",
    "        word = str(word)\n",
    "        integer_list =np.array([self.encode_dict_input.get(token, self.encode_dict_input[self.unknown_token]) for token in word])\n",
    "        input_list.append(integer_list)\n",
    "      \n",
    "      return input_list\n",
    "    \n",
    "    if (mode=='output'):\n",
    "      output_list = []\n",
    "      for word in X:\n",
    "        word = str(word)\n",
    "        integer_list = np.array([self.encode_dict_output[self.start_token]] + [self.encode_dict_output.get(token, self.encode_dict_output[self.unknown_token]) for token in word] + [self.encode_dict_output[self.stop_token]])\n",
    "        output_list.append(integer_list)\n",
    "      \n",
    "      return output_list\n",
    "    \n",
    "  # takes in lists of integers and returns lists of words\n",
    "  def decode(self, X, mode='input'):\n",
    "\n",
    "    if (mode=='input'):\n",
    "      input_list = []\n",
    "      for integers in X:\n",
    "        token_list=[]\n",
    "        for integer in integers :\n",
    "          if integer == 2 :\n",
    "            break\n",
    "          token_list.append(self.decode_dict_input.get(integer, '')) \n",
    "        input_list.append(''.join(token_list))\n",
    "      \n",
    "      return input_list\n",
    "\n",
    "    if (mode=='output'):\n",
    "      output_list = []\n",
    "      for integers in X:\n",
    "        token_list=[]\n",
    "        for integer in integers :\n",
    "          if integer == 2 :\n",
    "            break\n",
    "          token_list.append(self.decode_dict_output.get(integer, '')) \n",
    "        output_list.append(''.join(token_list))\n",
    "      \n",
    "      return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aerial-direction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:26.209819Z",
     "iopub.status.busy": "2021-05-17T07:59:26.208208Z",
     "iopub.status.idle": "2021-05-17T07:59:26.210492Z",
     "shell.execute_reply": "2021-05-17T07:59:26.210885Z"
    },
    "id": "s1mzVsRdBa4x",
    "papermill": {
     "duration": 1.490287,
     "end_time": "2021-05-17T07:59:26.211017",
     "exception": false,
     "start_time": "2021-05-17T07:59:24.720730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_data_dict(languages=['ta'], batch_size=32):\n",
    "\n",
    "  lex = data_loader._load_raw_df(languages)\n",
    "  lex = data_loader._make_final_df(lex)\n",
    "\n",
    "  data_dict = dict()\n",
    "\n",
    "  df_train = lex['train']\n",
    "  df_val = lex['val']\n",
    "  df_test = lex['test']\n",
    "\n",
    "  tk = Tokenizer(df_train)\n",
    "\n",
    "  data_dict['in_size'] = len(tk.input_corpus) + 1\n",
    "  data_dict['out_size'] = len(tk.output_corpus) + 1\n",
    "\n",
    "  X_train = tk.encode(df_train.input.tolist(), mode='input')\n",
    "  Y_train = tk.encode(df_train.output.tolist(), mode='output')\n",
    "  \n",
    "  X_val = tk.encode(df_val.input.tolist(), mode='input')\n",
    "  Y_val = tk.encode(df_val.output.tolist(), mode='output')\n",
    "\n",
    "  X_test = tk.encode(df_val.input.tolist(), mode='input')\n",
    "  Y_test = tk.encode(df_val.output.tolist(), mode='output')\n",
    "\n",
    "\n",
    "  data_dict['train'], data_dict['val'], data_dict['test']= dict(), dict(), dict()\n",
    "\n",
    "\n",
    "  data_dict['train']['df'] = df_train\n",
    "  data_dict['val']['df'] = df_val\n",
    "  data_dict['test']['df'] = df_test\n",
    "\n",
    "\n",
    "  data_dict['train']['max_source_length'] = np.max(np.array([len(x) for x in X_train]))\n",
    "  data_dict['train']['max_target_length'] = np.max(np.array([len(x) for x in Y_train]))\n",
    "  \n",
    "  data_dict['val']['max_source_length'] = np.max(np.array([len(x) for x in X_val]))\n",
    "  data_dict['val']['max_target_length'] = np.max(np.array([len(x) for x in Y_val]))\n",
    "\n",
    "  data_dict['test']['max_source_length'] = np.max(np.array([len(x) for x in X_test]))\n",
    "  data_dict['test']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
    "\n",
    "  data_dict['max_source_length'] = max(data_dict['train']['max_source_length'], data_dict['val']['max_source_length'])\n",
    "  data_dict['max_target_length'] = max(data_dict['train']['max_target_length'], data_dict['val']['max_target_length'])\n",
    "\n",
    "  data_dict['train']['batch'] = data_loader._generate_batch(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['train']['batch_greedy'] = data_loader._generate_batch_greedy(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['train']['batch_greedy_big'] = data_loader._generate_batch_greedy(X_train, Y_train, data_dict, data_dict['out_size'], 1024)\n",
    "  \n",
    "  data_dict['val']['batch'] = data_loader._generate_batch(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['val']['batch_greedy'] = data_loader._generate_batch_greedy(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['val']['batch_greedy_big'] = data_loader._generate_batch_greedy(X_val, Y_val, data_dict, data_dict['out_size'], 1024)\n",
    "\n",
    "  data_dict['test']['batch'] = data_loader._generate_batch(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['test']['batch_greedy'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['test']['batch_greedy_big'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], len(X_test))\n",
    "\n",
    "  data_dict['tokenizer'] = tk\n",
    "\n",
    "  return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "determined-rouge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:29.487914Z",
     "iopub.status.busy": "2021-05-17T07:59:29.482835Z",
     "iopub.status.idle": "2021-05-17T07:59:34.481820Z",
     "shell.execute_reply": "2021-05-17T07:59:34.482247Z"
    },
    "id": "MwJozmDWedfG",
    "outputId": "4f5a2451-efe2-4e3a-e8ea-4957413054f7",
    "papermill": {
     "duration": 6.65519,
     "end_time": "2021-05-17T07:59:34.482415",
     "exception": false,
     "start_time": "2021-05-17T07:59:27.827225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "dict_data_dict = dict()\n",
    "\n",
    "for batch_size in [32]:\n",
    "  dict_data_dict.update({batch_size: return_data_dict(batch_size=batch_size)})\n",
    "\n",
    "data_dict = list(dict_data_dict.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-things",
   "metadata": {
    "id": "ZV_63arXtzSt",
    "papermill": {
     "duration": 0.041762,
     "end_time": "2021-05-17T07:59:34.566554",
     "exception": false,
     "start_time": "2021-05-17T07:59:34.524792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intermediate-vinyl",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:34.672609Z",
     "iopub.status.busy": "2021-05-17T07:59:34.671296Z",
     "iopub.status.idle": "2021-05-17T07:59:34.673503Z",
     "shell.execute_reply": "2021-05-17T07:59:34.673988Z"
    },
    "id": "UpJm8eZrt5mA",
    "papermill": {
     "duration": 0.065401,
     "end_time": "2021-05-17T07:59:34.674168",
     "exception": false,
     "start_time": "2021-05-17T07:59:34.608767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class rnn():\n",
    "\n",
    "  def __init__(self, params):\n",
    "    \n",
    "    num_encode_layers = params['num_encode_layers']\n",
    "    num_decode_layers = params['num_decode_layers']\n",
    "    data_dict = params['data_dict']\n",
    "    in_size = params['data_dict']['in_size']\n",
    "    out_size = params['data_dict']['out_size']\n",
    "    cell_type = params['cell_type']\n",
    "    dropout = params['dropout']\n",
    "    embed_size = params['embed_size']\n",
    "    rep_size = params['rep_size']\n",
    "        \n",
    "    ###################### ENCODER NETWORK ######################\n",
    "    \n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    x = Embedding(in_size, embed_size ,mask_zero=True)(encoder_inputs)\n",
    "\n",
    "    encoder_layers = []\n",
    "    \n",
    "    for j in range(num_encode_layers-1) :   \n",
    "      curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_sequences=True)\n",
    "      encoder_layers.append(curr_layer)\n",
    "      x = curr_layer(x)\n",
    "\n",
    "    curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_state=True)\n",
    "    encoder_layers.append(curr_layer)\n",
    "    x, *encoder_states = curr_layer(x)\n",
    "\n",
    "    ###################### DECODER NETWORK ######################\n",
    "\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "    decoder_embedding =  Embedding(out_size, embed_size, mask_zero=True)\n",
    "    x = decoder_embedding(decoder_inputs)\n",
    "\n",
    "    decoder_layers = []    \n",
    "    \n",
    "    for j in range(num_decode_layers) :\n",
    "      curr_layer = getattr(layers, cell_type)(rep_size,dropout=dropout,return_state=True, return_sequences=True)\n",
    "      decoder_layers.append(curr_layer)\n",
    "      x, *decoder_states = curr_layer(x, initial_state=encoder_states)\n",
    "\n",
    "    x = Dropout(dropout)(x)\n",
    "    decoder_dense = TimeDistributed(Dense(units=out_size, activation='softmax'))\n",
    "    decoder_outputs = decoder_dense(x)\n",
    "\n",
    "    # define the model that will turn `encoder_inputs` & `decoder_inputs` into `decoder_outputs`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ????? \n",
    "    self.model = model\n",
    "    self.encoder_inputs = encoder_inputs\n",
    "    # self.encoder_layers = encoder_layers\n",
    "    self.decoder_inputs = decoder_inputs\n",
    "    self.decoder_embedding = decoder_embedding\n",
    "    self.decoder_layers = decoder_layers\n",
    "    self.decoder_dense = decoder_dense\n",
    "    self.encoder_states = encoder_states\n",
    "    self.params = params\n",
    "    self.details = {\n",
    "        'model' : self.model,\n",
    "        'encoder_inputs' : self.encoder_inputs,\n",
    "        # 'encoder_layers' :self.encoder_layers ,\n",
    "        'decoder_inputs' :self.decoder_inputs ,\n",
    "        'decoder_embedding' : self.decoder_embedding,\n",
    "        'decoder_layers' : self.decoder_layers,\n",
    "        'decoder_dense' : self.decoder_dense,\n",
    "        'encoder_states' : self.encoder_states ,\n",
    "        'params' :self.params,\n",
    "    }\n",
    "\n",
    "  def compile_and_fit(self, data_dict, params):\n",
    "\n",
    "    # compiling the model\n",
    "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    # printing the summary of the model\n",
    "    summary = self.model.summary()\n",
    "\n",
    "    # plotting the model figure\n",
    "    plot = plot_model(self.model, show_shapes=True)\n",
    "    \n",
    "    # total training samples\n",
    "    train_samples = len(data_dict['train']['df'])\n",
    "\n",
    "    # total validation samples\n",
    "    val_samples = len(data_dict['val']['df'])    \n",
    "    \n",
    "    # batch size\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    # number of epochs\n",
    "    num_epochs = params['num_epochs']\n",
    "\n",
    "    # training the model\n",
    "    run_details = self.model.fit_generator(generator = data_dict['train']['batch'],\n",
    "                                           steps_per_epoch = train_samples//batch_size,\n",
    "                                           epochs=num_epochs,\n",
    "                                           callbacks=[\n",
    "                                                      wandb.keras.WandbCallback()\n",
    "                                                      ],\n",
    "                                           validation_data = data_dict['val']['batch'], \n",
    "                                           validation_steps = val_samples//batch_size\n",
    "                                          )\n",
    "\n",
    "    return {\n",
    "        'run_details' : run_details\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "divine-richmond",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:34.795265Z",
     "iopub.status.busy": "2021-05-17T07:59:34.794157Z",
     "iopub.status.idle": "2021-05-17T07:59:34.796989Z",
     "shell.execute_reply": "2021-05-17T07:59:34.796581Z"
    },
    "id": "h0m1582SU6W8",
    "papermill": {
     "duration": 0.075767,
     "end_time": "2021-05-17T07:59:34.797108",
     "exception": false,
     "start_time": "2021-05-17T07:59:34.721341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class rnn_second() :\n",
    "  def __init__(self, details=None) :\n",
    "\n",
    "    if details is not None:\n",
    "      # copying required details\n",
    "      self.details = details\n",
    "\n",
    "      # copying decoder state input\n",
    "      decoder_state_input = self.details['encoder_states']\n",
    "\n",
    "      decoder_inputs = Input(shape=(1,))\n",
    "\n",
    "      # copying hidden representation size\n",
    "      rep_size = self.details['params']['rep_size']\n",
    "\n",
    "      # copying decoder inputs\n",
    "      # decoder_inputs = self.details['decoder_inputs']\n",
    "\n",
    "      # the decoder model\n",
    "      x = self.details['decoder_embedding'](decoder_inputs)\n",
    "    \n",
    "      all_outputs = []\n",
    "      for _ in range(self.details['params']['data_dict']['max_target_length']) :\n",
    "          for layer in self.details['decoder_layers'] :\n",
    "              x, *decoder_states = layer(x, initial_state=decoder_state_input)\n",
    "\n",
    "          x = self.details['decoder_dense'](x)\n",
    "\n",
    "          # appending the softmax output\n",
    "          all_outputs.append(x)\n",
    "\n",
    "          # taking the argmax to feed into the next time step\n",
    "          # print(\"Hello \",tf.math.argmax(x, 2))\n",
    "          # if int(tf.math.argmax(x, 2))==2:\n",
    "          #     x = 0\n",
    "          # else:\n",
    "          #     x = tf.math.argmax(x, 2)\n",
    "          x = tf.math.argmax(x, 2) \n",
    "          x = self.details['decoder_embedding'](x)\n",
    "          \n",
    "          # decoder state input for the next time step\n",
    "          decoder_state_input = decoder_states\n",
    "\n",
    "      ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ?????\n",
    "      # where do we evaluate stop condition?\n",
    "\n",
    "      decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "      model = Model([self.details['encoder_inputs'], decoder_inputs], decoder_outputs)\n",
    "      self.model = model\n",
    "    \n",
    "    else:\n",
    "      self.details = None \n",
    "      self.model = None\n",
    "\n",
    "  def compile_and_fit(self, data_dict, params) :\n",
    "\n",
    "    # compiling the model\n",
    "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "     # printing the summary of the model   \n",
    "    summary = self.model.summary()\n",
    "\n",
    "    # plotting the model figure\n",
    "    plot = plot_model(self.model, show_shapes=True)\n",
    "    \n",
    "    # total training samples\n",
    "    train_samples = len(data_dict['train']['df'])\n",
    "\n",
    "    # total validation samples \n",
    "    val_samples = len(data_dict['val']['df'])\n",
    "\n",
    "    # batch size   \n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    # number of epochs\n",
    "    num_epochs = params['num_epochs_2']\n",
    "\n",
    "    # training the model\n",
    "    run_details = self.model.fit_generator(generator = data_dict['train']['batch_greedy'],\n",
    "                                            steps_per_epoch = train_samples//batch_size,\n",
    "                                            epochs=num_epochs,\n",
    "                                            callbacks=[\n",
    "                                                      wandb.keras.WandbCallback()\n",
    "                                                      ],\n",
    "                                            validation_data = data_dict['val']['batch_greedy'],\n",
    "                                            validation_steps = val_samples//batch_size)\n",
    "   \n",
    "    return {\n",
    "        'run_details' : run_details\n",
    "    }\n",
    "\n",
    "  def evaluate(self, data_dict, train=False) :\n",
    "\n",
    "    if train :\n",
    "      test_gen = data_dict['train']['batch_greedy_big']\n",
    "    \n",
    "      # number of test samples\n",
    "      test_samples = len(data_dict['train']['df'])\n",
    "      # test_samples=100\n",
    "    \n",
    "      batch_size=1024\n",
    "\n",
    "      num_hits = 0\n",
    "      num_edits = 0\n",
    "\n",
    "      ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ?????\n",
    "      for i in tqdm(range(test_samples//batch_size)) :\n",
    "\n",
    "        (a,b),c = next(test_gen)\n",
    "        c = np.argmax(c, axis=2)\n",
    "        # print(c)\n",
    "        l1 = data_dict['tokenizer'].decode(c, mode='output')\n",
    "        out = self.model.predict([a,b])\n",
    "        out = np.argmax(out,axis=2) \n",
    "        l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
    "        num_hits += np.sum(np.array(l1)==np.array(l2))\n",
    "        num_edits += get_score(l1,l2)\n",
    "\n",
    "      print(\"Final Train Acc \", num_hits/test_samples)\n",
    "      print(\"Editdistance Train Avg \",num_edits/test_samples)\n",
    "      wandb.log({\"final_train_acc\":  num_hits/test_samples, \n",
    "               \"editdistance_train_acc\":  num_edits/test_samples})\n",
    "\n",
    "    # test batch generator\n",
    "    test_gen = data_dict['val']['batch_greedy_big']\n",
    "     \n",
    "    # number of test samples\n",
    "    test_samples = len(data_dict['val']['df'])\n",
    "    # test_samples=100\n",
    "    batch_size=1024\n",
    "    \n",
    "    num_hits = 0\n",
    "    num_edits = 0\n",
    "    for _ in tqdm(range(test_samples//batch_size)) :\n",
    "      (a,b),c = next(test_gen)\n",
    "      c = np.argmax(c, axis=2)\n",
    "      # print(c)\n",
    "      l1 = data_dict['tokenizer'].decode(c, mode='output')\n",
    "      out = self.model.predict([a,b])\n",
    "      out = np.argmax(out,axis=2) \n",
    "      l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
    "      num_hits += np.sum(np.array(l1)==np.array(l2))\n",
    "      num_edits += get_score(l1,l2)\n",
    "      # print(l1, l2)\n",
    "      # print(out)\n",
    "\n",
    "    print(\"Final Val Acc \", num_hits/test_samples)\n",
    "    print(\"Editdistance Val Avg \",num_edits/test_samples)\n",
    "    wandb.log({\"final_val_acc\":  num_hits/test_samples, \n",
    "               \"editdistance_val_acc\":  num_edits/test_samples})\n",
    "    \n",
    "  def evaluate_test(self, data_dict,filename):\n",
    "    test_gen = data_dict['test']['batch_greedy_big']\n",
    "     \n",
    "    # number of test samples\n",
    "    test_samples = len(data_dict['test']['df'])\n",
    "    # test_samples=100\n",
    "    batch_size=test_samples\n",
    "    \n",
    "    num_hits = 0\n",
    "    num_edits = 0\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for _ in tqdm(range(test_samples//batch_size)) :\n",
    "      (a,b),c = next(test_gen)\n",
    "      c = np.argmax(c, axis=2)\n",
    "      # print(c)\n",
    "      l1 = data_dict['tokenizer'].decode(c, mode='output')\n",
    "      out = self.model.predict([a,b])\n",
    "      out = np.argmax(out,axis=2) \n",
    "      l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
    "      inputs.append(l1)\n",
    "      outputs.append(l2)\n",
    "      num_hits += np.sum(np.array(l1)==np.array(l2))\n",
    "      num_edits += get_score(l1,l2)\n",
    "      # print(l1, l2)\n",
    "      # print(out)\n",
    "    with open(filename, 'wb') as f:\n",
    "       pickle.dump([inputs,outputs], f)\n",
    "    print(\"Final Test Acc \", num_hits/test_samples)\n",
    "    print(\"Editdistance Test Avg \",num_edits/test_samples)\n",
    "    wandb.log({\"final_test_acc\":  num_hits/test_samples, \n",
    "               \"editdistance_test_acc\":  num_edits/test_samples})\n",
    "  \n",
    "  # def save_model(self, folder='model'):\n",
    "  #   save_model(self.model, dir+'/'+folder)\n",
    "\n",
    "  # def load_model(self, folder='model'):\n",
    "  #   self.model = load_model(dir+'/'+folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "personalized-festival",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:34.890447Z",
     "iopub.status.busy": "2021-05-17T07:59:34.889579Z",
     "iopub.status.idle": "2021-05-17T07:59:34.892115Z",
     "shell.execute_reply": "2021-05-17T07:59:34.891707Z"
    },
    "id": "HK6hQXYRTrD1",
    "papermill": {
     "duration": 0.051102,
     "end_time": "2021-05-17T07:59:34.892246",
     "exception": false,
     "start_time": "2021-05-17T07:59:34.841144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(A,B) :\n",
    "  fin = 0\n",
    "  for a,b in zip(A,B) :\n",
    "    if len(a)>0 or len(b)>0:   \n",
    "      # print(a,b)\n",
    "      j = editdistance.eval(a,b)\n",
    "      # print(j)\n",
    "      fin += 1 - j/max(len(a),len(b))\n",
    "  return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "divine-there",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:35.120811Z",
     "iopub.status.busy": "2021-05-17T07:59:35.119753Z",
     "iopub.status.idle": "2021-05-17T07:59:35.125209Z",
     "shell.execute_reply": "2021-05-17T07:59:35.126440Z"
    },
    "id": "uNxpiKsoX1g6",
    "outputId": "c3740191-9b2d-406e-ad1d-b551f2ac2a71",
    "papermill": {
     "duration": 0.163865,
     "end_time": "2021-05-17T07:59:35.126683",
     "exception": false,
     "start_time": "2021-05-17T07:59:34.962818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.202961185701124"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(['சாவா', 'வேயப்பட்ட', 'சியோல்', 'வழங்கவில்லை', 'புரிந்து', 'ஜென்னி', 'போட்டிகளிலும்', 'பணித்', 'ஆலயமாக', 'லீக்கில்', 'ஆலயத்தில்', 'பாருங்கள்', 'உணவுத்', 'புரிபவர்கள்', 'செயலாற்றும்', 'பாதகமாக', 'மூலக்கூறுகளின்', 'சைபர்', 'சித்திரையில்', 'பேனல்கள்', 'அம்சங்களையும்', 'இந்தியாவுக்கான', 'கரகாட்டம்', 'நீல்', 'மிதக்கும்', 'அப்துல்', 'சோழர்களால்', 'தோன்றியது', 'பல்லவர்களின்', 'இலட்சம்', 'அட்டாக்', 'பவுடர்']\n",
    ",['சாலை', 'வெயபளபளைக்கைக்கைபைப்க்க்கைகா', 'சில்', 'வரங்கைகைக்கைக்க்க்க்க்க்க்க்', 'கோலாயகேக்க்க்ளு', 'ஜஜெயீலிலிக்க்க', 'போகுகிக்கிகைகிக்க்க்', 'பென்', 'ஆலியம்க்க்க்க்க்க்க்கை', 'லாகைகாகைகாகேக்க்க்', 'ஆலமாகர்க்க்க்', 'பாருலிகேகேகை', 'துர்க்க்க்க்க்க்க்க்க்க்ளு', 'புரிப்பிள்ள்', 'செயலாலைக்க்க்க்க்க்க்க்க்க்க', 'பாகாக்க்க்ளிள்க்', 'மூக்கிக்க்கிக்க்கைக', 'சிபெல்க்க்', 'சீதரிக்கிக்க்க்க்க்க்க்க்க்க', 'பேனில்கைகிக்க்ள்', 'அம்ம்லாக்ள்காள்கை', 'இந்தினிகிளிக்க்க்க்க்க்ள்ள்க', 'காரகாக்கிக்கால', 'க்ளியாள்க்க்கி', 'மீதிக்க்கிலுகிகை', 'அபோகுல்க்க்க', 'சொல்ளிளி', 'தூற்க்கிக்க்க்க்க்ளு', 'பயலால்க்க்க்க்க்க்', 'இலில்க்க்ளி', 'அடிக்க்க்கிளு', 'பாலுக்க்க்']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "local-entertainment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:35.340293Z",
     "iopub.status.busy": "2021-05-17T07:59:35.339348Z",
     "iopub.status.idle": "2021-05-17T07:59:35.343592Z",
     "shell.execute_reply": "2021-05-17T07:59:35.344341Z"
    },
    "id": "kDLMoTWfBn86",
    "papermill": {
     "duration": 0.121081,
     "end_time": "2021-05-17T07:59:35.344574",
     "exception": false,
     "start_time": "2021-05-17T07:59:35.223493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class tools:\n",
    "  def init_params(config,data_dict):\n",
    "  \n",
    "    # returning parameters\n",
    "    params = {\n",
    "        'num_encode_layers' : config.num_encode_layers,\n",
    "        'num_decode_layers' : config.num_decode_layers,\n",
    "        'cell_type' : config.cell_type,\n",
    "        'rep_size' : config.rep_size,\n",
    "        'embed_size' : config.embed_size,\n",
    "        'dropout' : config.dropout,\n",
    "        'num_epochs' : config.num_epochs,\n",
    "        'data_dict' : data_dict,\n",
    "        'batch_size' : config.batch_size\n",
    "    }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "addressed-dietary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:35.539499Z",
     "iopub.status.busy": "2021-05-17T07:59:35.537639Z",
     "iopub.status.idle": "2021-05-17T07:59:35.540053Z",
     "shell.execute_reply": "2021-05-17T07:59:35.540458Z"
    },
    "id": "_AWE1lLSDDXh",
    "papermill": {
     "duration": 0.057882,
     "end_time": "2021-05-17T07:59:35.540589",
     "exception": false,
     "start_time": "2021-05-17T07:59:35.482707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sweep configuration\n",
    "# sweep_config = {\n",
    "    \n",
    "#     'method' : 'bayes',\n",
    "#     'metric' : {\n",
    "#         'name' : 'val_acc',\n",
    "#         'goal' : 'maximize'\n",
    "#     },\n",
    "    \n",
    "#     'parameters': {\n",
    "#         'cell_type' : {\n",
    "#             'values': ['LSTM', 'GRU', 'SimpleRNN']  \n",
    "#         },\n",
    "#         'embed_size': {\n",
    "#             'values': [2, 4, 8, 16]\n",
    "#         },\n",
    "#         'rep_size': {\n",
    "#             'values': [32, 64, 128, 256]\n",
    "#         },\n",
    "#         'dropout': {\n",
    "#             'values': [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#         },\n",
    "#         'batch_size': {\n",
    "#             'values': [32]\n",
    "#         },\n",
    "#         'num_epochs': {\n",
    "#             'values': [5, 15, 25]\n",
    "#         },\n",
    "#         'num_encode_layers': {\n",
    "#             'values': [1, 2, 3]\n",
    "#         },\n",
    "#         'num_decode_layers': {\n",
    "#             'values': [1, 2, 3]\n",
    "#         }\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "objective-moisture",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:35.631195Z",
     "iopub.status.busy": "2021-05-17T07:59:35.629754Z",
     "iopub.status.idle": "2021-05-17T07:59:35.632025Z",
     "shell.execute_reply": "2021-05-17T07:59:35.632476Z"
    },
    "id": "gqDamLUoDQWV",
    "outputId": "48705e57-a6b2-4027-c271-536f14514e16",
    "papermill": {
     "duration": 0.049119,
     "end_time": "2021-05-17T07:59:35.632609",
     "exception": false,
     "start_time": "2021-05-17T07:59:35.583490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project='dakshina_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nutritional-madagascar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:35.724859Z",
     "iopub.status.busy": "2021-05-17T07:59:35.724062Z",
     "iopub.status.idle": "2021-05-17T07:59:35.726732Z",
     "shell.execute_reply": "2021-05-17T07:59:35.726346Z"
    },
    "id": "Ez3f-pjxDTU8",
    "papermill": {
     "duration": 0.051359,
     "end_time": "2021-05-17T07:59:35.726840",
     "exception": false,
     "start_time": "2021-05-17T07:59:35.675481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sweep_module:\n",
    "  @staticmethod\n",
    "  def train(config=None):\n",
    "\n",
    "    with wandb.init(config):\n",
    "      \n",
    "      # copying the config \n",
    "      config = wandb.config\n",
    " \n",
    "      # naming the run\n",
    "      wandb.run.name = 'typ:'+config['cell_type'][:4]+ '_' + 'dro:'+str(config['dropout'])+ '_' + 'enc:' + str(config['num_encode_layers'])+ '_' + 'dec:'+str(config['num_decode_layers'])\n",
    "      \n",
    "      # returning the data dictionairy\n",
    "      data_dict = dict_data_dict[config.batch_size]\n",
    "\n",
    "      # copying the parameters\n",
    "      params = tools.init_params(config,data_dict)\n",
    "\n",
    "      # creating and training the first model\n",
    "      network = rnn(params)\n",
    "      run_details = network.compile_and_fit(data_dict, params)\n",
    "\n",
    "      rnn_2 = rnn_second(network.details)\n",
    "      rnn_2.evaluate(data_dict,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "passive-dispatch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:35.817639Z",
     "iopub.status.busy": "2021-05-17T07:59:35.816823Z",
     "iopub.status.idle": "2021-05-17T07:59:35.819395Z",
     "shell.execute_reply": "2021-05-17T07:59:35.818986Z"
    },
    "id": "V6QBd1gJDV-R",
    "papermill": {
     "duration": 0.049495,
     "end_time": "2021-05-17T07:59:35.819508",
     "exception": false,
     "start_time": "2021-05-17T07:59:35.770013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sweep_id = '1gv485mq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "measured-fellowship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:35.909776Z",
     "iopub.status.busy": "2021-05-17T07:59:35.908973Z",
     "iopub.status.idle": "2021-05-17T07:59:35.911744Z",
     "shell.execute_reply": "2021-05-17T07:59:35.911345Z"
    },
    "id": "XCq49t4zDZod",
    "papermill": {
     "duration": 0.049521,
     "end_time": "2021-05-17T07:59:35.911865",
     "exception": false,
     "start_time": "2021-05-17T07:59:35.862344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performing the sweep\n",
    "# wandb.agent(sweep_id, sweep_module.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-virus",
   "metadata": {
    "id": "UBotvdIuDczo",
    "papermill": {
     "duration": 0.043263,
     "end_time": "2021-05-17T07:59:35.998604",
     "exception": false,
     "start_time": "2021-05-17T07:59:35.955341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rolled-banner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:36.089949Z",
     "iopub.status.busy": "2021-05-17T07:59:36.089161Z",
     "iopub.status.idle": "2021-05-17T07:59:36.092002Z",
     "shell.execute_reply": "2021-05-17T07:59:36.091609Z"
    },
    "id": "eBfaOoDTt-Zd",
    "papermill": {
     "duration": 0.050485,
     "end_time": "2021-05-17T07:59:36.092110",
     "exception": false,
     "start_time": "2021-05-17T07:59:36.041625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_encode_layers' : 3,\n",
    "    'num_decode_layers' : 1,\n",
    "    'cell_type' : 'LSTM', \n",
    "    'rep_size' : 128,\n",
    "    'embed_size' : 16,\n",
    "    'dropout' : 0.5,\n",
    "    'num_epochs' : 25,\n",
    "    'data_dict' : data_dict,\n",
    "    'batch_size' : 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "equipped-discretion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:36.187064Z",
     "iopub.status.busy": "2021-05-17T07:59:36.186328Z",
     "iopub.status.idle": "2021-05-17T07:59:39.471697Z",
     "shell.execute_reply": "2021-05-17T07:59:39.472426Z"
    },
    "id": "zi90I1dr2VcH",
    "papermill": {
     "duration": 3.336961,
     "end_time": "2021-05-17T07:59:39.472585",
     "exception": false,
     "start_time": "2021-05-17T07:59:36.135624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mramkamal\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">gentle-thunder-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ramkamal/uncategorized\" target=\"_blank\">https://wandb.ai/ramkamal/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ramkamal/uncategorized/runs/2d83du1u\" target=\"_blank\">https://wandb.ai/ramkamal/uncategorized/runs/2d83du1u</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210517_075936-2d83du1u</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2d83du1u)</h1><iframe src=\"https://wandb.ai/ramkamal/uncategorized/runs/2d83du1u\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f69842cbb90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "awful-polish",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:59:39.587626Z",
     "iopub.status.busy": "2021-05-17T07:59:39.586752Z",
     "iopub.status.idle": "2021-05-17T08:21:32.464771Z",
     "shell.execute_reply": "2021-05-17T08:21:32.464046Z"
    },
    "id": "gar8YRXwLV94",
    "outputId": "ed98f98b-16f5-4113-847c-7e1af1e09a3a",
    "papermill": {
     "duration": 1312.945565,
     "end_time": "2021-05-17T08:21:32.464927",
     "exception": false,
     "start_time": "2021-05-17T07:59:39.519362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 16)     480         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 128)    74240       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 128)    131584      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 16)     800         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 131584      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 128),  74240       embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 128)    0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 50)     6450        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 419,378\n",
      "Trainable params: 419,378\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2056/2056 [==============================] - 69s 26ms/step - loss: 0.8787 - acc: 0.3044 - val_loss: 0.5295 - val_acc: 0.5245\n",
      "Epoch 2/25\n",
      "2056/2056 [==============================] - 50s 24ms/step - loss: 0.5833 - acc: 0.5147 - val_loss: 0.3990 - val_acc: 0.6358\n",
      "Epoch 3/25\n",
      "2056/2056 [==============================] - 49s 24ms/step - loss: 0.4651 - acc: 0.6114 - val_loss: 0.3351 - val_acc: 0.6954\n",
      "Epoch 4/25\n",
      "2056/2056 [==============================] - 51s 25ms/step - loss: 0.4021 - acc: 0.6638 - val_loss: 0.2910 - val_acc: 0.7389\n",
      "Epoch 5/25\n",
      "2056/2056 [==============================] - 49s 24ms/step - loss: 0.3552 - acc: 0.7053 - val_loss: 0.2554 - val_acc: 0.7739\n",
      "Epoch 6/25\n",
      "2056/2056 [==============================] - 51s 25ms/step - loss: 0.3171 - acc: 0.7392 - val_loss: 0.2264 - val_acc: 0.8019\n",
      "Epoch 7/25\n",
      "2056/2056 [==============================] - 50s 24ms/step - loss: 0.2842 - acc: 0.7696 - val_loss: 0.2074 - val_acc: 0.8187\n",
      "Epoch 8/25\n",
      "2056/2056 [==============================] - 52s 25ms/step - loss: 0.2608 - acc: 0.7897 - val_loss: 0.1934 - val_acc: 0.8349\n",
      "Epoch 9/25\n",
      "2056/2056 [==============================] - 50s 24ms/step - loss: 0.2417 - acc: 0.8065 - val_loss: 0.1820 - val_acc: 0.8452\n",
      "Epoch 10/25\n",
      "2056/2056 [==============================] - 52s 25ms/step - loss: 0.2267 - acc: 0.8189 - val_loss: 0.1722 - val_acc: 0.8567\n",
      "Epoch 11/25\n",
      "2056/2056 [==============================] - 50s 24ms/step - loss: 0.2146 - acc: 0.8289 - val_loss: 0.1662 - val_acc: 0.8630\n",
      "Epoch 12/25\n",
      "2056/2056 [==============================] - 53s 26ms/step - loss: 0.2053 - acc: 0.8371 - val_loss: 0.1624 - val_acc: 0.8679\n",
      "Epoch 13/25\n",
      "2056/2056 [==============================] - 51s 25ms/step - loss: 0.1967 - acc: 0.8450 - val_loss: 0.1555 - val_acc: 0.8749\n",
      "Epoch 14/25\n",
      "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1891 - acc: 0.8503 - val_loss: 0.1510 - val_acc: 0.8781\n",
      "Epoch 15/25\n",
      "2056/2056 [==============================] - 51s 25ms/step - loss: 0.1821 - acc: 0.8564 - val_loss: 0.1503 - val_acc: 0.8794\n",
      "Epoch 16/25\n",
      "2056/2056 [==============================] - 54s 26ms/step - loss: 0.1768 - acc: 0.8614 - val_loss: 0.1473 - val_acc: 0.8832\n",
      "Epoch 17/25\n",
      "2056/2056 [==============================] - 52s 25ms/step - loss: 0.1703 - acc: 0.8666 - val_loss: 0.1439 - val_acc: 0.8855\n",
      "Epoch 18/25\n",
      "2056/2056 [==============================] - 54s 26ms/step - loss: 0.1660 - acc: 0.8695 - val_loss: 0.1416 - val_acc: 0.8878\n",
      "Epoch 19/25\n",
      "2056/2056 [==============================] - 50s 24ms/step - loss: 0.1621 - acc: 0.8732 - val_loss: 0.1419 - val_acc: 0.8873\n",
      "Epoch 20/25\n",
      "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1583 - acc: 0.8762 - val_loss: 0.1409 - val_acc: 0.8890\n",
      "Epoch 21/25\n",
      "2056/2056 [==============================] - 52s 25ms/step - loss: 0.1545 - acc: 0.8790 - val_loss: 0.1406 - val_acc: 0.8897\n",
      "Epoch 22/25\n",
      "2056/2056 [==============================] - 51s 25ms/step - loss: 0.1511 - acc: 0.8821 - val_loss: 0.1356 - val_acc: 0.8929\n",
      "Epoch 23/25\n",
      "2056/2056 [==============================] - 50s 25ms/step - loss: 0.1478 - acc: 0.8848 - val_loss: 0.1373 - val_acc: 0.8930\n",
      "Epoch 24/25\n",
      "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1461 - acc: 0.8859 - val_loss: 0.1368 - val_acc: 0.8916\n",
      "Epoch 25/25\n",
      "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1428 - acc: 0.8886 - val_loss: 0.1358 - val_acc: 0.8931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'run_details': <tensorflow.python.keras.callbacks.History at 0x7f690046b890>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = rnn(params)\n",
    "network.compile_and_fit(data_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "burning-absolute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:21:42.632215Z",
     "iopub.status.busy": "2021-05-17T08:21:42.631345Z",
     "iopub.status.idle": "2021-05-17T08:24:05.431071Z",
     "shell.execute_reply": "2021-05-17T08:24:05.431596Z"
    },
    "id": "DdHi981P1vAI",
    "papermill": {
     "duration": 147.948201,
     "end_time": "2021-05-17T08:24:05.431753",
     "exception": false,
     "start_time": "2021-05-17T08:21:37.483552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737344194d9b42d0acb67e6c69706fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Acc  0.6351523806630002\n",
      "Editdistance Train Avg  0.8995018425035165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f426ad50e64db1a2fbe89195f5bfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Val Acc  0.42540055857709835\n",
      "Editdistance Val Avg  0.7645827045064213\n"
     ]
    }
   ],
   "source": [
    "rnn_2 = rnn_second(network.details)\n",
    "# run_details_2 = rnn_2.compile_and_fit(data_dict, params)\n",
    "rnn_2.evaluate(data_dict, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "incorporate-creation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:24:15.571419Z",
     "iopub.status.busy": "2021-05-17T08:24:15.570564Z",
     "iopub.status.idle": "2021-05-17T08:24:56.272461Z",
     "shell.execute_reply": "2021-05-17T08:24:56.271825Z"
    },
    "id": "LvpiWzkuBR0k",
    "outputId": "86a98bc5-4403-4861-8510-378130ee0633",
    "papermill": {
     "duration": 45.924549,
     "end_time": "2021-05-17T08:24:56.272618",
     "exception": false,
     "start_time": "2021-05-17T08:24:10.348069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1105be03debb432c8632e829b7f92812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Acc  0.46813186813186813\n",
      "Editdistance Test Avg  0.8429676980387052\n"
     ]
    }
   ],
   "source": [
    "rnn_2.evaluate_test(data_dict,'/kaggle/working/greedy_rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "instant-chinese",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:25:06.884825Z",
     "iopub.status.busy": "2021-05-17T08:25:06.883003Z",
     "iopub.status.idle": "2021-05-17T08:25:06.885647Z",
     "shell.execute_reply": "2021-05-17T08:25:06.886496Z"
    },
    "id": "Ov4ObUBO1wtY",
    "outputId": "49052bd3-fc41-4936-b903-8fa41e712235",
    "papermill": {
     "duration": 5.500362,
     "end_time": "2021-05-17T08:25:06.886694",
     "exception": false,
     "start_time": "2021-05-17T08:25:01.386332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rnn_2 = rnn_second(network.details)\n",
    "# run_details_2 = rnn_2.compile_and_fit(data_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "neural-payment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:25:17.035742Z",
     "iopub.status.busy": "2021-05-17T08:25:17.034987Z",
     "iopub.status.idle": "2021-05-17T08:25:17.036917Z",
     "shell.execute_reply": "2021-05-17T08:25:17.036359Z"
    },
    "id": "bk5_HtEoSFcu",
    "papermill": {
     "duration": 4.88348,
     "end_time": "2021-05-17T08:25:17.037057",
     "exception": false,
     "start_time": "2021-05-17T08:25:12.153577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def evaluate(net, data_dict) :\n",
    "\n",
    "#   # test batch generator\n",
    "#   test_gen = data_dict['val']['batch_greedy']\n",
    "  \n",
    "#   # number of test samples\n",
    "#   test_samples = 32\n",
    "\n",
    "#   batch_size=32\n",
    "\n",
    "#   num_hits = 0\n",
    "  \n",
    "#   for _ in range(test_samples//batch_size) :\n",
    "#     (a,b),c = next(test_gen)\n",
    "#     c = np.argmax(c, axis=2)\n",
    "#     # print(c)\n",
    "#     l1 = data_dict['tokenizer'].decode(c, mode='output')\n",
    "#     out = net.model.predict([a,b])\n",
    "#     out = np.argmax(out,axis=2) \n",
    "#     l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
    "#     # print(l1)\n",
    "#     # print(l2)\n",
    "#     # print(out)\n",
    "#     num_hits += get_score(l1,l2)\n",
    "#     # break\n",
    "\n",
    "#   print(\"Val Acc \", num_hits/test_samples)\n",
    "#   # wandb.log({\"final_val_acc\":  num_hits/test_samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "presidential-rochester",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:25:27.198009Z",
     "iopub.status.busy": "2021-05-17T08:25:27.190415Z",
     "iopub.status.idle": "2021-05-17T08:25:27.201479Z",
     "shell.execute_reply": "2021-05-17T08:25:27.200895Z"
    },
    "id": "tzltrzDvtGdp",
    "papermill": {
     "duration": 4.901487,
     "end_time": "2021-05-17T08:25:27.201639",
     "exception": false,
     "start_time": "2021-05-17T08:25:22.300152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_sequence_beam(input_seq, k, encoder_model, decoder_model, tk, max_target_length=20, alpha=0.7,getall=False):\n",
    "    # encode the input as state vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = 1 \n",
    "    run_condition = [True for i in range(k)]\n",
    "    # print(len(states_value))\n",
    "    # print([target_seq] + [states_value])\n",
    "    results, *states_values_temp = decoder_model.predict([target_seq] + [states_value])\n",
    "    output_tokens = results\n",
    "\n",
    "    states_values_k = [states_values_temp for i in range(k)]\n",
    "    #get topk indices\n",
    "    ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
    "    bestk_ind = ind\n",
    "    output_tokens = np.array(output_tokens[0, -1, :])\n",
    "    bestk_prob = np.log(output_tokens[ind])\n",
    "    bestk_tot = [[bestk_ind[i]] for i in range(k)]\n",
    "    # print(bestk_tot)\n",
    "\n",
    "    \n",
    "    while any(run_condition):\n",
    "        bestk_tot_new = []\n",
    "        bestk_prob_new = []\n",
    "        states_values_k_new = []\n",
    "        for i in range(k) :\n",
    "            if run_condition[i] :\n",
    "                a = bestk_tot[i]\n",
    "                b = bestk_prob[i]\n",
    "                target_seq[0,0] = a[-1]\n",
    "                results,*states_values_temp = decoder_model.predict([target_seq] + states_values_k[i],batch_size=1)\n",
    "                output_tokens = results\n",
    "\n",
    "                states_values_k_temp = [states_values_temp for m in range(k)]\n",
    "\n",
    "                states_values_k_new += states_values_k_temp\n",
    "                ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
    "                bestk_ind = ind\n",
    "                output_tokens = np.array(output_tokens[0, -1, :])\n",
    "                bestk_prob_temp = output_tokens[ind]\n",
    "                bestk_tot_temp = [a+[bestk_ind[j]] for j in range(k)]\n",
    "                bestk_prob_temp2 = [(b*(np.power(len(bestk_tot_temp[j])-1,alpha)) + np.log(bestk_prob_temp[j]))/(np.power(len(bestk_tot_temp[j]),alpha)) for j in range(k)]\n",
    "                bestk_prob_new += bestk_prob_temp2\n",
    "                bestk_tot_new += bestk_tot_temp\n",
    "            \n",
    "            else :\n",
    "                a = bestk_tot[i]\n",
    "                b = bestk_prob[i]\n",
    "                bestk_tot_new += [bestk_tot[i]]\n",
    "                bestk_prob_new += [b]\n",
    "                states_values_k_new += [states_values_k[i]]\n",
    "\n",
    "        bestk_prob_new = np.array(bestk_prob_new)\n",
    "        # print(len(bestk_prob_new),len(bestk_tot_new),len(states_values_k_new))\n",
    "        ind = np.argpartition(bestk_prob_new,-k)[-k:]\n",
    "        bestk_tot = [bestk_tot_new[i] for i in ind]\n",
    "        states_values_k = [states_values_k_new[i] for i in ind]\n",
    "        bestk_prob = bestk_prob_new[ind]\n",
    "        run_condition = []\n",
    "        for i in range(k) :\n",
    "            a = bestk_tot[i]\n",
    "            b = bestk_prob[i]\n",
    "            if a[-1]!= 2 and len(a)<=max_target_length :\n",
    "              run_condition.append(True)\n",
    "            else :\n",
    "              run_condition.append(False)\n",
    "\n",
    "        # print(bestk_tot)\n",
    "\n",
    "    final_words = []\n",
    "    best_word = []\n",
    "    best = -5.0\n",
    "    for i in range(k) :\n",
    "      a = bestk_tot[i]\n",
    "      b = bestk_prob[i]\n",
    "      final_words += [a]\n",
    "      if b > best :\n",
    "        best_word = [a]\n",
    "        best = b\n",
    "\n",
    "    if getall :\n",
    "      return (tk.decode(final_words,'output'),best_word)\n",
    "    else :\n",
    "      return final_words,best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "boolean-rating",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:25:37.405668Z",
     "iopub.status.busy": "2021-05-17T08:25:37.404764Z",
     "iopub.status.idle": "2021-05-17T08:25:37.406549Z",
     "shell.execute_reply": "2021-05-17T08:25:37.407133Z"
    },
    "id": "1gAVtwb3tHyo",
    "papermill": {
     "duration": 5.059009,
     "end_time": "2021-05-17T08:25:37.407334",
     "exception": false,
     "start_time": "2021-05-17T08:25:32.348325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beam_search(details,tokenizer,test_data,out_size,beam,data_dict) :\n",
    "  encoder_model = Model(details['encoder_inputs'], details['encoder_states'])\n",
    "  rep_size = details['params']['rep_size']\n",
    "  decoder_state_input = []\n",
    "  for i in range(len(details['encoder_states'])) :\n",
    "      new_state = Input(shape=(rep_size,))\n",
    "      decoder_state_input.append(new_state)\n",
    "  decoder_inputs = details['decoder_inputs']\n",
    "  x = details['decoder_embedding'](decoder_inputs)\n",
    "\n",
    "  for layer in details['decoder_layers'] :\n",
    "    x, *decoder_states = layer(x,initial_state=decoder_state_input)\n",
    "\n",
    "  x = details['decoder_dense'](x)\n",
    "  decoder_model = Model(\n",
    "      [decoder_inputs] + decoder_state_input,\n",
    "      [x] + decoder_states )\n",
    "  inp = tokenizer.encode(test_data['df'].input.tolist())\n",
    "  out = tokenizer.encode(test_data['df'].output.tolist(),mode='output')\n",
    "  val_gen = data_loader._generate_batch(inp,out,data_dict,out_size)\n",
    "  acc = 0\n",
    "  acc_k = 0\n",
    "  num_val = len(inp)\n",
    "  inputs = []\n",
    "  outputs = []\n",
    "#   num_val = 10\n",
    "  for i in tqdm(range(num_val)) :\n",
    "    (input_seq,ans) , _ = next(val_gen)\n",
    "    K,best = decode_sequence_beam(input_seq,beam,encoder_model,decoder_model,tokenizer,data_dict['max_target_length'],getall=True)\n",
    "    w1 = tokenizer.decode(best,mode='output')\n",
    "    w2 = tokenizer.decode([ans[0][1:]],mode='output')\n",
    "    inputs.append(w2[0])\n",
    "    outputs.append(w1[0])\n",
    "#     print(K,w1,w2)\n",
    "    comp = (w1[0]==w2[0])\n",
    "    if comp :\n",
    "      acc += 1    \n",
    "    if w2[0] in K :\n",
    "      acc_k += 1\n",
    "\n",
    "  acc /= num_val\n",
    "  acc_k /= num_val\n",
    "  filename = '/kaggle/working/beam_rnn'\n",
    "  with open(filename, 'wb') as f:\n",
    "    pickle.dump([inputs,outputs], f)\n",
    "  print(\"Val Accuracy : \"+str(acc))\n",
    "  print(\"Val Accuracy K : \"+str(acc_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abstract-wiring",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:25:47.799466Z",
     "iopub.status.busy": "2021-05-17T08:25:47.797877Z",
     "iopub.status.idle": "2021-05-17T08:25:47.800345Z",
     "shell.execute_reply": "2021-05-17T08:25:47.801091Z"
    },
    "papermill": {
     "duration": 4.868164,
     "end_time": "2021-05-17T08:25:47.801309",
     "exception": false,
     "start_time": "2021-05-17T08:25:42.933145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# beam_search(network.details,data_dict['tokenizer'],data_dict['test'],data_dict['out_size'],10,data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-upset",
   "metadata": {
    "id": "CBDm0UsMc0lr",
    "papermill": {
     "duration": 4.871932,
     "end_time": "2021-05-17T08:25:57.913440",
     "exception": false,
     "start_time": "2021-05-17T08:25:53.041508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "collaborative-devices",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:26:07.989450Z",
     "iopub.status.busy": "2021-05-17T08:26:07.988605Z",
     "iopub.status.idle": "2021-05-17T08:26:07.991134Z",
     "shell.execute_reply": "2021-05-17T08:26:07.991676Z"
    },
    "id": "ZgcjEWaGczny",
    "outputId": "8f5c5664-eaa2-448c-ab07-5dea8bbac89d",
    "papermill": {
     "duration": 4.964021,
     "end_time": "2021-05-17T08:26:07.991850",
     "exception": false,
     "start_time": "2021-05-17T08:26:03.027829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rnn_2.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-injury",
   "metadata": {
    "id": "Q50aXs34flRf",
    "papermill": {
     "duration": 5.077259,
     "end_time": "2021-05-17T08:26:18.411758",
     "exception": false,
     "start_time": "2021-05-17T08:26:13.334499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "authorized-spine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:26:28.458053Z",
     "iopub.status.busy": "2021-05-17T08:26:28.457234Z",
     "iopub.status.idle": "2021-05-17T08:26:28.460070Z",
     "shell.execute_reply": "2021-05-17T08:26:28.459459Z"
    },
    "id": "oVgcNhOQfm1T",
    "papermill": {
     "duration": 5.095709,
     "end_time": "2021-05-17T08:26:28.460247",
     "exception": false,
     "start_time": "2021-05-17T08:26:23.364538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rnn_2_loaded = rnn_second()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "lined-safety",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:26:38.592044Z",
     "iopub.status.busy": "2021-05-17T08:26:38.591099Z",
     "iopub.status.idle": "2021-05-17T08:26:38.593737Z",
     "shell.execute_reply": "2021-05-17T08:26:38.592999Z"
    },
    "id": "HFnwzLBQgy0P",
    "outputId": "cc522c51-8d4a-42b4-8909-c7e51451ee57",
    "papermill": {
     "duration": 5.183102,
     "end_time": "2021-05-17T08:26:38.593901",
     "exception": false,
     "start_time": "2021-05-17T08:26:33.410799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rnn_2.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-guinea",
   "metadata": {
    "id": "yoVmYJXQV2Fg",
    "papermill": {
     "duration": 5.193221,
     "end_time": "2021-05-17T08:26:49.152731",
     "exception": false,
     "start_time": "2021-05-17T08:26:43.959510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "documentary-brooks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:26:59.272011Z",
     "iopub.status.busy": "2021-05-17T08:26:59.271155Z",
     "iopub.status.idle": "2021-05-17T08:26:59.273959Z",
     "shell.execute_reply": "2021-05-17T08:26:59.274530Z"
    },
    "id": "XvJ0o0TDV4ns",
    "papermill": {
     "duration": 5.170363,
     "end_time": "2021-05-17T08:26:59.274722",
     "exception": false,
     "start_time": "2021-05-17T08:26:54.104359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_test():\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-parameter",
   "metadata": {
    "id": "W3crs0giYyAo",
    "papermill": {
     "duration": 5.108275,
     "end_time": "2021-05-17T08:27:09.329500",
     "exception": false,
     "start_time": "2021-05-17T08:27:04.221225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ROUGH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1733.940301,
   "end_time": "2021-05-17T08:27:17.469327",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-17T07:58:23.529026",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03c38b7f21834e88a561eefe739198b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "04f426ad50e64db1a2fbe89195f5bfc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3a7793f39f17481e9b202249c6a672d3",
        "IPY_MODEL_0f7e3f2c33dd4572b1995d65659c95f9",
        "IPY_MODEL_5515367156984abc9f5481727a44b4b3"
       ],
       "layout": "IPY_MODEL_dd305b72c8a049838ea9add582a66122"
      }
     },
     "0f7e3f2c33dd4572b1995d65659c95f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_54ed5e859e4b411dab25bbcee992341e",
       "max": 6.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_697532a2685047f39b4ad530d7bbc00e",
       "value": 6.0
      }
     },
     "1105be03debb432c8632e829b7f92812": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3194ee22c89a44699471a74170c3f8b2",
        "IPY_MODEL_ce65180ae926446f83e2c86e9e9a0dd0",
        "IPY_MODEL_d586ffa5ee034ea6be0c49ec9eb8fd8f"
       ],
       "layout": "IPY_MODEL_864d8ee3d3374abb91f85615fdf0b095"
      }
     },
     "15e5ba6199bd434092efafba3323e3d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "187cf56b29794683a7059e676898a3db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b92b5461df54889bb3903d0ccbf82f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c8f46cb370d4022bc2fc1be461f81f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fa533a76dc7e4615bc80ddcb61fb0d01",
       "placeholder": "​",
       "style": "IPY_MODEL_58b4ee6fa7614b4398831b96aa2e72db",
       "value": ""
      }
     },
     "21640837d7324c14a928032657845075": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "252c79d847b347d9a2434d963e93d8e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_187cf56b29794683a7059e676898a3db",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e653ac354f7843bd866c96176d7d17d9",
       "value": 0.0
      }
     },
     "3194ee22c89a44699471a74170c3f8b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_84d8733fb85f40e1baa3d71d1b05f3a2",
       "placeholder": "​",
       "style": "IPY_MODEL_afddb288b698463484c4af6dc987234c",
       "value": "100%"
      }
     },
     "3a7793f39f17481e9b202249c6a672d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_21640837d7324c14a928032657845075",
       "placeholder": "​",
       "style": "IPY_MODEL_66c170c700754168ba722c68cfc98ef7",
       "value": "100%"
      }
     },
     "432707dd8d6b4247bf551b28558a4f7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5fa7b1d7d43c4132b0c7f6c1fe503853",
       "placeholder": "​",
       "style": "IPY_MODEL_e449fbd05a9e46b8b2a9baf589eb73c5",
       "value": "100%"
      }
     },
     "4b9e09bd6ff64cbfbe7b4644618b47c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b92b5461df54889bb3903d0ccbf82f6",
       "placeholder": "​",
       "style": "IPY_MODEL_6282ac916a6942cc83121667207233da",
       "value": " 64/64 [01:49&lt;00:00,  1.24s/it]"
      }
     },
     "4f5084c2924941cda8c740ef645acadb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54ed5e859e4b411dab25bbcee992341e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5515367156984abc9f5481727a44b4b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_15e5ba6199bd434092efafba3323e3d3",
       "placeholder": "​",
       "style": "IPY_MODEL_ffa965c23d174c859aed4a6e363f7116",
       "value": " 6/6 [00:12&lt;00:00,  2.13s/it]"
      }
     },
     "58b4ee6fa7614b4398831b96aa2e72db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5c30d32dbffe40349afb3de70f5417e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1c8f46cb370d4022bc2fc1be461f81f7",
        "IPY_MODEL_252c79d847b347d9a2434d963e93d8e1"
       ],
       "layout": "IPY_MODEL_03c38b7f21834e88a561eefe739198b7"
      }
     },
     "5fa7b1d7d43c4132b0c7f6c1fe503853": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6282ac916a6942cc83121667207233da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "66c170c700754168ba722c68cfc98ef7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "697532a2685047f39b4ad530d7bbc00e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "737344194d9b42d0acb67e6c69706fd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_432707dd8d6b4247bf551b28558a4f7c",
        "IPY_MODEL_8dd82a48e40b4655881e4928112d3d15",
        "IPY_MODEL_4b9e09bd6ff64cbfbe7b4644618b47c0"
       ],
       "layout": "IPY_MODEL_bbefcc1da4474790bd03c8fbb10a1ae8"
      }
     },
     "84d8733fb85f40e1baa3d71d1b05f3a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "864d8ee3d3374abb91f85615fdf0b095": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8dd82a48e40b4655881e4928112d3d15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a773453653164a6197220d5b5af1aab9",
       "max": 64.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f1f1ba1c3e5348e9b87feaddf197389d",
       "value": 64.0
      }
     },
     "a773453653164a6197220d5b5af1aab9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afddb288b698463484c4af6dc987234c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b585a1cfe4184c98b4e06f45da7b3a1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbefcc1da4474790bd03c8fbb10a1ae8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc628120f040444b8704abeba34be1de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ce65180ae926446f83e2c86e9e9a0dd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4f5084c2924941cda8c740ef645acadb",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fd53fe1a48cd4441acb83be0ed8418d8",
       "value": 1.0
      }
     },
     "d586ffa5ee034ea6be0c49ec9eb8fd8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b585a1cfe4184c98b4e06f45da7b3a1d",
       "placeholder": "​",
       "style": "IPY_MODEL_bc628120f040444b8704abeba34be1de",
       "value": " 1/1 [00:40&lt;00:00, 40.69s/it]"
      }
     },
     "dd305b72c8a049838ea9add582a66122": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e449fbd05a9e46b8b2a9baf589eb73c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e653ac354f7843bd866c96176d7d17d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f1f1ba1c3e5348e9b87feaddf197389d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fa533a76dc7e4615bc80ddcb61fb0d01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd53fe1a48cd4441acb83be0ed8418d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ffa965c23d174c859aed4a6e363f7116": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
