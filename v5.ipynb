{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "v6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd5217d19a284d18a3db587e3fffd999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b6eb279be274a80bca9b66aacfddbf1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a55cb341747b4b02ab5345d6f045e1dd",
              "IPY_MODEL_5853a888dd0e46a1b994ef5984b3165d"
            ]
          }
        },
        "7b6eb279be274a80bca9b66aacfddbf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a55cb341747b4b02ab5345d6f045e1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_8056cbc1cd4d4e338c1af5240b1dba9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78474c330f6749799a8318801030d77b"
          }
        },
        "5853a888dd0e46a1b994ef5984b3165d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_756e6d3dd744478ea55ad37b66bafe31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea5f53b17d424f99bf5bbd374c09fb72"
          }
        },
        "8056cbc1cd4d4e338c1af5240b1dba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78474c330f6749799a8318801030d77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "756e6d3dd744478ea55ad37b66bafe31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea5f53b17d424f99bf5bbd374c09fb72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "166781fe39c04d38b4a37bdfe864504f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b22fb3144f64b3b9a2fa939fdc96d0a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe83fdc81ffb41a68a8775bd5f123c0e",
              "IPY_MODEL_710d2d82fe034c1b9675d248fb78299c"
            ]
          }
        },
        "7b22fb3144f64b3b9a2fa939fdc96d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe83fdc81ffb41a68a8775bd5f123c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_9d9474b725434928bd042538aaa3953f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.00MB of 0.00MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_282873a718224017a015e0b686fd3646"
          }
        },
        "710d2d82fe034c1b9675d248fb78299c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b38688d330264a9fb831757ed0726c30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0dc7735232ae41bf9a1e8c1dac1ac72d"
          }
        },
        "9d9474b725434928bd042538aaa3953f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "282873a718224017a015e0b686fd3646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b38688d330264a9fb831757ed0726c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0dc7735232ae41bf9a1e8c1dac1ac72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a484c7e2ab4242bfaae533b4f8646f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9daf2180bcb4347908774f93def7890",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41e290870b0f43b791ca65b522404644",
              "IPY_MODEL_e258e417b4a5457dbef9937be633e502"
            ]
          }
        },
        "b9daf2180bcb4347908774f93def7890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41e290870b0f43b791ca65b522404644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_e8cbac7ff0c048fc924e2240c51203e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f41529fc34a41dc87b1e8d8611a37a8"
          }
        },
        "e258e417b4a5457dbef9937be633e502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ff908fdafaa4c05a49e513099b9fcf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff8e0de9c1b1474c910829770584850b"
          }
        },
        "e8cbac7ff0c048fc924e2240c51203e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f41529fc34a41dc87b1e8d8611a37a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ff908fdafaa4c05a49e513099b9fcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff8e0de9c1b1474c910829770584850b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtcVxQrUVxtS"
      },
      "source": [
        "# TO DO\n",
        "1. Change structure of test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRAUpzh1BLEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03590ea2-fb8d-42d2-f31c-ef54a97746b6"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.30)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.1.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bClAC3xAEhKS"
      },
      "source": [
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "from keras import layers\n",
        "from keras.layers import LSTM, Dense, Embedding, Input\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tqdm.auto import tqdm\n",
        "from keras.layers import Lambda\n",
        "from keras import backend as K\n",
        "import datetime\n",
        "from math import ceil\n",
        "from pprint import pprint"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs9sbR5xCVo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7530494a-f73b-4d80-b2f6-29905baa0924"
      },
      "source": [
        "!wget -nc https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "\n",
        "if not os.path.isdir('/content/dakshina_dataset_v1.0'):\n",
        "  tarfile.open(\"/content/dakshina_dataset_v1.0.tar\").extractall()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘dakshina_dataset_v1.0.tar’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0fMpPf_BUUK",
        "outputId": "321b2147-ab0a-4767-ae18-c60321ff8ce1"
      },
      "source": [
        "wandb.login(key='14394907543f59ea21931529e34b4d80d2ca8c9c')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BstzblcHmd5"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNDJrkl5EUHX"
      },
      "source": [
        "class data_loader():\n",
        "\n",
        "  @staticmethod\n",
        "  def _load_raw_df(languages = [\"mr\",\"hi\"]):\n",
        "    lex = dict()\n",
        "    lex['train'], lex['val'], lex['test'] = [], [], [] \n",
        "    column_names = ['output', 'input', 'count']\n",
        "    \n",
        "    for la in languages:\n",
        "      lex['train'].append(pd.read_csv('/content/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.train.tsv', sep='\\t', header=None, names=column_names))\n",
        "      lex['val'].append(pd.read_csv('/content/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.dev.tsv', sep='\\t', header=None, names=column_names))\n",
        "      lex['test'].append(pd.read_csv('/content/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.test.tsv', sep='\\t', header=None, names=column_names))\n",
        "\n",
        "    lex['train'] = pd.concat(lex['train'])\n",
        "    lex['val'] = pd.concat(lex['val'])\n",
        "    lex['test'] = pd.concat(lex['test'])\n",
        "\n",
        "    return lex    \n",
        "\n",
        "  @staticmethod\n",
        "  def _make_final_df(lex):\n",
        "    \n",
        "    for div in ['train', 'val', 'test']:\n",
        "    \n",
        "      # removing non max transliterations\n",
        "      idx = lex[div].groupby(['input'])['count'].transform(max) == lex[div]['count']\n",
        "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
        "\n",
        "      # calclulating difference in lengths of various transliterations\n",
        "      lex[div]['input_len'] = lex[div].apply(lambda x: len(str(x['input'])), axis=1)\n",
        "      lex[div]['output_len'] = lex[div].apply(lambda y: len(str(y['output'])), axis=1)\n",
        "      lex[div]['mod_dif'] = lex[div].apply(lambda z: abs(z['input_len'] - z['output_len']), axis=1) \n",
        "\n",
        "      # removing transliterations that vary by a lot in length\n",
        "      idx = lex[div].groupby(['input'])['mod_dif'].transform(min) == lex[div]['mod_dif']\n",
        "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
        "\n",
        "      # removing duplicates if any remain\n",
        "      lex[div].drop_duplicates(subset='input', keep='first', inplace=True)\n",
        "\n",
        "      # removing redundant columns\n",
        "      lex[div].drop(labels=['count', 'input_len', 'output_len', 'mod_dif'], inplace=True, axis=1)\n",
        "\n",
        "      # shuffling the dataset i.e. rows of the dataset\n",
        "      lex[div] = lex[div].sample(frac=1)\n",
        "      lex[div].reset_index()\n",
        "\n",
        "    return lex\n",
        "\n",
        "  @staticmethod\n",
        "  def _generate_batch(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
        "\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            \n",
        "            # placeholder data structures\n",
        "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, data_dict['max_target_length']),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
        "\n",
        "            # assessing one batch at a time\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "\n",
        "                for t, word in enumerate(input_text):\n",
        "                  encoder_input_data[i, t] = word\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t<len(target_text)-1:\n",
        "                        # decoder input sequence\n",
        "                        # does not include the <EOW> token\n",
        "                        decoder_input_data[i, t] = word \n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the <SOW> token\n",
        "                        decoder_target_data[i, t - 1, word] = 1.\n",
        "                    \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
        "\n",
        "  @staticmethod\n",
        "  def _generate_batch_greedy(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
        "\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "\n",
        "            # placeholder data structures\n",
        "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, 1),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
        "            \n",
        "            # assessing one batch at a time\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text):\n",
        "                  encoder_input_data[i, t] = word\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t==0 :\n",
        "                        decoder_input_data[i, t] = 1 # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        decoder_target_data[i, t - 1, word] = 1.\n",
        "                    \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOo1m6s3vDaN"
      },
      "source": [
        "class Tokenizer:\n",
        "\n",
        "  def __init__(self, df):\n",
        "\n",
        "    self.start_token = '<SOW>'\n",
        "    self.stop_token = '<EOW>'\n",
        "    self.unknown_token = '<UNK>'\n",
        "\n",
        "    self.input_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
        "    self.output_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
        "\n",
        "    input_words = df.input.tolist()\n",
        "    output_words = df.output.tolist()\n",
        "\n",
        "    for word in input_words:\n",
        "      tokens = str(word)\n",
        "      for token in tokens:\n",
        "        if token not in self.input_corpus:\n",
        "          self.input_corpus.append(token)\n",
        "\n",
        "    for word in output_words:\n",
        "      tokens = str(word)\n",
        "      for token in tokens:\n",
        "        if token not in self.output_corpus:\n",
        "          self.output_corpus.append(token)\n",
        "    \n",
        "    self.encode_dict_input = {self.input_corpus[i] : i+1 for i in range(len(self.input_corpus))}\n",
        "    self.decode_dict_input = {k:v for v,k in self.encode_dict_input.items()}\n",
        "    \n",
        "    \n",
        "    self.encode_dict_output = {self.output_corpus[i] : i+1 for i in range(len(self.output_corpus))}\n",
        "    self.decode_dict_output = {k:v for v,k in self.encode_dict_output.items()}\n",
        "\n",
        "  # takes in lists of words and returns lists of integers\n",
        "  def encode(self, X, mode='input'):\n",
        "\n",
        "    if (mode=='input'):\n",
        "      input_list = []\n",
        "      for word in X:\n",
        "        word = str(word)\n",
        "        integer_list =np.array([self.encode_dict_input.get(token, self.encode_dict_input[self.unknown_token]) for token in word])\n",
        "        input_list.append(integer_list)\n",
        "      \n",
        "      return input_list\n",
        "    \n",
        "    if (mode=='output'):\n",
        "      output_list = []\n",
        "      for word in X:\n",
        "        word = str(word)\n",
        "        integer_list = np.array([self.encode_dict_output[self.start_token]] + [self.encode_dict_output.get(token, self.encode_dict_output[self.unknown_token]) for token in word] + [self.encode_dict_output[self.stop_token]])\n",
        "        output_list.append(integer_list)\n",
        "      \n",
        "      return output_list\n",
        "    \n",
        "  # takes in lists of integers and returns lists of words\n",
        "  def decode(self, X, mode='input'):\n",
        "\n",
        "    if (mode=='input'):\n",
        "      input_list = []\n",
        "      for integers in X:\n",
        "        token_list = [self.decode_dict_input.get(integer, '') for integer in integers] \n",
        "        input_list.append(''.join(token_list))\n",
        "      \n",
        "      return input_list\n",
        "\n",
        "    if (mode=='output'):\n",
        "      output_list = []\n",
        "      for integers in X:\n",
        "        token_list = [self.decode_dict_output.get(integer, '') for integer in integers[1:-1]] \n",
        "        output_list.append(''.join(token_list))\n",
        "      \n",
        "      return output_list"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1mzVsRdBa4x"
      },
      "source": [
        "def return_data_dict(languages=['mr','hi'], batch_size=32):\n",
        "\n",
        "  lex = data_loader._load_raw_df(languages)\n",
        "  lex = data_loader._make_final_df(lex)\n",
        "\n",
        "  data_dict = dict()\n",
        "\n",
        "  df_train = lex['train'].head(n=100)\n",
        "  df_val = lex['val'].head(n=100)\n",
        "  df_test = lex['test'].head(n=100)\n",
        "\n",
        "  tk = Tokenizer(df_train)\n",
        "\n",
        "  data_dict['in_size'] = len(tk.input_corpus) + 1\n",
        "  data_dict['out_size'] = len(tk.output_corpus) + 1\n",
        "\n",
        "  X_train = tk.encode(df_train.input.tolist(), mode='input')\n",
        "  Y_train = tk.encode(df_train.output.tolist(), mode='output')\n",
        "  \n",
        "  X_val = tk.encode(df_val.input.tolist(), mode='input')\n",
        "  Y_val = tk.encode(df_val.output.tolist(), mode='output')\n",
        "  \n",
        "  X_test = tk.encode(df_test.input.tolist(), mode='input')\n",
        "  Y_test = tk.encode(df_test.output.tolist(), mode='output')\n",
        "\n",
        "\n",
        "  data_dict['train'], data_dict['val'], data_dict['test']= dict(), dict(), dict()\n",
        "\n",
        "\n",
        "  data_dict['train']['df'] = df_train\n",
        "  data_dict['val']['df'] = df_val\n",
        "  data_dict['test']['df'] = df_test\n",
        "\n",
        "\n",
        "  data_dict['train']['max_source_length'] = np.max(np.array([len(x) for x in X_train]))\n",
        "  data_dict['train']['max_target_length'] = np.max(np.array([len(x) for x in Y_train]))\n",
        "  \n",
        "  data_dict['val']['max_source_length'] = np.max(np.array([len(x) for x in X_val]))\n",
        "  data_dict['val']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
        "  \n",
        "  data_dict['test']['max_source_length'] = np.max(np.array([len(x) for x in X_test]))\n",
        "  data_dict['test']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
        "\n",
        "\n",
        "  data_dict['max_source_length'] = max(data_dict['train']['max_source_length'], data_dict['val']['max_source_length'], data_dict['test']['max_source_length'])\n",
        "  data_dict['max_target_length'] = max(data_dict['train']['max_target_length'], data_dict['val']['max_target_length'], data_dict['test']['max_target_length'])\n",
        "\n",
        "\n",
        "  data_dict['train']['batch'] = data_loader._generate_batch(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['train']['batch_greedy'] = data_loader._generate_batch_greedy(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
        "  \n",
        "  data_dict['val']['batch'] = data_loader._generate_batch(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['val']['batch_greedy'] = data_loader._generate_batch_greedy(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
        "\n",
        "  data_dict['test']['batch'] = data_loader._generate_batch(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)  \n",
        "  data_dict['test']['batch_greedy'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)    \n",
        "  data_dict['test']['batch_1'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], 1)\n",
        "\n",
        "\n",
        "  data_dict['tokenizer'] = tk\n",
        "\n",
        "  return data_dict"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwJozmDWedfG"
      },
      "source": [
        "data_dict = return_data_dict()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zKjtjWJ_U9t",
        "outputId": "50e351fd-edd6-4153-9e7f-adbc4635fd94"
      },
      "source": [
        "pprint(data_dict)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'in_size': 29,\n",
            " 'max_source_length': 16,\n",
            " 'max_target_length': 19,\n",
            " 'out_size': 56,\n",
            " 'test': {'batch': <generator object data_loader._generate_batch at 0x7fc801ca0f50>,\n",
            "          'batch_1': <generator object data_loader._generate_batch_greedy at 0x7fc801ca0d50>,\n",
            "          'batch_greedy': <generator object data_loader._generate_batch_greedy at 0x7fc801ca03d0>,\n",
            "          'df':               output           input\n",
            "9736        सिंघाड़े         singhre\n",
            "1906          डॉल्बी          dolbii\n",
            "3522    ब्राह्मणांचा    bramhanancha\n",
            "9383          विष्णु         vishanu\n",
            "8918         योजनाएं       yojanaein\n",
            "...              ...             ...\n",
            "4055          मोर्ले         moorley\n",
            "6342           कमेरे           kmere\n",
            "4837  व्याख्यानासाठी  vyakhyanasathi\n",
            "2574         परफेक्ट       peerfeekt\n",
            "4507        वकिलांना       vakilanna\n",
            "\n",
            "[100 rows x 2 columns],\n",
            "          'max_source_length': 16,\n",
            "          'max_target_length': 19},\n",
            " 'tokenizer': <__main__.Tokenizer object at 0x7fc7f675f710>,\n",
            " 'train': {'batch': <generator object data_loader._generate_batch at 0x7fc97350f550>,\n",
            "           'batch_greedy': <generator object data_loader._generate_batch_greedy at 0x7fc801ca0550>,\n",
            "           'df':             output         input\n",
            "85587          वेट           wet\n",
            "18340     ढासळलेली   dhasalhleli\n",
            "27854  प्रचाराच्या  pracharachya\n",
            "51870    होईपर्यंत    hoiparyant\n",
            "2191   आंबेडकरांना  ambedkaranna\n",
            "...            ...           ...\n",
            "7532         काजोल       kajoola\n",
            "24028       नेल्सन       nelsana\n",
            "23893   नेटवर्किंग   netavarqing\n",
            "40891   लोकबिरादरी   lokbiradari\n",
            "78879    मध्यस्थता   madhyasthta\n",
            "\n",
            "[100 rows x 2 columns],\n",
            "           'max_source_length': 16,\n",
            "           'max_target_length': 17},\n",
            " 'val': {'batch': <generator object data_loader._generate_batch at 0x7fc801ca0ed0>,\n",
            "         'batch_greedy': <generator object data_loader._generate_batch_greedy at 0x7fc801ca01d0>,\n",
            "         'df':             output       input\n",
            "7583          नकुम       nakum\n",
            "2717         पुढचा     pudhcha\n",
            "1849         तसतशी    tastashi\n",
            "1845    तळ्यातल्या   talyatlya\n",
            "9710         सौदों      saudon\n",
            "...            ...         ...\n",
            "9361       शिनाख्त    shinakht\n",
            "3056          फारच     pharach\n",
            "1463         जायफळ     jayphal\n",
            "6931         ज़मीर       zamir\n",
            "8     अंटार्क्टिका  antarctika\n",
            "\n",
            "[100 rows x 2 columns],\n",
            "         'max_source_length': 16,\n",
            "         'max_target_length': 19}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV_63arXtzSt"
      },
      "source": [
        "# Question 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwQl8eh2y35p"
      },
      "source": [
        "# class BeamSearchCallBack(keras.callbacks.Callback):\n",
        "#   def __init__(self, details, test_data, tokenizer, out_size, num_val=200, beam=3) :\n",
        "#     self.details = details\n",
        "#     self.test_data = test_data\n",
        "#     self.tokenizer = tokenizer\n",
        "#     self.out_size = out_size\n",
        "#     self.num_val = num_val\n",
        "#     self.beam = beam\n",
        "\n",
        "#   def on_epoch_end(self, epoch, logs=None) :\n",
        "    \n",
        "#     # defining the encoder model\n",
        "#     encoder_model = Model(self.details['encoder_inputs'], self.details['encoder_states'])\n",
        "    \n",
        "#     # hidden representation size\n",
        "#     rep_size = self.details['params']['rep_size']\n",
        "\n",
        "#     # initializing decoder state input\n",
        "#     decoder_state_input = []\n",
        "\n",
        "\n",
        "#     for i in range(len(self.details['encoder_states'])) :\n",
        "#         new_state = Input(shape=(rep_size,))\n",
        "#         decoder_state_input.append(new_state)\n",
        "#     decoder_inputs = self.details['decoder_inputs']\n",
        "#     x = self.details['decoder_embedding'](decoder_inputs)\n",
        "    \n",
        "#     for layer in self.details['decoder_layers'] :\n",
        "#       x, *decoder_states = layer(x,initial_state=decoder_state_input)\n",
        "\n",
        "#     x = self.details['decoder_dense'](x)\n",
        "#     decoder_model = Model(\n",
        "#         [decoder_inputs] + decoder_state_input,\n",
        "#         [x] + decoder_states )\n",
        "#     inp = self.tokenizer.encode(self.test_data['df'].input.tolist())\n",
        "#     out = self.tokenizer.encode(self.test_data['df'].output.tolist(),mode='output')\n",
        "#     out_size = self.out_size\n",
        "#     val_gen = data_loader._generate_batch(inp,out,self.test_data,self.out_size)\n",
        "#     acc = 0\n",
        "#     for i in tqdm(range(self.num_val)) :\n",
        "#       (input_seq,ans) , _ = next(val_gen)\n",
        "#       _,best = decode_sequence_beam(input_seq,self.beam,encoder_model,decoder_model,self.tokenizer,self.test_data['max_target_length'])\n",
        "#       w1 = self.tokenizer.decode(best,mode='output')\n",
        "#       w2 = self.tokenizer.decode(ans,mode='output')\n",
        "#       comp = (w1==w2)\n",
        "#       if comp :\n",
        "#         acc += 1    \n",
        "\n",
        "#     acc /= len(inp)\n",
        "#     print(\"Val Accuracy : \"+str(acc))\n",
        "    "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-cdgAqTLyAr"
      },
      "source": [
        "def decode_sequence_beam(input_seq, k, encoder_model, decoder_model, tk, max_target_length=20, getall=False):\n",
        "    # encode the input as state vectors\n",
        "    states_value = encoder_model.predict(input_seq,batch_size=1,use_multiprocessing=True)\n",
        "    # generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = 1 \n",
        "    run_condition = [True for i in range(k)]\n",
        "    # print(len(states_value))\n",
        "    # print([target_seq] + [states_value])\n",
        "    results, *states_values_temp = decoder_model.predict([target_seq] + [states_value])\n",
        "    output_tokens = results\n",
        "\n",
        "    states_values_k = [states_values_temp for i in range(k)]\n",
        "    #get topk indices\n",
        "    ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
        "    bestk_ind = ind\n",
        "    output_tokens = np.array(output_tokens[0, -1, :])\n",
        "    bestk_prob = output_tokens[ind]\n",
        "    bestk_tot = [[1,bestk_ind[i]] for i in range(k)]\n",
        "    # print(bestk_tot)\n",
        "\n",
        "    \n",
        "    while any(run_condition):\n",
        "        bestk_tot_new = []\n",
        "        bestk_prob_new = []\n",
        "        states_values_k_new = []\n",
        "        for i in range(k) :\n",
        "            if run_condition[i] :\n",
        "                a = bestk_tot[i]\n",
        "                b = bestk_prob[i]\n",
        "                target_seq[0,0] = a[-1]\n",
        "                results,*states_values_temp = decoder_model.predict([target_seq] + states_values_k[i],batch_size=1)\n",
        "                output_tokens = results\n",
        "\n",
        "                states_values_k_temp = [states_values_temp for m in range(k)]\n",
        "\n",
        "                states_values_k_new += states_values_k_temp\n",
        "                ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
        "                bestk_ind = ind\n",
        "                output_tokens = np.array(output_tokens[0, -1, :])\n",
        "                bestk_prob_temp = output_tokens[ind]\n",
        "                bestk_tot_temp = [a+[bestk_ind[j]] for j in range(k)]\n",
        "                bestk_prob_temp2 = [b*bestk_prob_temp[j] for j in range(k)]\n",
        "                bestk_prob_new += bestk_prob_temp2\n",
        "                bestk_tot_new += bestk_tot_temp\n",
        "            \n",
        "            else :\n",
        "                a = bestk_tot[i]\n",
        "                b = bestk_prob[i]\n",
        "                bestk_tot_new += [bestk_tot[i]]\n",
        "                bestk_prob_new += [b]\n",
        "                states_values_k_new += [states_values_k[i]]\n",
        "\n",
        "        bestk_prob_new = np.array(bestk_prob_new)\n",
        "        # print(len(bestk_prob_new),len(bestk_tot_new),len(states_values_k_new))\n",
        "        ind = np.argpartition(bestk_prob_new,-k)[-k:]\n",
        "        bestk_tot = [bestk_tot_new[i] for i in ind]\n",
        "        states_values_k = [states_values_k_new[i] for i in ind]\n",
        "        bestk_prob = bestk_prob_new[ind]\n",
        "        run_condition = []\n",
        "        for i in range(k) :\n",
        "            a = bestk_tot[i]\n",
        "            b = bestk_prob[i]\n",
        "            if a[-1]!= 2 and len(a)<=max_target_length :\n",
        "              run_condition.append(True)\n",
        "            else :\n",
        "              run_condition.append(False)\n",
        "\n",
        "        # print(bestk_tot)\n",
        "\n",
        "    final_words = []\n",
        "    best_word = []\n",
        "    best = 0.0\n",
        "    for i in range(k) :\n",
        "      a = bestk_tot[i]\n",
        "      b = bestk_prob[i]\n",
        "      final_words += [a]\n",
        "      if b > best :\n",
        "        best_word = [a]\n",
        "\n",
        "    if getall :\n",
        "      return (tk.decode(final_words,'output'),best_word)\n",
        "    else :\n",
        "      return final_words,best_word"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpJm8eZrt5mA"
      },
      "source": [
        "class rnn():\n",
        "\n",
        "  def __init__(self, params):\n",
        "    \n",
        "    num_encode_layers = params['num_encode_layers']\n",
        "    num_decode_layers = params['num_decode_layers']\n",
        "    data_dict = params['data_dict']\n",
        "    in_size = params['data_dict']['in_size']\n",
        "    out_size = params['data_dict']['out_size']\n",
        "    cell_type = params['cell_type']\n",
        "    dropout = params['dropout']\n",
        "    embed_size = params['embed_size']\n",
        "    rep_size = params['rep_size']\n",
        "        \n",
        "    ###################### ENCODER NETWORK ######################\n",
        "    \n",
        "    encoder_inputs = Input(shape=(None,))\n",
        "    x = Embedding(in_size, embed_size ,mask_zero=True)(encoder_inputs)\n",
        "\n",
        "    encoder_layers = []\n",
        "    \n",
        "    for j in range(num_encode_layers-1) :   \n",
        "      curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_sequences=True)\n",
        "      encoder_layers.append(curr_layer)\n",
        "      x = curr_layer(x)\n",
        "\n",
        "    curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_state=True)\n",
        "    encoder_layers.append(curr_layer)\n",
        "    x, *encoder_states = curr_layer(x)\n",
        "\n",
        "    ###################### DECODER NETWORK ######################\n",
        "\n",
        "    decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "    decoder_embedding =  Embedding(out_size, embed_size, mask_zero=True)\n",
        "    x = decoder_embedding(decoder_inputs)\n",
        "\n",
        "    decoder_layers = []    \n",
        "    \n",
        "    for j in range(num_decode_layers) :\n",
        "      curr_layer = getattr(layers, cell_type)(rep_size,dropout=dropout,return_state=True, return_sequences=True)\n",
        "      decoder_layers.append(curr_layer)\n",
        "      x, *decoder_states = curr_layer(x, initial_state=encoder_states)\n",
        "\n",
        "    decoder_dense = Dense(units=out_size, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(x)\n",
        "\n",
        "    # define the model that will turn `encoder_inputs` & `decoder_inputs` into `decoder_outputs`\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ????? \n",
        "    self.model = model\n",
        "    self.encoder_inputs = encoder_inputs\n",
        "    self.encoder_layers = encoder_layers\n",
        "    self.decoder_inputs = decoder_inputs\n",
        "    self.decoder_embedding = decoder_embedding\n",
        "    self.decoder_layers = decoder_layers\n",
        "    self.decoder_dense = decoder_dense\n",
        "    self.encoder_states = encoder_states\n",
        "    self.params = params\n",
        "    self.details = {\n",
        "        'model' : self.model,\n",
        "        'encoder_inputs' : self.encoder_inputs,\n",
        "        'encoder_layers' :self.encoder_layers ,\n",
        "        'decoder_inputs' :self.decoder_inputs ,\n",
        "        'decoder_embedding' : self.decoder_embedding,\n",
        "        'decoder_layers' : self.decoder_layers,\n",
        "        'decoder_dense' : self.decoder_dense,\n",
        "        'encoder_states' : self.encoder_states ,\n",
        "        'params' :self.params,\n",
        "    }\n",
        "\n",
        "  def compile_and_fit(self, data_dict, params):\n",
        "\n",
        "    # compiling the model\n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "    \n",
        "    # printing the summary of the model\n",
        "    summary = self.model.summary()\n",
        "\n",
        "    # plotting the model figure\n",
        "    plot = plot_model(self.model, show_shapes=True)\n",
        "    \n",
        "    # total training samples\n",
        "    train_samples = len(data_dict['train']['df'])\n",
        "\n",
        "    # total validation samples\n",
        "    val_samples = len(data_dict['val']['df'])    \n",
        "    \n",
        "    # batch size\n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    # number of epochs\n",
        "    num_epochs = params['num_epochs']\n",
        "\n",
        "    # steps per epoch\n",
        "    steps_per_epoch = ceil(train_samples/batch_size) - 1\n",
        "\n",
        "    # training the model\n",
        "    run_details = self.model.fit_generator(generator = data_dict['train']['batch'],\n",
        "                                           steps_per_epoch = steps_per_epoch,\n",
        "                                           epochs=num_epochs,\n",
        "                                           # callbacks=[\n",
        "                                           # BeamSearchCallBack(self.details,data_dict['val'],data_dict['tokenizer'],data_dict['out_size'],num_val=num_val_samples,beam=beam),\n",
        "                                                        # wandb.keras.WandbCallback()\n",
        "                                                        # ],\n",
        "                                           validation_data = data_dict['val']['batch'], \n",
        "                                           validation_steps = val_samples//batch_size\n",
        "                                          )\n",
        "\n",
        "    return {\n",
        "        'run_details' : run_details\n",
        "    }\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmfE-kGOvjk8",
        "outputId": "cc34dcbe-6dd1-4ccb-b002-e0a431215249"
      },
      "source": [
        "10/4"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0m1582SU6W8"
      },
      "source": [
        "class rnn_second() :\n",
        "  def __init__(self, details) :\n",
        "\n",
        "    # copying required details\n",
        "    self.details = details\n",
        "\n",
        "    # copying decoder state input\n",
        "    decoder_state_input = self.details['encoder_states']\n",
        "\n",
        "    decoder_inputs = Input(shape=(1,))\n",
        "\n",
        "    # copying hidden representation size\n",
        "    rep_size = self.details['params']['rep_size']\n",
        "\n",
        "    # copying decoder inputs\n",
        "    decoder_inputs = self.details['decoder_inputs']\n",
        "\n",
        "    # the decoder model\n",
        "    x = self.details['decoder_embedding'](decoder_inputs)\n",
        "  \n",
        "    all_outputs = []\n",
        "    for _ in range(self.details['params']['data_dict']['max_target_length']) :\n",
        "        for layer in self.details['decoder_layers'] :\n",
        "            x, *decoder_states = layer(x, initial_state=decoder_state_input)\n",
        "\n",
        "        x = self.details['decoder_dense'](x)\n",
        "\n",
        "        # appending the softmax output\n",
        "        all_outputs.append(x)\n",
        "\n",
        "        # taking the argmax to feed into the next time step\n",
        "        x = tf.math.argmax(x, 2)  \n",
        "        x = self.details['decoder_embedding'](x)\n",
        "        \n",
        "        # decoder state input for the next time step\n",
        "        decoder_state_input = decoder_states\n",
        "\n",
        "    ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ?????\n",
        "    # where do we evaluate stop condition?\n",
        "\n",
        "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    model = Model([self.details['encoder_inputs'], decoder_inputs], decoder_outputs)\n",
        "    self.model = model\n",
        "\n",
        "  def compile_and_fit(self,data_dict,params) :\n",
        "\n",
        "    # compiling the model\n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "     # printing the summary of the model   \n",
        "    summary = self.model.summary()\n",
        "\n",
        "    # plotting the model figure\n",
        "    plot = plot_model(self.model, show_shapes=True)\n",
        "    \n",
        "    # total training samples\n",
        "    train_samples = len(data_dict['train']['df'])\n",
        "\n",
        "    # total validation samples \n",
        "    val_samples = len(data_dict['val']['df'])\n",
        "\n",
        "    # batch size   \n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    # number of epochs\n",
        "    num_epochs = params['num_epochs_2']\n",
        "\n",
        "    # training the model\n",
        "    run_details = self.model.fit_generator(generator = data_dict['train']['batch_greedy'],\n",
        "                                            steps_per_epoch = train_samples//batch_size,\n",
        "                                            epochs=num_epochs,)\n",
        "                                            # callbacks=[\n",
        "                                                      # BeamSearchCallBack(self.details,data_dict['val'],data_dict['tokenizer'],data_dict['out_size'],num_val=num_val_samples,beam=beam),\n",
        "                                                      # wandb.keras.WandbCallback()\n",
        "                                                      # ],\n",
        "                                            # validation_data = data_dict['val']['batch_greedy'],\n",
        "                                            # validation_steps = val_samples//batch_size)\n",
        "   \n",
        "    return {\n",
        "        'run_details' : run_details\n",
        "    }\n",
        "\n",
        "  def evaluate(self, data_dict) :\n",
        "\n",
        "    # test batch generator\n",
        "    test_gen = data_dict['val']['batch_greedy']\n",
        "    \n",
        "    # number of test samples\n",
        "    test_samples = len(data_dict['val']['df'])\n",
        "  \n",
        "    batch_size=32\n",
        "\n",
        "    num_hits = 0\n",
        "    \n",
        "    for _ in range(test_samples//batch_size) :\n",
        "      (a,b),c = next(test_gen)\n",
        "      l1 = data_dict['tokenizer'].decode(np.argmax(c, axis=2), mode='output')\n",
        "      out = self.model.predict([a,b])\n",
        "      out = np.argmax(out,axis=2)\n",
        "      ##### \n",
        "      l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
        "      num_hits += np.sum(np.array(l1)==np.array(l2))\n",
        "    \n",
        "    print(\"Test Acc \", num_hits/test_samples)\n",
        "    wandb.log({\"Final Test Accuracy \":  num_hits/test_samples})"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDLMoTWfBn86"
      },
      "source": [
        "class tools:\n",
        "  def init_params(config,data_dict):\n",
        "  \n",
        "    # returning parameters\n",
        "    params = {\n",
        "        'num_encode_layers' : config.num_encode_layers,\n",
        "        'num_decode_layers' : config.num_decode_layers,\n",
        "        'cell_type' : config.cell_type,\n",
        "        'rep_size' : config.rep_size,\n",
        "        'embed_size' : config.embed_size,\n",
        "        'dropout' : config.dropout,\n",
        "        'num_epochs' : config.num_epochs,\n",
        "        'num_epochs_2' : config.num_epochs_2,\n",
        "        'data_dict' : data_dict,\n",
        "        'batch_size' : config.batch_size\n",
        "    }\n",
        "    return params"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AWE1lLSDDXh"
      },
      "source": [
        "# sweep configuration\n",
        "sweep_config = {\n",
        "    'method' : 'bayes',\n",
        "    'metric' : {\n",
        "        'name' : 'val_acc',\n",
        "        'goal' : 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'cell_type' : {\n",
        "            'values': ['LSTM', 'GRU', 'SimpleRNN']  \n",
        "        },\n",
        "        'embed_size': {\n",
        "            'values': [10]\n",
        "        },\n",
        "        'rep_size': {\n",
        "            'values': [32, 64, 128, 256]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0, 0.2, 0.4]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32]\n",
        "        },\n",
        "        'num_epochs': {\n",
        "            'values': [25]\n",
        "        },\n",
        "        'num_epochs_2' : {\n",
        "            'values': [25]\n",
        "        },\n",
        "        'num_encode_layers': {\n",
        "            'values': [1, 2, 4]\n",
        "        },\n",
        "        'num_decode_layers': {\n",
        "            'values': [1, 2, 4]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaeqg-Otpnbo"
      },
      "source": [
        "# sweep configuration\n",
        "sweep_config = {\n",
        "    'method' : 'bayes',\n",
        "    'metric' : {\n",
        "        'name' : 'val_acc',\n",
        "        'goal' : 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'cell_type' : {\n",
        "            'values': ['LSTM']  \n",
        "        },\n",
        "        'embed_size': {\n",
        "            'values': [10]\n",
        "        },\n",
        "        'rep_size': {\n",
        "            'values': [32]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32]\n",
        "        },\n",
        "        'num_epochs': {\n",
        "            'values': [1]\n",
        "        },\n",
        "        'num_epochs_2' : {\n",
        "            'values': [1]\n",
        "        },\n",
        "        'num_encode_layers': {\n",
        "            'values': [1]\n",
        "        },\n",
        "        'num_decode_layers': {\n",
        "            'values': [1]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqDamLUoDQWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c78bc5-41ad-42f1-c74c-c6cf72a66acb"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='dakshina_v2')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: e7je1lu4\n",
            "Sweep URL: https://wandb.ai/ramkamal/dakshina_v2/sweeps/e7je1lu4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez3f-pjxDTU8"
      },
      "source": [
        "class sweep_module:\n",
        "  @staticmethod\n",
        "  def train(config=None):\n",
        "\n",
        "    with wandb.init(config):\n",
        "      \n",
        "      # copying the config \n",
        "      config = wandb.config\n",
        " \n",
        "      # naming the run\n",
        "      # wandb.run.name = 'fil:'+str(config['num_filters_'])+'_type:'+config['type_of_filters'][0]+'_aug:'+str(config['augmentation'])[0]+'_dro:'+str(config['dropout'])[0]\n",
        "      wandb.run.name = 'typ:'+config['cell_type'][:4]+ '_' + 'emb:'+str(config['embed_size'])+ '_' + 'enc:' + str(config['num_encode_layers'])+ '_' + 'dec:'+str(config['num_decode_layers'])\n",
        "      \n",
        "      # returning the data dictionairy\n",
        "      ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ?????\n",
        "      data_dict = return_data_dict(batch_size=config.batch_size)\n",
        "\n",
        "      # copying the parameters\n",
        "      params = tools.init_params(config,data_dict)\n",
        "\n",
        "      # creating and training the first model\n",
        "      network = rnn(params)\n",
        "      run_details = network.compile_and_fit(data_dict, params)\n",
        "\n",
        "      # creating and training/ fine-tuning the second model\n",
        "      rnn_2 = rnn_second(network.details)\n",
        "      run_details_2 = rnn_2.compile_and_fit(data_dict,params)\n",
        "      \n",
        "      ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ?????\n",
        "      rnn_2.evaluate(data_dict)\n",
        "\n",
        "      if os.path.isdir('/content/wandb'): \n",
        "        shutil.rmtree('/content/wandb')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6QBd1gJDV-R"
      },
      "source": [
        "# sweep_id = '7g0porer'"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCq49t4zDZod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cd5217d19a284d18a3db587e3fffd999",
            "7b6eb279be274a80bca9b66aacfddbf1",
            "a55cb341747b4b02ab5345d6f045e1dd",
            "5853a888dd0e46a1b994ef5984b3165d",
            "8056cbc1cd4d4e338c1af5240b1dba9c",
            "78474c330f6749799a8318801030d77b",
            "756e6d3dd744478ea55ad37b66bafe31",
            "ea5f53b17d424f99bf5bbd374c09fb72",
            "166781fe39c04d38b4a37bdfe864504f",
            "7b22fb3144f64b3b9a2fa939fdc96d0a",
            "fe83fdc81ffb41a68a8775bd5f123c0e",
            "710d2d82fe034c1b9675d248fb78299c",
            "9d9474b725434928bd042538aaa3953f",
            "282873a718224017a015e0b686fd3646",
            "b38688d330264a9fb831757ed0726c30",
            "0dc7735232ae41bf9a1e8c1dac1ac72d"
          ]
        },
        "outputId": "af6b5e38-08a2-4d34-d780-e6c63c5f2de1"
      },
      "source": [
        "# performing the sweep\n",
        "wandb.agent(sweep_id, sweep_module.train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0nl9vu0g with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decode_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encode_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs_2: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trep_size: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">rare-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/sweeps/sdxo2ij7\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/sweeps/sdxo2ij7</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/runs/0nl9vu0g\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/runs/0nl9vu0g</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210511_153217-0nl9vu0g</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 10)     280         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10)     570         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 32), (None,  5504        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 32), ( 5504        embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 57)     1881        lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 13,739\n",
            "Trainable params: 13,739\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1/3 [=========>....................] - ETA: 18s - loss: 1.9325 - acc: 0.0154"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2967<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd5217d19a284d18a3db587e3fffd999",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210511_153217-0nl9vu0g/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210511_153217-0nl9vu0g/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">rare-sweep-1</strong>: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/runs/0nl9vu0g\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/runs/0nl9vu0g</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Run 0nl9vu0g errored: IndexError('index 17 is out of bounds for axis 1 with size 17')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 0nl9vu0g errored: IndexError('index 17 is out of bounds for axis 1 with size 17')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2i37643o with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decode_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encode_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs_2: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trep_size: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">good-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/sweeps/sdxo2ij7\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/sweeps/sdxo2ij7</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/runs/2i37643o\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/runs/2i37643o</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210511_153239-2i37643o</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 10)     290         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10)     580         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 32), (None,  5504        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 32), ( 5504        embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 58)     1914        lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 13,792\n",
            "Trainable params: 13,792\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 9s 1s/step - loss: 1.8671 - acc: 0.0371 - val_loss: 1.7371 - val_acc: 0.0715\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 10)     290         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10)     580         input_2[0][0]                    \n",
            "                                                                 tf.math.argmax[0][0]             \n",
            "                                                                 tf.math.argmax_1[0][0]           \n",
            "                                                                 tf.math.argmax_2[0][0]           \n",
            "                                                                 tf.math.argmax_3[0][0]           \n",
            "                                                                 tf.math.argmax_4[0][0]           \n",
            "                                                                 tf.math.argmax_5[0][0]           \n",
            "                                                                 tf.math.argmax_6[0][0]           \n",
            "                                                                 tf.math.argmax_7[0][0]           \n",
            "                                                                 tf.math.argmax_8[0][0]           \n",
            "                                                                 tf.math.argmax_9[0][0]           \n",
            "                                                                 tf.math.argmax_10[0][0]          \n",
            "                                                                 tf.math.argmax_11[0][0]          \n",
            "                                                                 tf.math.argmax_12[0][0]          \n",
            "                                                                 tf.math.argmax_13[0][0]          \n",
            "                                                                 tf.math.argmax_14[0][0]          \n",
            "                                                                 tf.math.argmax_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 32), (None,  5504        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 32), ( 5504        embedding_1[1][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "                                                                 embedding_1[2][0]                \n",
            "                                                                 lstm_1[1][1]                     \n",
            "                                                                 lstm_1[1][2]                     \n",
            "                                                                 embedding_1[3][0]                \n",
            "                                                                 lstm_1[2][1]                     \n",
            "                                                                 lstm_1[2][2]                     \n",
            "                                                                 embedding_1[4][0]                \n",
            "                                                                 lstm_1[3][1]                     \n",
            "                                                                 lstm_1[3][2]                     \n",
            "                                                                 embedding_1[5][0]                \n",
            "                                                                 lstm_1[4][1]                     \n",
            "                                                                 lstm_1[4][2]                     \n",
            "                                                                 embedding_1[6][0]                \n",
            "                                                                 lstm_1[5][1]                     \n",
            "                                                                 lstm_1[5][2]                     \n",
            "                                                                 embedding_1[7][0]                \n",
            "                                                                 lstm_1[6][1]                     \n",
            "                                                                 lstm_1[6][2]                     \n",
            "                                                                 embedding_1[8][0]                \n",
            "                                                                 lstm_1[7][1]                     \n",
            "                                                                 lstm_1[7][2]                     \n",
            "                                                                 embedding_1[9][0]                \n",
            "                                                                 lstm_1[8][1]                     \n",
            "                                                                 lstm_1[8][2]                     \n",
            "                                                                 embedding_1[10][0]               \n",
            "                                                                 lstm_1[9][1]                     \n",
            "                                                                 lstm_1[9][2]                     \n",
            "                                                                 embedding_1[11][0]               \n",
            "                                                                 lstm_1[10][1]                    \n",
            "                                                                 lstm_1[10][2]                    \n",
            "                                                                 embedding_1[12][0]               \n",
            "                                                                 lstm_1[11][1]                    \n",
            "                                                                 lstm_1[11][2]                    \n",
            "                                                                 embedding_1[13][0]               \n",
            "                                                                 lstm_1[12][1]                    \n",
            "                                                                 lstm_1[12][2]                    \n",
            "                                                                 embedding_1[14][0]               \n",
            "                                                                 lstm_1[13][1]                    \n",
            "                                                                 lstm_1[13][2]                    \n",
            "                                                                 embedding_1[15][0]               \n",
            "                                                                 lstm_1[14][1]                    \n",
            "                                                                 lstm_1[14][2]                    \n",
            "                                                                 embedding_1[16][0]               \n",
            "                                                                 lstm_1[15][1]                    \n",
            "                                                                 lstm_1[15][2]                    \n",
            "                                                                 embedding_1[17][0]               \n",
            "                                                                 lstm_1[16][1]                    \n",
            "                                                                 lstm_1[16][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 58)     1914        lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax (TFOpLambda)     (None, None)         0           dense[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_1 (TFOpLambda)   (None, None)         0           dense[2][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_2 (TFOpLambda)   (None, None)         0           dense[3][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_3 (TFOpLambda)   (None, None)         0           dense[4][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_4 (TFOpLambda)   (None, None)         0           dense[5][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_5 (TFOpLambda)   (None, None)         0           dense[6][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_6 (TFOpLambda)   (None, None)         0           dense[7][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_7 (TFOpLambda)   (None, None)         0           dense[8][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_8 (TFOpLambda)   (None, None)         0           dense[9][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_9 (TFOpLambda)   (None, None)         0           dense[10][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_10 (TFOpLambda)  (None, None)         0           dense[11][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_11 (TFOpLambda)  (None, None)         0           dense[12][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_12 (TFOpLambda)  (None, None)         0           dense[13][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_13 (TFOpLambda)  (None, None)         0           dense[14][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_14 (TFOpLambda)  (None, None)         0           dense[15][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_15 (TFOpLambda)  (None, None)         0           dense[16][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, None, 58)     0           dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[17][0]                     \n",
            "==================================================================================================\n",
            "Total params: 13,792\n",
            "Trainable params: 13,792\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "3/3 [==============================] - 59s 111ms/step - loss: 1.8647 - acc: 0.0449\n",
            "Test Acc  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3019<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "166781fe39c04d38b4a37bdfe864504f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Run 2i37643o errored: Exception('The wandb backend process has shutdown')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2i37643o errored: Exception('The wandb backend process has shutdown')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zyu3arye with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decode_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encode_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs_2: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trep_size: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">pleasant-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/sweeps/sdxo2ij7\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/sweeps/sdxo2ij7</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/runs/zyu3arye\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/runs/zyu3arye</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210511_153433-zyu3arye</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 10)     280         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10)     570         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 32), (None,  5504        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 32), ( 5504        embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 57)     1881        lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 13,739\n",
            "Trainable params: 13,739\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 9s 1s/step - loss: 1.8032 - acc: 0.0265 - val_loss: 1.5517 - val_acc: 0.1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBotvdIuDczo"
      },
      "source": [
        "# Run One Model separate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBfaOoDTt-Zd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a484c7e2ab4242bfaae533b4f8646f9c",
            "b9daf2180bcb4347908774f93def7890",
            "41e290870b0f43b791ca65b522404644",
            "e258e417b4a5457dbef9937be633e502",
            "e8cbac7ff0c048fc924e2240c51203e6",
            "1f41529fc34a41dc87b1e8d8611a37a8",
            "8ff908fdafaa4c05a49e513099b9fcf3",
            "ff8e0de9c1b1474c910829770584850b"
          ]
        },
        "outputId": "57b986ad-7529-492d-e5ba-0ca8e96aeaad"
      },
      "source": [
        "params = {\n",
        "    'num_encode_layers' : 2,\n",
        "    'num_decode_layers' : 1,\n",
        "    'cell_type' : 'LSTM', \n",
        "    'rep_size' : 100,\n",
        "    'embed_size' : 10,\n",
        "    'dropout' : 0,\n",
        "    'num_epochs' : 1,\n",
        "    'num_epochs_2' : 1,\n",
        "    'data_dict' : data_dict,\n",
        "    'batch_size' : 32\n",
        "}\n",
        "network = rnn(params)\n",
        "plot_model(network.model, show_shapes=True)\n",
        "network.compile_and_fit(data_dict, params)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3092<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a484c7e2ab4242bfaae533b4f8646f9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210511_153433-zyu3arye/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210511_153433-zyu3arye/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">pleasant-sweep-3</strong>: <a href=\"https://wandb.ai/ramkamal/dakshina_v2/runs/zyu3arye\" target=\"_blank\">https://wandb.ai/ramkamal/dakshina_v2/runs/zyu3arye</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 10)     290         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 100)    44400       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10)     500         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 100), (None, 80400       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 100),  44400       embedding_1[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 50)     5050        lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 175,040\n",
            "Trainable params: 175,040\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-fa23f35e8b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-bacaf678fac6>\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[0;34m(self, data_dict, params)\u001b[0m\n\u001b[1;32m    106\u001b[0m                                                         \u001b[0;31m# ],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                            \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                                            \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                                           )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m                 ))\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'constants'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   def call(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m           (last_output, outputs, new_h, new_c,\n\u001b[0;32m-> 1270\u001b[0;31m            runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[0;31m# Call the normal LSTM impl and register the CuDNN impl function. The\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1400\u001b[0m       input_length=(sequence_lengths\n\u001b[1;32m   1401\u001b[0m                     if sequence_lengths is not None else timesteps),\n\u001b[0;32m-> 1402\u001b[0;31m       zero_output_for_mask=zero_output_for_mask)\n\u001b[0m\u001b[1;32m   1403\u001b[0m   return (last_output, outputs, new_states[0], new_states[1],\n\u001b[1;32m   1404\u001b[0m           _runtime(_RUNTIME_CPU))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4501\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4502\u001b[0;31m     \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_time_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4501\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4502\u001b[0;31m     \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_time_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1217\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10477\u001b[0m                         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10478\u001b[0m                         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10479\u001b[0;31m                         shrink_axis_mask=shrink_axis_mask, name=name)\n\u001b[0m\u001b[1;32m  10480\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10481\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    375\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;31m# Perform input type inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6505\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6506\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6507\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6508\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Issue 19330: ensure context manager instances have good docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__doc__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggdPRy5NOA03"
      },
      "source": [
        "rnn_2 = rnn_second(network.details)\n",
        "run_details_2 = rnn_2.compile_and_fit(data_dict, params)\n",
        "rnn_2.evaluate(data_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utq4Wtvg85ms"
      },
      "source": [
        "pprint(network.details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMHkTtHSTBmD"
      },
      "source": [
        "plot_model(rnn_2.model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YHfKL5_YTKk"
      },
      "source": [
        "# !pip install editdistance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtqXB5sXLLYV"
      },
      "source": [
        "test_gen = data_dict['test']['batch_greedy']\n",
        "test_samples = len(data_dict['test']['df'])\n",
        "batch_size=32\n",
        "acc = 0\n",
        "for _ in range(test_samples//batch_size) :\n",
        "  (a,b),c = next(test_gen)\n",
        "  l1 = data_dict['tokenizer'].decode(np.argmax(c,axis=2),mode='output')\n",
        "  out = rnn_2.model.predict([a,b])\n",
        "  out = np.argmax(out,axis=2)\n",
        "  l2 = data_dict['tokenizer'].decode(out,mode='output')\n",
        "  acc += np.sum(np.array(l1)==np.array(l2))\n",
        "\n",
        "print(\"Val Accuracy : \",acc/test_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yd31nMSSdxh"
      },
      "source": [
        "l1 = ['andiranchi', 'ake', 'irangula', 'ndha', 'ulakhatee', 'alal', 'urvajanche', 'urunath', 'amjhunga', 'maging', 'tutya', 'stitvachi', 'nudit', 'addhtipeksha', 'aam', 'uloos', 'eneth', 'eevandan', 'ndreas', 'ugnata', 'alvon', 'stitvatil', 'anchyabaddal', 'otipeksha', 'umak', 'haktte', 'ubhati', 'hhavi', 'ang', 'azipur', 'illi', 'hodi']\n",
        "l2 = ['andyyaachi', 'ake', 'irnngda', 'ndha', 'ulakatii', 'alalt', 'urvajaache', 'urunach', 'amaaaaagt', 'minangt', 'tutya', 'sttyaache', 'nduit', 'adhititaassh', 'amttt', 'ulustt', 'anich', 'ivanaaa', 'ndyiiist', 'uganta', 'alvoo', 'stttaaaii', 'anthaaaaaadd', 'otipissha', 'umak', 'hakttt', 'ubhate', 'hhali', 'ang', 'ajiprrt', 'hlll', 'hodit']\n",
        "np.sum(np.array(l1)==np.array(l2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OzbbHG-33UB"
      },
      "source": [
        "from keras.layers import Lambda\n",
        "from keras import backend as K\n",
        "num_encoder_tokens = data_dict['in_size']\n",
        "latent_dim = 256\n",
        "num_decoder_tokens = data_dict['out_size']\n",
        "batch_size=32\n",
        "epochs=20\n",
        "val_samples = 4981\n",
        "train_samples = 45444\n",
        "\n",
        "# The first part is unchanged\n",
        "encoder_inputs1 = Input(shape=(None,))\n",
        "encoder_inputs=Embedding(data_dict['in_size'], 64,mask_zero=True)(encoder_inputs1)\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, which will only process one timestep at a time.\n",
        "decoder_inputs1 = Input(shape=(1,))\n",
        "decoder_embedding =  Embedding(data_dict['out_size'], 64,mask_zero=True)\n",
        "decoder_inputs = decoder_embedding(decoder_inputs1)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "\n",
        "all_outputs = []\n",
        "inputs = decoder_inputs\n",
        "for _ in range(23):\n",
        "    # Run the decoder on one timestep\n",
        "    outputs, state_h, state_c = decoder_lstm(inputs,\n",
        "                                             initial_state=states)\n",
        "    outputs = decoder_dense(outputs)\n",
        "    # Store the current prediction (we will concatenate all predictions later)\n",
        "    all_outputs.append(outputs)\n",
        "    # Reinject the outputs as inputs for the next loop iteration\n",
        "    # as well as update the states\n",
        "    outputs1 = tf.math.argmax(outputs,2)\n",
        "    inputs = decoder_embedding(outputs1)\n",
        "    states = [state_h, state_c]\n",
        "\n",
        "# Concatenate all predictions\n",
        "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "\n",
        "# Define and compile model as previously\n",
        "model = Model([encoder_inputs1, decoder_inputs1], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Prepare decoder input data that just contains the start character\n",
        "# Note that we could have made it a constant hard-coded in the model\n",
        "\n",
        "# # Train model as previously\n",
        "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           validation_split=0.2)\n",
        "\n",
        "model.fit_generator(generator = data_dict['train']['batch_greedy'],\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = data_dict['val']['batch_greedy'],\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjtrtMiHDbiy"
      },
      "source": [
        "generator=data_dict['test']['batch_greedy']\n",
        "(a,b),c = next(generator)\n",
        "print(a,b,np.argmax(c,axis=2))\n",
        "out = model.predict([a,b])\n",
        "out = np.argmax(out,axis=2)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7o9Y_NBzelI"
      },
      "source": [
        "plot_model(model,to_file='model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqiICTfUid26"
      },
      "source": [
        "# Attention?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glswCuYJlume"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS-7MTO4lyP7"
      },
      "source": [
        "from tensorflow.python.keras.layers import Input, GRU, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.python.keras.models import Model"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NWc0APTli6i"
      },
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        print(input_shape[0][2],input_shape[1][2])\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7drOpPqmltW3",
        "outputId": "1cca1de1-f23d-4df1-d13d-eca54b5c198c"
      },
      "source": [
        "def define_nmt(hidden_size, batch_size, max_source_length, source_vsize, max_target_length, target_vsize):\n",
        "\n",
        "    print(\"max_source_length, source_vsize, max_target_length, target_vsize\")\n",
        "    print(max_source_length, source_vsize, max_target_length, target_vsize)\n",
        "    # Define an input sequence and process it\n",
        "    if batch_size:\n",
        "        encoder_inputs = Input(batch_shape=(batch_size, max_source_length, source_vsize))\n",
        "        decoder_inputs = Input(batch_shape=(batch_size, max_target_length - 1, target_vsize))\n",
        "    else:\n",
        "        encoder_inputs = Input(shape=(None,))\n",
        "        decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "    # Encoder GRU\n",
        "    encoder_emb = Embedding(data_dict['in_size'], source_vsize, input_length=max_source_length)\n",
        "    temp1 = encoder_emb(encoder_inputs)\n",
        "    encoder_gru = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
        "    encoder_out, *encoder_state = encoder_gru(temp1)\n",
        "    \n",
        "    # Set up the decoder GRU, using `encoder_states` as initial state\n",
        "    decoder_emb = Embedding(data_dict['out_size'], target_vsize, input_length=max_target_length)\n",
        "    temp2 = decoder_emb(decoder_inputs)\n",
        "    decoder_gru = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
        "    decoder_out, *decoder_state = decoder_gru(temp2, initial_state=encoder_state)\n",
        "\n",
        "    # Attention layer\n",
        "    attn_layer = AttentionLayer()\n",
        "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
        "\n",
        "    # Concat attention input and decoder GRU output\n",
        "    decoder_concat_input = Concatenate(axis=-1)([decoder_out, attn_out])\n",
        "\n",
        "    # Dense layer\n",
        "    dense = Dense(target_vsize, activation='softmax')\n",
        "    dense_time = TimeDistributed(dense)\n",
        "    decoder_pred = dense_time(decoder_concat_input)\n",
        "\n",
        "    # Full model\n",
        "    full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
        "    full_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "    full_model.summary()\n",
        "\n",
        "    \"\"\" Inference model \"\"\"\n",
        "    batch_size = 1\n",
        "\n",
        "    \"\"\" Encoder (Inference) model \"\"\"\n",
        "    encoder_inf_inputs = Input(shape=(max_source_length,))\n",
        "    temp3 = encoder_emb(encoder_inf_inputs)\n",
        "    encoder_inf_out, *encoder_inf_state = encoder_gru(temp3)\n",
        "    encoder_model = Model(inputs=encoder_inf_inputs, outputs=[encoder_inf_out, encoder_inf_state])\n",
        "\n",
        "    \"\"\" Decoder (Inference) model \"\"\"\n",
        "    decoder_inf_inputs = Input(batch_shape=(batch_size, 1))\n",
        "    encoder_inf_states = Input(batch_shape=(batch_size, None, hidden_size))\n",
        "    decoder_init_stateh = Input(batch_shape=(batch_size, hidden_size))\n",
        "    decoder_init_statec = Input(batch_shape=(batch_size, hidden_size))\n",
        "    decoder_init_state = [decoder_init_stateh,decoder_init_statec]\n",
        "    temp = decoder_emb(decoder_inf_inputs)\n",
        "    decoder_inf_out, *decoder_inf_state = decoder_gru(temp, initial_state=decoder_init_state)\n",
        "    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
        "    decoder_inf_concat = Concatenate(axis=-1)([decoder_inf_out, attn_inf_out])\n",
        "    decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
        "    decoder_model = Model(inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
        "                          outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state])\n",
        "\n",
        "    return full_model, encoder_model, decoder_model\n",
        "    # return full_model\n",
        "\n",
        "\n",
        "m1, m2, m3 = define_nmt(256, None, None, 40, None, 40)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_source_length, source_vsize, max_target_length, target_vsize\n",
            "None 40 None 40\n",
            "256 256\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_31 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_32 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, None, 40)     1160        input_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, None, 40)     2240        input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  [(None, None, 256),  304128      embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  [(None, None, 256),  304128      embedding_11[0][0]               \n",
            "                                                                 lstm_11[0][1]                    \n",
            "                                                                 lstm_11[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer_4 (AttentionLay ((None, None, 256),  131328      lstm_11[0][0]                    \n",
            "                                                                 lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, None, 512)    0           lstm_12[0][0]                    \n",
            "                                                                 attention_layer_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistrib (None, None, 56)     28728       concatenate_8[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 771,712\n",
            "Trainable params: 771,712\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "dJlOmqBwpWAS",
        "outputId": "998d794d-d4dc-4b59-962f-bcceb970767c"
      },
      "source": [
        "plot_model(m1, show_shapes=True)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0QSXRudzevC",
        "outputId": "466759d5-928a-4940-c579-d4c7ef92a799"
      },
      "source": [
        "batch_size=32\n",
        "epochs=10\n",
        "val_samples = len(data_dict['val']['df'])\n",
        "train_samples = len(data_dict['train']['df'])\n",
        "\n",
        "m1.fit_generator(generator = data_dict['train']['batch'],\n",
        "                 steps_per_epoch=train_samples//batch_size,\n",
        "                 epochs=epochs,\n",
        "                 validation_data=data_dict['val']['batch'],\n",
        "                 validation_steps=val_samples//batch_size\n",
        "                 )"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fc8092ceef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 5s 465ms/step - loss: 1.2274 - acc: 0.0169 - val_loss: 1.5572 - val_acc: 0.0526\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 1.5227 - acc: 0.0450 - val_loss: 1.5325 - val_acc: 0.0526\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 1.6560 - acc: 0.0526 - val_loss: 1.4289 - val_acc: 0.0526\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.8058 - acc: 0.0277 - val_loss: 1.3447 - val_acc: 0.0526\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 1.0134 - acc: 0.0422 - val_loss: 1.3273 - val_acc: 0.0515\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 1.2655 - acc: 0.0542 - val_loss: 1.3197 - val_acc: 0.0543\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 1.3919 - acc: 0.0701 - val_loss: 1.3034 - val_acc: 0.0641\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.7518 - acc: 0.0365 - val_loss: 1.2993 - val_acc: 0.0603\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.9737 - acc: 0.0485 - val_loss: 1.2979 - val_acc: 0.0641\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 1.2321 - acc: 0.0615 - val_loss: 1.3017 - val_acc: 0.0587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc8032d1790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "namCfz0sFqRx"
      },
      "source": [
        "acc = 0\n",
        "generator = data_dict['test']['batch_1']\n",
        "tk = data_dict['tokenizer']\n",
        "for j in tqdm(range(4967)) :\n",
        "  (a,b),c = next(generator)\n",
        "  g = [[1] + list(np.argmax(c,axis=-1)[0])]\n",
        "  enc_outs, enc_last_state = m2.predict(a)\n",
        "  dec_state = enc_last_state\n",
        "  attention_weights = []\n",
        "  word = [1]\n",
        "  for i in range(23):\n",
        "\n",
        "      dec_out, attention, dec_state = m3.predict([enc_outs, dec_state, b])\n",
        "      dec_ind = np.argmax(dec_out, axis=-1)\n",
        "\n",
        "      word.append(dec_ind[0][0])\n",
        "      b = dec_ind\n",
        "      attention_weights.append((dec_ind, attention))\n",
        "      if dec_ind[0][0] == 2 :\n",
        "        break\n",
        "  str1 = tk.decode(g,mode='output')\n",
        "  str2 = tk.decode([word],mode='output')\n",
        "  if str1 == str2 :\n",
        "    acc += 1\n",
        "\n",
        "print(acc/4967)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItqoHkE2JTO1"
      },
      "source": [
        "# Romanized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O8dFDOHGbEb"
      },
      "source": [
        "ta_rom = dict()\n",
        "ta_rom['rejoined'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv', sep='\\t', header=None, error_bad_lines=False)\n",
        "ta_rom['rejoined_aligned_cased'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.cased_nopunct.tsv', sep='\\t', header=None, error_bad_lines=False) \n",
        "ta_rom['rejoined_aligned'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.tsv', sep='\\t', header=None, error_bad_lines=False)\n",
        "ta_rom['split'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.tsv', sep='\\t', header=None, error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-WGvG_RJqsr"
      },
      "source": [
        "list(ta_rom['rejoined'].iloc[0, 0])[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p75rYpZkNCJV"
      },
      "source": [
        "ta_rom['rejoined_aligned_cased']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E9hQuQMULO"
      },
      "source": [
        "ta_rom['rejoined_aligned']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yAnW0rAKDY5"
      },
      "source": [
        "ta_rom['split']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD7CedwSKaoS"
      },
      "source": [
        "l1 = [1,4,2,3]\n",
        "l2 = [1,4,2,5]\n",
        "print(np.array(l1[1:-1])==np.array(l2[1:-1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}