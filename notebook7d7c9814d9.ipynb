{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "happy-wednesday",
   "metadata": {
    "id": "dtcVxQrUVxtS",
    "papermill": {
     "duration": 0.022699,
     "end_time": "2021-05-17T07:18:36.210098",
     "exception": false,
     "start_time": "2021-05-17T07:18:36.187399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TO DO\n",
    "1. Change structure of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anticipated-fourth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:18:36.257741Z",
     "iopub.status.busy": "2021-05-17T07:18:36.256383Z",
     "iopub.status.idle": "2021-05-17T07:18:36.260460Z",
     "shell.execute_reply": "2021-05-17T07:18:36.259960Z"
    },
    "id": "qRAUpzh1BLEB",
    "outputId": "3793ba3b-f5e9-4188-fd46-d8784ae5982e",
    "papermill": {
     "duration": 0.029045,
     "end_time": "2021-05-17T07:18:36.260580",
     "exception": false,
     "start_time": "2021-05-17T07:18:36.231535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standard-reasoning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:18:36.310139Z",
     "iopub.status.busy": "2021-05-17T07:18:36.309655Z",
     "iopub.status.idle": "2021-05-17T07:18:41.934179Z",
     "shell.execute_reply": "2021-05-17T07:18:41.933110Z"
    },
    "id": "bClAC3xAEhKS",
    "papermill": {
     "duration": 5.652578,
     "end_time": "2021-05-17T07:18:41.934358",
     "exception": false,
     "start_time": "2021-05-17T07:18:36.281780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import shutil\n",
    "from keras import layers\n",
    "from keras.layers import LSTM, Dense, Embedding, Input\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tqdm.auto import tqdm\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "import datetime\n",
    "from math import ceil\n",
    "from pprint import pprint\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Concatenate, TimeDistributed,Dropout\n",
    "from tensorflow.python.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equivalent-certificate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:18:41.984657Z",
     "iopub.status.busy": "2021-05-17T07:18:41.983710Z",
     "iopub.status.idle": "2021-05-17T07:18:41.986330Z",
     "shell.execute_reply": "2021-05-17T07:18:41.985902Z"
    },
    "papermill": {
     "duration": 0.028997,
     "end_time": "2021-05-17T07:18:41.986472",
     "exception": false,
     "start_time": "2021-05-17T07:18:41.957475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dir = '/content'\n",
    "dir = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continental-credit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:18:42.036397Z",
     "iopub.status.busy": "2021-05-17T07:18:42.035854Z",
     "iopub.status.idle": "2021-05-17T07:19:05.147896Z",
     "shell.execute_reply": "2021-05-17T07:19:05.147294Z"
    },
    "id": "Fs9sbR5xCVo3",
    "outputId": "4e1ed4b9-6e96-4f24-8a15-26a7cb03561f",
    "papermill": {
     "duration": 23.139598,
     "end_time": "2021-05-17T07:19:05.148041",
     "exception": false,
     "start_time": "2021-05-17T07:18:42.008443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-17 07:18:42--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.122.128, 64.233.185.128, 74.125.21.128, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.122.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2008340480 (1.9G) [application/x-tar]\r\n",
      "Saving to: ‘dakshina_dataset_v1.0.tar’\r\n",
      "\r\n",
      "dakshina_dataset_v1 100%[===================>]   1.87G   158MB/s    in 14s     \r\n",
      "\r\n",
      "2021-05-17 07:18:56 (142 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
    "\n",
    "if not os.path.isdir(dir + '/dakshina_dataset_v1.0'):\n",
    "  tarfile.open(dir + \"/dakshina_dataset_v1.0.tar\").extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "royal-martin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:14.798215Z",
     "iopub.status.busy": "2021-05-17T07:19:14.797314Z",
     "iopub.status.idle": "2021-05-17T07:19:15.856203Z",
     "shell.execute_reply": "2021-05-17T07:19:15.855327Z"
    },
    "id": "K0fMpPf_BUUK",
    "outputId": "25f035fe-8f67-4a41-a925-85f4d74173d6",
    "papermill": {
     "duration": 1.158591,
     "end_time": "2021-05-17T07:19:15.856331",
     "exception": false,
     "start_time": "2021-05-17T07:19:14.697740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='14394907543f59ea21931529e34b4d80d2ca8c9c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-pound",
   "metadata": {
    "id": "-BstzblcHmd5",
    "papermill": {
     "duration": 1.32883,
     "end_time": "2021-05-17T07:19:17.569451",
     "exception": false,
     "start_time": "2021-05-17T07:19:16.240621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "official-chick",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:17.732004Z",
     "iopub.status.busy": "2021-05-17T07:19:17.730951Z",
     "iopub.status.idle": "2021-05-17T07:19:17.763913Z",
     "shell.execute_reply": "2021-05-17T07:19:17.771634Z"
    },
    "id": "fNDJrkl5EUHX",
    "papermill": {
     "duration": 0.129157,
     "end_time": "2021-05-17T07:19:17.771877",
     "exception": false,
     "start_time": "2021-05-17T07:19:17.642720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class data_loader():\n",
    "\n",
    "  @staticmethod\n",
    "  def _load_raw_df(languages = [\"ta\"]):\n",
    "    lex = dict()\n",
    "    lex['train'], lex['val'], lex['test'] = [], [], [] \n",
    "    column_names = ['output', 'input', 'count']\n",
    "    \n",
    "    for la in languages:\n",
    "      lex['train'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.train.tsv', sep='\\t', header=None, names=column_names))\n",
    "      lex['val'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.dev.tsv', sep='\\t', header=None, names=column_names))\n",
    "      lex['test'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.test.tsv', sep='\\t', header=None, names=column_names))\n",
    "\n",
    "    lex['train'] = pd.concat(lex['train'])\n",
    "    lex['val'] = pd.concat(lex['val'])\n",
    "    lex['test'] = pd.concat(lex['test'])\n",
    "\n",
    "    return lex    \n",
    "\n",
    "  @staticmethod\n",
    "  def _make_final_df(lex):\n",
    "    \n",
    "    for div in ['train', 'val', 'test']:\n",
    "    \n",
    "      # removing non max transliterations\n",
    "      idx = lex[div].groupby(['input'])['count'].transform(max) == lex[div]['count']\n",
    "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
    "\n",
    "      # calclulating difference in lengths of various transliterations\n",
    "      lex[div]['input_len'] = lex[div].apply(lambda x: len(str(x['input'])), axis=1)\n",
    "      lex[div]['output_len'] = lex[div].apply(lambda y: len(str(y['output'])), axis=1)\n",
    "      lex[div]['mod_dif'] = lex[div].apply(lambda z: abs(z['input_len'] - z['output_len']), axis=1) \n",
    "\n",
    "      # removing transliterations that vary by a lot in length\n",
    "      idx = lex[div].groupby(['input'])['mod_dif'].transform(min) == lex[div]['mod_dif']\n",
    "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
    "\n",
    "      # removing duplicates if any remain\n",
    "      lex[div].drop_duplicates(subset='input', keep='first', inplace=True)\n",
    "\n",
    "      # removing redundant columns\n",
    "      lex[div].drop(labels=['count', 'input_len', 'output_len', 'mod_dif'], inplace=True, axis=1)\n",
    "\n",
    "      # shuffling the dataset i.e. rows of the dataset\n",
    "      lex[div] = lex[div].sample(frac=1)\n",
    "      lex[div].reset_index()\n",
    "\n",
    "    return lex\n",
    "\n",
    "  @staticmethod\n",
    "  def _generate_batch(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
    "\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            \n",
    "            # placeholder data structures\n",
    "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, data_dict['max_target_length']),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
    "\n",
    "            # assessing one batch at a time\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "\n",
    "                for t, word in enumerate(input_text):\n",
    "                  encoder_input_data[i, t] = word\n",
    "                for t, word in enumerate(target_text):\n",
    "                    if t<len(target_text)-1:\n",
    "                        # decoder input sequence\n",
    "                        # does not include the <EOW> token\n",
    "                        decoder_input_data[i, t] = word \n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the <SOW> token\n",
    "                        decoder_target_data[i, t - 1, word] = 1.\n",
    "                    \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "\n",
    "  @staticmethod\n",
    "  def _generate_batch_greedy(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
    "\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "\n",
    "            # placeholder data structures\n",
    "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, 1),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
    "            \n",
    "            # assessing one batch at a time\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text):\n",
    "                  encoder_input_data[i, t] = word\n",
    "                for t, word in enumerate(target_text):\n",
    "                    if t==0 :\n",
    "                        decoder_input_data[i, t] = 1 # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        decoder_target_data[i, t - 1, word] = 1.\n",
    "                    \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numeric-exception",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:17.974876Z",
     "iopub.status.busy": "2021-05-17T07:19:17.973905Z",
     "iopub.status.idle": "2021-05-17T07:19:17.989573Z",
     "shell.execute_reply": "2021-05-17T07:19:17.990717Z"
    },
    "id": "rOo1m6s3vDaN",
    "papermill": {
     "duration": 0.1239,
     "end_time": "2021-05-17T07:19:17.990940",
     "exception": false,
     "start_time": "2021-05-17T07:19:17.867040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "\n",
    "  def __init__(self, df):\n",
    "\n",
    "    self.start_token = '<SOW>'\n",
    "    self.stop_token = '<EOW>'\n",
    "    self.unknown_token = '<UNK>'\n",
    "\n",
    "    self.input_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
    "    self.output_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
    "\n",
    "    input_words = df.input.tolist()\n",
    "    output_words = df.output.tolist()\n",
    "\n",
    "    for word in input_words:\n",
    "      tokens = str(word)\n",
    "      for token in tokens:\n",
    "        if token not in self.input_corpus:\n",
    "          self.input_corpus.append(token)\n",
    "\n",
    "    for word in output_words:\n",
    "      tokens = str(word)\n",
    "      for token in tokens:\n",
    "        if token not in self.output_corpus:\n",
    "          self.output_corpus.append(token)\n",
    "    \n",
    "    self.encode_dict_input = {self.input_corpus[i] : i+1 for i in range(len(self.input_corpus))}\n",
    "    self.decode_dict_input = {k:v for v,k in self.encode_dict_input.items()}\n",
    "    \n",
    "    \n",
    "    self.encode_dict_output = {self.output_corpus[i] : i+1 for i in range(len(self.output_corpus))}\n",
    "    self.decode_dict_output = {k:v for v,k in self.encode_dict_output.items()}\n",
    "    self.decode_dict_output.update({2:''})\n",
    "\n",
    "  # takes in lists of words and returns lists of integers\n",
    "  def encode(self, X, mode='input'):\n",
    "\n",
    "    if (mode=='input'):\n",
    "      input_list = []\n",
    "      for word in X:\n",
    "        word = str(word)\n",
    "        integer_list =np.array([self.encode_dict_input.get(token, self.encode_dict_input[self.unknown_token]) for token in word])\n",
    "        input_list.append(integer_list)\n",
    "      \n",
    "      return input_list\n",
    "    \n",
    "    if (mode=='output'):\n",
    "      output_list = []\n",
    "      for word in X:\n",
    "        word = str(word)\n",
    "        integer_list = np.array([self.encode_dict_output[self.start_token]] + [self.encode_dict_output.get(token, self.encode_dict_output[self.unknown_token]) for token in word] + [self.encode_dict_output[self.stop_token]])\n",
    "        output_list.append(integer_list)\n",
    "      \n",
    "      return output_list\n",
    "    \n",
    "  # takes in lists of integers and returns lists of words\n",
    "  def decode(self, X, mode='input'):\n",
    "\n",
    "    if (mode=='input'):\n",
    "      input_list = []\n",
    "      for integers in X:\n",
    "        token_list = [self.decode_dict_input.get(integer, '') for integer in integers] \n",
    "        input_list.append(''.join(token_list))\n",
    "      \n",
    "      return input_list\n",
    "\n",
    "    if (mode=='output'):\n",
    "      output_list = []\n",
    "      for integers in X:\n",
    "        token_list = [self.decode_dict_output.get(integer, '') for integer in integers[:-1]] \n",
    "        output_list.append(''.join(token_list))\n",
    "      \n",
    "      return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "instant-coordinate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:18.107632Z",
     "iopub.status.busy": "2021-05-17T07:19:18.106147Z",
     "iopub.status.idle": "2021-05-17T07:19:18.108674Z",
     "shell.execute_reply": "2021-05-17T07:19:18.109073Z"
    },
    "id": "s1mzVsRdBa4x",
    "papermill": {
     "duration": 0.059174,
     "end_time": "2021-05-17T07:19:18.109215",
     "exception": false,
     "start_time": "2021-05-17T07:19:18.050041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_data_dict(languages=[\"ta\"], batch_size=32):\n",
    "\n",
    "  lex = data_loader._load_raw_df(languages)\n",
    "  lex = data_loader._make_final_df(lex)\n",
    "\n",
    "  data_dict = dict()\n",
    "\n",
    "  df_train = lex['train']\n",
    "  df_val = lex['val']\n",
    "  df_test = lex['test']\n",
    "\n",
    "  tk = Tokenizer(df_train)\n",
    "\n",
    "  data_dict['in_size'] = len(tk.input_corpus) + 1\n",
    "  data_dict['out_size'] = len(tk.output_corpus) + 1\n",
    "\n",
    "  X_train = tk.encode(df_train.input.tolist(), mode='input')\n",
    "  Y_train = tk.encode(df_train.output.tolist(), mode='output')\n",
    "  \n",
    "  X_val = tk.encode(df_val.input.tolist(), mode='input')\n",
    "  Y_val = tk.encode(df_val.output.tolist(), mode='output')\n",
    "  \n",
    "  X_test = tk.encode(df_test.input.tolist(), mode='input')\n",
    "  Y_test = tk.encode(df_test.output.tolist(), mode='output')\n",
    "\n",
    "\n",
    "  data_dict['train'], data_dict['val'], data_dict['test']= dict(), dict(), dict()\n",
    "\n",
    "\n",
    "  data_dict['train']['df'] = df_train\n",
    "  data_dict['val']['df'] = df_val\n",
    "  data_dict['test']['df'] = df_test\n",
    "\n",
    "\n",
    "  data_dict['train']['max_source_length'] = np.max(np.array([len(x) for x in X_train]))\n",
    "  data_dict['train']['max_target_length'] = np.max(np.array([len(x) for x in Y_train]))\n",
    "  \n",
    "  data_dict['val']['max_source_length'] = np.max(np.array([len(x) for x in X_val]))\n",
    "  data_dict['val']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
    "  \n",
    "  data_dict['test']['max_source_length'] = np.max(np.array([len(x) for x in X_test]))\n",
    "  data_dict['test']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
    "\n",
    "\n",
    "  data_dict['max_source_length'] = max(data_dict['train']['max_source_length'], data_dict['val']['max_source_length'], data_dict['test']['max_source_length'])\n",
    "  data_dict['max_target_length'] = max(data_dict['train']['max_target_length'], data_dict['val']['max_target_length'], data_dict['test']['max_target_length'])\n",
    "\n",
    "\n",
    "  data_dict['train']['batch'] = data_loader._generate_batch(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['train']['batch_greedy'] = data_loader._generate_batch_greedy(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
    "  \n",
    "  data_dict['val']['batch'] = data_loader._generate_batch(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
    "  data_dict['val']['batch_greedy'] = data_loader._generate_batch_greedy(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
    "\n",
    "  data_dict['test']['batch'] = data_loader._generate_batch(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)  \n",
    "  data_dict['test']['batch_greedy'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)    \n",
    "  data_dict['test']['batch_1'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], 1)\n",
    "\n",
    "\n",
    "  data_dict['tokenizer'] = tk\n",
    "\n",
    "  return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chubby-ferry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:18.192882Z",
     "iopub.status.busy": "2021-05-17T07:19:18.192062Z",
     "iopub.status.idle": "2021-05-17T07:19:23.183791Z",
     "shell.execute_reply": "2021-05-17T07:19:23.184245Z"
    },
    "id": "MwJozmDWedfG",
    "papermill": {
     "duration": 5.036059,
     "end_time": "2021-05-17T07:19:23.184471",
     "exception": false,
     "start_time": "2021-05-17T07:19:18.148412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = return_data_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-delicious",
   "metadata": {
    "id": "HqiICTfUid26",
    "papermill": {
     "duration": 3.302699,
     "end_time": "2021-05-17T07:19:26.531528",
     "exception": false,
     "start_time": "2021-05-17T07:19:23.228829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "jewish-seattle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:28.248741Z",
     "iopub.status.busy": "2021-05-17T07:19:28.247733Z",
     "iopub.status.idle": "2021-05-17T07:19:28.291057Z",
     "shell.execute_reply": "2021-05-17T07:19:28.291766Z"
    },
    "id": "9NWc0APTli6i",
    "papermill": {
     "duration": 0.141565,
     "end_time": "2021-05-17T07:19:28.291940",
     "exception": false,
     "start_time": "2021-05-17T07:19:28.150375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        # print(input_shape[0][2],input_shape[1][2])\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        # print(\"attn called\")\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "organic-location",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:32.955415Z",
     "iopub.status.busy": "2021-05-17T07:19:32.954355Z",
     "iopub.status.idle": "2021-05-17T07:19:32.958877Z",
     "shell.execute_reply": "2021-05-17T07:19:32.959970Z"
    },
    "id": "hjO2uBZFkYT0",
    "papermill": {
     "duration": 1.353483,
     "end_time": "2021-05-17T07:19:32.960198",
     "exception": false,
     "start_time": "2021-05-17T07:19:31.606715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class attn_rnn():\n",
    "  def __init__(self,params) :\n",
    "    in_size = params['data_dict']['in_size']\n",
    "    out_size = params['data_dict']['out_size']\n",
    "    dropout = params['dropout']\n",
    "    embed_size = params['embed_size']\n",
    "    rep_size = params['rep_size']\n",
    "\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "\n",
    "    encoder_emb = Embedding(in_size, embed_size, input_length=None,mask_zero=True)\n",
    "    temp1 = encoder_emb(encoder_inputs)\n",
    "    encoder_lstm = LSTM(rep_size, return_sequences=True, return_state=True,dropout=dropout)\n",
    "    encoder_out, *encoder_state = encoder_lstm(temp1)\n",
    "    \n",
    "\n",
    "    decoder_emb = Embedding(out_size, embed_size , input_length=None,mask_zero=True)\n",
    "    temp2 = decoder_emb(decoder_inputs)\n",
    "    decoder_lstm = LSTM(rep_size, return_sequences=True, return_state=True,dropout=dropout)\n",
    "    decoder_out, *decoder_state = decoder_lstm(temp2, initial_state=encoder_state)\n",
    "\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer()\n",
    "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = Concatenate(axis=-1)([decoder_out, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    drop = Dropout(dropout)\n",
    "    decoder_concat_input = drop(decoder_concat_input)\n",
    "    dense = Dense(out_size, activation='softmax')\n",
    "    dense_time = TimeDistributed(dense)\n",
    "    decoder_pred = dense_time(decoder_concat_input)\n",
    "\n",
    "    # Full model\n",
    "    full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "\n",
    "    batch_size = 1\n",
    "\n",
    "    \"\"\" Encoder (Inference) model \"\"\"\n",
    "    encoder_inf_inputs = Input(shape=(None,))\n",
    "    temp3 = encoder_emb(encoder_inf_inputs)\n",
    "    encoder_inf_out, *encoder_inf_state = encoder_lstm(temp3)\n",
    "    encoder_model = Model(inputs=encoder_inf_inputs, outputs=[encoder_inf_out, encoder_inf_state])\n",
    "\n",
    "    \"\"\" Decoder (Inference) model \"\"\"\n",
    "    decoder_inf_inputs = Input(shape=(None,))\n",
    "    encoder_inf_states = Input(shape=(None, rep_size))\n",
    "    decoder_init_stateh = Input(shape=(rep_size,))\n",
    "    decoder_init_statec = Input(shape=(rep_size,))\n",
    "    decoder_init_state = [decoder_init_stateh,decoder_init_statec]\n",
    "    temp = decoder_emb(decoder_inf_inputs)\n",
    "    decoder_inf_out, *decoder_inf_state = decoder_lstm(temp, initial_state=decoder_init_state)\n",
    "    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "    decoder_inf_concat = Concatenate(axis=-1)([decoder_inf_out, attn_inf_out])\n",
    "    decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "    decoder_model = Model(inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "                          outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state])\n",
    "\n",
    "    self.model = full_model\n",
    "    self.encoder = encoder_model\n",
    "    self.decoder = decoder_model\n",
    "\n",
    "  def compile_and_fit(self,data_dict,params):\n",
    "\n",
    "    self.model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "    self.model.summary()\n",
    "    batch_size=params['batch_size']\n",
    "    epochs=params['num_epochs']\n",
    "    val_samples = len(data_dict['val']['df'])\n",
    "    train_samples = len(data_dict['train']['df'])\n",
    "\n",
    "    self.model.fit_generator(generator = data_dict['train']['batch'],\n",
    "                 steps_per_epoch=train_samples//batch_size,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=data_dict['val']['batch'],\n",
    "                 validation_steps=val_samples//batch_size\n",
    "                 )\n",
    "    \n",
    "  def evaluate(self,data_dict,filename) :\n",
    "    generator = data_dict['test']['batch_1']\n",
    "    tk = data_dict['tokenizer']\n",
    "    acc = 0\n",
    "    num = len(data_dict['test']['df'])\n",
    "    # num = 1\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    attn = []\n",
    "    for j in tqdm(range(num)) :\n",
    "      (a,b),c = next(generator)\n",
    "      g = [np.argmax(c,axis=-1)[0]]\n",
    "      enc_outs, enc_last_state = self.encoder.predict(a)\n",
    "      dec_state = enc_last_state\n",
    "      attention_weights = []\n",
    "      word = []\n",
    "      for i in range(23):\n",
    "\n",
    "          dec_out, attention, dec_state = self.decoder.predict([enc_outs, dec_state, b])\n",
    "          dec_ind = np.argmax(dec_out, axis=-1)\n",
    "\n",
    "          word.append(dec_ind[0][0])\n",
    "          b = dec_ind\n",
    "          attention_weights.append((dec_ind, attention))\n",
    "          if dec_ind[0][0] == 2 :\n",
    "            break\n",
    "      str1 = tk.decode(g,mode='output')\n",
    "      str2 = tk.decode([word],mode='output')\n",
    "      inputs.append(str1[0])\n",
    "      outputs.append(str2[0])\n",
    "      attn.append(attention_weights)\n",
    "      # print(word)\n",
    "      # print(str1[0],str2[0])\n",
    "      if str1[0] == str2[0] :\n",
    "        acc += 1\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump([inputs,outputs,attn], f)\n",
    "    print(\"Test accuracy : \",acc/num)\n",
    "\n",
    "  def get_attn_weights(self,a,b) :\n",
    "    enc_outs, enc_last_state = self.encoder.predict(a)\n",
    "    dec_state = enc_last_state\n",
    "    attention_weights = []\n",
    "    word = []\n",
    "    for i in range(23):\n",
    "\n",
    "        dec_out, attention, dec_state = self.decoder.predict([enc_outs, dec_state, b])\n",
    "        dec_ind = np.argmax(dec_out, axis=-1)\n",
    "\n",
    "        word.append(dec_ind[0][0])\n",
    "        b = dec_ind\n",
    "        attention_weights.append((dec_ind, attention))\n",
    "        if dec_ind[0][0] == 2 :\n",
    "          break\n",
    "\n",
    "    return attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hybrid-bearing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:33.146872Z",
     "iopub.status.busy": "2021-05-17T07:19:33.145844Z",
     "iopub.status.idle": "2021-05-17T07:19:33.148446Z",
     "shell.execute_reply": "2021-05-17T07:19:33.147690Z"
    },
    "id": "nerT1tBt8ZUo",
    "papermill": {
     "duration": 0.079244,
     "end_time": "2021-05-17T07:19:33.148624",
     "exception": false,
     "start_time": "2021-05-17T07:19:33.069380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'rep_size' : 128,\n",
    "    'embed_size' : 16,\n",
    "    'dropout' : 0.5,\n",
    "    'num_epochs' : 15,\n",
    "    'data_dict' : data_dict,\n",
    "    'batch_size' : 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "marked-process",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T07:19:33.301333Z",
     "iopub.status.busy": "2021-05-17T07:19:33.300497Z",
     "iopub.status.idle": "2021-05-17T08:01:21.775013Z",
     "shell.execute_reply": "2021-05-17T08:01:21.774469Z"
    },
    "id": "lGmgPaQD8r90",
    "outputId": "26ea0b93-08a5-44ab-9f3f-f45bd7af0ea0",
    "papermill": {
     "duration": 2508.542193,
     "end_time": "2021-05-17T08:01:21.775155",
     "exception": false,
     "start_time": "2021-05-17T07:19:33.232962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 16)     480         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 16)     800         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 128),  74240       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  74240       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 128),  32896       lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 256)    0           lstm_1[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 50)     12850       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 195,506\n",
      "Trainable params: 195,506\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2071/2071 [==============================] - 173s 78ms/step - loss: 0.8773 - acc: 0.3019 - val_loss: 0.3619 - val_acc: 0.6979\n",
      "Epoch 2/15\n",
      "2071/2071 [==============================] - 161s 78ms/step - loss: 0.3828 - acc: 0.6876 - val_loss: 0.1815 - val_acc: 0.8569\n",
      "Epoch 3/15\n",
      "2071/2071 [==============================] - 165s 80ms/step - loss: 0.2425 - acc: 0.8127 - val_loss: 0.1476 - val_acc: 0.8836\n",
      "Epoch 4/15\n",
      "2071/2071 [==============================] - 168s 81ms/step - loss: 0.2001 - acc: 0.8464 - val_loss: 0.1326 - val_acc: 0.8950\n",
      "Epoch 5/15\n",
      "2071/2071 [==============================] - 168s 81ms/step - loss: 0.1773 - acc: 0.8636 - val_loss: 0.1233 - val_acc: 0.9025\n",
      "Epoch 6/15\n",
      "2071/2071 [==============================] - 168s 81ms/step - loss: 0.1622 - acc: 0.8756 - val_loss: 0.1186 - val_acc: 0.9062\n",
      "Epoch 7/15\n",
      "2071/2071 [==============================] - 167s 81ms/step - loss: 0.1512 - acc: 0.8839 - val_loss: 0.1139 - val_acc: 0.9091\n",
      "Epoch 8/15\n",
      "2071/2071 [==============================] - 166s 80ms/step - loss: 0.1427 - acc: 0.8903 - val_loss: 0.1111 - val_acc: 0.9107\n",
      "Epoch 9/15\n",
      "2071/2071 [==============================] - 172s 83ms/step - loss: 0.1360 - acc: 0.8948 - val_loss: 0.1098 - val_acc: 0.9122\n",
      "Epoch 10/15\n",
      "2071/2071 [==============================] - 168s 81ms/step - loss: 0.1292 - acc: 0.8994 - val_loss: 0.1092 - val_acc: 0.9136\n",
      "Epoch 11/15\n",
      "2071/2071 [==============================] - 162s 78ms/step - loss: 0.1253 - acc: 0.9019 - val_loss: 0.1059 - val_acc: 0.9158\n",
      "Epoch 12/15\n",
      "2071/2071 [==============================] - 163s 79ms/step - loss: 0.1211 - acc: 0.9052 - val_loss: 0.1060 - val_acc: 0.9166\n",
      "Epoch 13/15\n",
      "2071/2071 [==============================] - 165s 79ms/step - loss: 0.1181 - acc: 0.9075 - val_loss: 0.1038 - val_acc: 0.9175\n",
      "Epoch 14/15\n",
      "2071/2071 [==============================] - 169s 82ms/step - loss: 0.1147 - acc: 0.9102 - val_loss: 0.1073 - val_acc: 0.9175\n",
      "Epoch 15/15\n",
      "2071/2071 [==============================] - 168s 81ms/step - loss: 0.1111 - acc: 0.9127 - val_loss: 0.1045 - val_acc: 0.9179\n"
     ]
    }
   ],
   "source": [
    "network = attn_rnn(params)\n",
    "network.compile_and_fit(data_dict,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accessory-plaza",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:01:38.398807Z",
     "iopub.status.busy": "2021-05-17T08:01:38.398116Z",
     "iopub.status.idle": "2021-05-17T08:52:36.886480Z",
     "shell.execute_reply": "2021-05-17T08:52:36.887208Z"
    },
    "id": "wCzqDU79Hgr3",
    "outputId": "bc6f0034-4f53-41d9-f78b-2a0700915528",
    "papermill": {
     "duration": 3066.838908,
     "end_time": "2021-05-17T08:52:36.887486",
     "exception": false,
     "start_time": "2021-05-17T08:01:30.048578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e98858b80b44987aef28d90fea112c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6833 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy :  0.5332943070393678\n"
     ]
    }
   ],
   "source": [
    "network.evaluate(data_dict,'/kaggle/working/attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "creative-injection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:52:53.112362Z",
     "iopub.status.busy": "2021-05-17T08:52:53.110448Z",
     "iopub.status.idle": "2021-05-17T08:52:53.112913Z",
     "shell.execute_reply": "2021-05-17T08:52:53.113301Z"
    },
    "id": "ylVGlR52Rv9-",
    "papermill": {
     "duration": 7.991566,
     "end_time": "2021-05-17T08:52:53.113453",
     "exception": false,
     "start_time": "2021-05-17T08:52:45.121887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def plot_attention_weights(encoder_inputs, attention_weights, en_id2word, fr_id2word, filename=None):\n",
    "#     \"\"\"\n",
    "#     Plots attention weights\n",
    "#     :param encoder_inputs: Sequence of word ids (list/numpy.ndarray)\n",
    "#     :param attention_weights: Sequence of (<word_id_at_decode_step_t>:<attention_weights_at_decode_step_t>)\n",
    "#     :param en_id2word: dict\n",
    "#     :param fr_id2word: dict\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "\n",
    "#     if len(attention_weights) == 0:\n",
    "#         print('Your attention weights was empty. No attention map saved to the disk. ' +\n",
    "#               '\\nPlease check if the decoder produced  a proper translation')\n",
    "#         return\n",
    "\n",
    "#     mats = []\n",
    "#     dec_inputs = []\n",
    "#     l = 0\n",
    "#     encoder_inputs = encoder_inputs.flatten()\n",
    "#     for i in range(len(encoder_inputs)) :\n",
    "#       l += 1\n",
    "#       if encoder_inputs[i] == 0 :\n",
    "#         break\n",
    "#     for dec_ind, attn in attention_weights:\n",
    "#         mats.append(attn.reshape(-1)[:l])\n",
    "#         dec_inputs.append(dec_ind)\n",
    "#     attention_mat = np.transpose(np.array(mats))\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#     ax.imshow(attention_mat)\n",
    "\n",
    "#     ax.set_xticks(np.arange(attention_mat.shape[1]))\n",
    "#     ax.set_yticks(np.arange(attention_mat.shape[0]))\n",
    "#     encoder_inputs = encoder_inputs[:l]\n",
    "#     print([(inp,fr_id2word[inp]) for inp in np.array(dec_inputs).ravel()]) \n",
    "#     ax.set_xticklabels([inp for inp in np.array(dec_inputs).ravel()])\n",
    "#     ax.set_yticklabels([en_id2word[inp] if inp != 0 else \"Nan\" for inp in np.array(encoder_inputs).ravel()])\n",
    "\n",
    "#     ax.tick_params(labelsize=32)\n",
    "#     ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "#     if filename is None:\n",
    "#         plt.savefig('attention.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "structured-advertising",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:53:09.975666Z",
     "iopub.status.busy": "2021-05-17T08:53:09.974805Z",
     "iopub.status.idle": "2021-05-17T08:53:09.976981Z",
     "shell.execute_reply": "2021-05-17T08:53:09.976359Z"
    },
    "id": "rGO67b2vftqW",
    "outputId": "5cb96d80-15bb-4e59-9600-c35b2fdb0b04",
    "papermill": {
     "duration": 8.676944,
     "end_time": "2021-05-17T08:53:09.977127",
     "exception": false,
     "start_time": "2021-05-17T08:53:01.300183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_attention_weights(a,attention_weights,data_dict['tokenizer'].decode_dict_input,data_dict['tokenizer'].decode_dict_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "attempted-nirvana",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:53:26.380064Z",
     "iopub.status.busy": "2021-05-17T08:53:26.378348Z",
     "iopub.status.idle": "2021-05-17T08:53:26.380757Z",
     "shell.execute_reply": "2021-05-17T08:53:26.381145Z"
    },
    "id": "KqeaGwh4SGne",
    "papermill": {
     "duration": 8.108319,
     "end_time": "2021-05-17T08:53:26.381276",
     "exception": false,
     "start_time": "2021-05-17T08:53:18.272957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_sequence_beam_attn(input_seq,target_seq, k, encoder_model, decoder_model, tk, max_target_length=20, getall=False,alpha=0.7):\n",
    "    # encode the input as state vectors\n",
    "    enc_outs,states_value = encoder_model.predict(input_seq)\n",
    "    # generate empty target sequence of length 1.\n",
    "    # populate the first character of target sequence with the start character.\n",
    "    run_condition = [True for i in range(k)]\n",
    "    # print(len(states_value))\n",
    "    # print([target_seq] + [states_value])\n",
    "    results, attn,states_values_temp = decoder_model.predict([enc_outs , states_value,target_seq])\n",
    "    output_tokens = results\n",
    "    # print(results)\n",
    "    states_values_k = [states_values_temp for i in range(k)]\n",
    "    #get topk indices\n",
    "    ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
    "    # print(ind)\n",
    "    bestk_ind = ind\n",
    "    output_tokens = np.array(output_tokens[0, -1, :])\n",
    "    bestk_prob = np.log(output_tokens[ind])\n",
    "    bestk_tot = [[bestk_ind[i]] for i in range(k)]\n",
    "    # print(bestk_tot)\n",
    "    # print(bestk_prob)\n",
    "\n",
    "    \n",
    "    while any(run_condition):\n",
    "        # print(\"##############\")\n",
    "        bestk_tot_new = []\n",
    "        bestk_prob_new = []\n",
    "        states_values_k_new = []\n",
    "        for i in range(k) :\n",
    "            # print(\"**\")\n",
    "            if run_condition[i] :\n",
    "                a = bestk_tot[i]\n",
    "                b = bestk_prob[i]\n",
    "                target_seq[0,0] = a[-1]\n",
    "                results,attn,states_values_temp = decoder_model.predict([enc_outs,states_values_k[i],target_seq],batch_size=1)\n",
    "\n",
    "                output_tokens = results\n",
    "\n",
    "                states_values_k_temp = [states_values_temp for m in range(k)]\n",
    "\n",
    "                states_values_k_new += states_values_k_temp\n",
    "                ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
    "                bestk_ind = ind\n",
    "                output_tokens = np.array(output_tokens[0, -1, :])\n",
    "                bestk_prob_temp = output_tokens[ind]\n",
    "                # print(np.log(bestk_prob_temp))\n",
    "                bestk_tot_temp = [a+[bestk_ind[j]] for j in range(k)]\n",
    "                # print(bestk_tot_temp)\n",
    "                bestk_prob_temp2 = [(b*(np.power(len(bestk_tot_temp[j])-1,alpha)) + np.log(bestk_prob_temp[j]))/(np.power(len(bestk_tot_temp[j]),alpha)) for j in range(k)]\n",
    "                # print(bestk_prob_temp2)\n",
    "                bestk_prob_new += bestk_prob_temp2\n",
    "                bestk_tot_new += bestk_tot_temp\n",
    "            \n",
    "            else :\n",
    "                a = bestk_tot[i]\n",
    "                b = bestk_prob[i]\n",
    "                bestk_tot_new += [bestk_tot[i]]\n",
    "                bestk_prob_new += [b]\n",
    "                states_values_k_new += [states_values_k[i]]\n",
    "\n",
    "        bestk_prob_new = np.array(bestk_prob_new)\n",
    "        # print(len(bestk_prob_new),len(bestk_tot_new),len(states_values_k_new))\n",
    "        ind = np.argpartition(bestk_prob_new,-k)[-k:]\n",
    "        bestk_tot = [bestk_tot_new[i] for i in ind]\n",
    "        states_values_k = [states_values_k_new[i] for i in ind]\n",
    "        bestk_prob = bestk_prob_new[ind]\n",
    "        run_condition = []\n",
    "        for i in range(k) :\n",
    "            a = bestk_tot[i]\n",
    "            b = bestk_prob[i]\n",
    "            if a[-1]!= 2 and len(a)<=max_target_length :\n",
    "              run_condition.append(True)\n",
    "            else :\n",
    "              run_condition.append(False)\n",
    "\n",
    "        # print(bestk_tot)\n",
    "\n",
    "    final_words = []\n",
    "    best_word = []\n",
    "    best = -5.0\n",
    "    for i in range(k) :\n",
    "      a = bestk_tot[i]\n",
    "      b = bestk_prob[i]\n",
    "      final_words += [a]\n",
    "      if b > best :\n",
    "        best_word = [a]\n",
    "        best = b\n",
    "\n",
    "    if getall :\n",
    "      return (tk.decode(final_words,'output'),best_word)\n",
    "    else :\n",
    "      return final_words,bestk_prob, best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "round-stage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:53:43.237083Z",
     "iopub.status.busy": "2021-05-17T08:53:43.235017Z",
     "iopub.status.idle": "2021-05-17T08:53:43.237798Z",
     "shell.execute_reply": "2021-05-17T08:53:43.238301Z"
    },
    "id": "6bP5GF92G_Qr",
    "outputId": "b6fa7d40-ea28-40e9-e3c7-f74419397389",
    "papermill": {
     "duration": 8.642327,
     "end_time": "2021-05-17T08:53:43.238472",
     "exception": false,
     "start_time": "2021-05-17T08:53:34.596145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##run beam search\n",
    "\n",
    "# generator = data_dict['test']['batch_1']\n",
    "# tk = data_dict['tokenizer']\n",
    "# m2 = network.encoder\n",
    "# m3 = network.decoder\n",
    "# acc = 0\n",
    "# num = len(data_dict['test']['df'])\n",
    "# acc_k = 0\n",
    "# # num = 50\n",
    "# inputs = []\n",
    "# outputs = []\n",
    "# for j in tqdm(range(num)) :\n",
    "#   (a,b),c = next(generator)\n",
    "#   g = [np.argmax(c,axis=-1)[0]]\n",
    "#   attention_weights = []\n",
    "#   K,word = decode_sequence_beam_attn(a,b,10,m2,m3,data_dict['tokenizer'],max_target_length=data_dict['max_target_length'],getall=True )\n",
    "#   str1 = tk.decode(g,mode='output')\n",
    "#   str2 = tk.decode(word,mode='output')\n",
    "#   inputs.append(str1[0])\n",
    "#   outputs.append(str2[0])\n",
    "#   if str1[0] in K :\n",
    "#     acc_k += 1\n",
    "  \n",
    "#   if str1[0] == str2[0] :\n",
    "#     acc += 1\n",
    "    \n",
    "#   if (j+1) %500 == 0 :\n",
    "#     print(acc/num)\n",
    "#     print(acc_k/num)\n",
    "    \n",
    "# with open('/kaggle/working/beam_attn_temp', 'wb') as f:\n",
    "#         pickle.dump([inputs,outputs], f)\n",
    "        \n",
    "\n",
    "# print(acc/num)\n",
    "# print(acc_k/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automatic-speech",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:53:59.615559Z",
     "iopub.status.busy": "2021-05-17T08:53:59.614823Z",
     "iopub.status.idle": "2021-05-17T08:53:59.625423Z",
     "shell.execute_reply": "2021-05-17T08:53:59.625931Z"
    },
    "id": "xpyqMLYkEWW-",
    "outputId": "cb24a527-61b0-489b-a26b-642d018b0528",
    "papermill": {
     "duration": 8.047658,
     "end_time": "2021-05-17T08:53:59.626125",
     "exception": false,
     "start_time": "2021-05-17T08:53:51.578467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "phantom-sustainability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:54:16.445133Z",
     "iopub.status.busy": "2021-05-17T08:54:16.444284Z",
     "iopub.status.idle": "2021-05-17T08:54:16.448481Z",
     "shell.execute_reply": "2021-05-17T08:54:16.448058Z"
    },
    "id": "fIis2SNfEMkJ",
    "papermill": {
     "duration": 8.679847,
     "end_time": "2021-05-17T08:54:16.448597",
     "exception": false,
     "start_time": "2021-05-17T08:54:07.768750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6d0063ba4ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Models/m1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Models/m2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Models/m3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(m1,'/content/drive/MyDrive/Models/m1')\n",
    "tf.keras.models.save_model(m2,'/content/drive/MyDrive/Models/m2')\n",
    "tf.keras.models.save_model(m3,'/content/drive/MyDrive/Models/m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "educated-bloom",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:54:32.894511Z",
     "iopub.status.busy": "2021-05-17T08:54:32.893958Z",
     "iopub.status.idle": "2021-05-17T08:54:32.919052Z",
     "shell.execute_reply": "2021-05-17T08:54:32.918602Z"
    },
    "id": "nmKTmC6XFtfA",
    "outputId": "4b02bd37-7c7e-4951-e9e7-db20a6d19a10",
    "papermill": {
     "duration": 8.164396,
     "end_time": "2021-05-17T08:54:32.919177",
     "exception": false,
     "start_time": "2021-05-17T08:54:24.754781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /content/drive/MyDrive/Models/m1/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0d054d33be95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Models/m1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Models/m2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Models/m3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/drive/MyDrive/Models/m1/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "m1 = tf.keras.models.load_model('/content/drive/MyDrive/Models/m1')\n",
    "m2 = tf.keras.models.load_model('/content/drive/MyDrive/Models/m2')\n",
    "m3 = tf.keras.models.load_model('/content/drive/MyDrive/Models/m3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-christopher",
   "metadata": {
    "id": "ItqoHkE2JTO1",
    "papermill": {
     "duration": 8.616507,
     "end_time": "2021-05-17T08:54:49.729013",
     "exception": false,
     "start_time": "2021-05-17T08:54:41.112506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Romanized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "planned-river",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:55:05.861118Z",
     "iopub.status.busy": "2021-05-17T08:55:05.860246Z",
     "iopub.status.idle": "2021-05-17T08:55:05.865387Z",
     "shell.execute_reply": "2021-05-17T08:55:05.864962Z"
    },
    "id": "vv1674An8lTj",
    "papermill": {
     "duration": 7.976788,
     "end_time": "2021-05-17T08:55:05.865508",
     "exception": false,
     "start_time": "2021-05-17T08:54:57.888720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GRU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-36be2ac62727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_nmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-36be2ac62727>\u001b[0m in \u001b[0;36mdefine_nmt\u001b[0;34m(hidden_size, batch_size, en_timesteps, en_vsize, fr_timesteps, fr_vsize)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Encoder GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mencoder_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GRU' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "\n",
    "def define_nmt(hidden_size, batch_size, en_timesteps, en_vsize, fr_timesteps, fr_vsize):\n",
    "    \"\"\" Defining a NMT model \"\"\"\n",
    "\n",
    "    # Define an input sequence and process it.\n",
    "    if batch_size:\n",
    "        encoder_inputs = Input(batch_shape=(batch_size, en_timesteps, en_vsize))\n",
    "        decoder_inputs = Input(batch_shape=(batch_size, fr_timesteps - 1, fr_vsize))\n",
    "    else:\n",
    "        encoder_inputs = Input(shape=(en_timesteps, en_vsize))\n",
    "        if fr_timesteps!=None:\n",
    "            decoder_inputs = Input(shape=(fr_timesteps - 1, fr_vsize))\n",
    "        else:\n",
    "            decoder_inputs = Input(shape=(None, fr_vsize))\n",
    "\n",
    "    # Encoder GRU\n",
    "    encoder_gru = GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "    encoder_out, encoder_state = encoder_gru(encoder_inputs)\n",
    "\n",
    "    # Set up the decoder GRU, using `encoder_states` as initial state.\n",
    "    decoder_gru = GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "    decoder_out, decoder_state = decoder_gru(decoder_inputs, initial_state=encoder_state)\n",
    "\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer()\n",
    "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = Concatenate(axis=-1)([decoder_out, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    dense = Dense(fr_vsize, activation='softmax')\n",
    "    dense_time = TimeDistributed(dense)\n",
    "    decoder_pred = dense_time(decoder_concat_input)\n",
    "\n",
    "    # Full model\n",
    "    full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "    full_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    full_model.summary()\n",
    "\n",
    "    \"\"\" Inference model \"\"\"\n",
    "    batch_size = 1\n",
    "\n",
    "    \"\"\" Encoder (Inference) model \"\"\"\n",
    "    encoder_inf_inputs = Input(batch_shape=(batch_size, en_timesteps, en_vsize), name='encoder_inf_inputs')\n",
    "    encoder_inf_out, encoder_inf_state = encoder_gru(encoder_inf_inputs)\n",
    "    encoder_model = Model(inputs=encoder_inf_inputs, outputs=[encoder_inf_out, encoder_inf_state])\n",
    "\n",
    "    \"\"\" Decoder (Inference) model \"\"\"\n",
    "    decoder_inf_inputs = Input(batch_shape=(batch_size, 1, fr_vsize), name='decoder_word_inputs')\n",
    "    encoder_inf_states = Input(batch_shape=(batch_size, en_timesteps, hidden_size), name='encoder_inf_states')\n",
    "    decoder_init_state = Input(batch_shape=(batch_size, hidden_size), name='decoder_init')\n",
    "\n",
    "    decoder_inf_out, decoder_inf_state = decoder_gru(decoder_inf_inputs, initial_state=decoder_init_state)\n",
    "    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "    decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])\n",
    "    decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "    decoder_model = Model(inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "                          outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state])\n",
    "\n",
    "    return full_model, encoder_model, decoder_model\n",
    "\n",
    "\n",
    "m1,m2,m3 = define_nmt(1024, None, None, 20, None, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "psychological-chancellor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:55:22.692449Z",
     "iopub.status.busy": "2021-05-17T08:55:22.691733Z",
     "iopub.status.idle": "2021-05-17T08:55:22.725075Z",
     "shell.execute_reply": "2021-05-17T08:55:22.725616Z"
    },
    "id": "6O8dFDOHGbEb",
    "papermill": {
     "duration": 8.681276,
     "end_time": "2021-05-17T08:55:22.725765",
     "exception": false,
     "start_time": "2021-05-17T08:55:14.044489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b1adc0f04e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mta_rom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rejoined'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rejoined_aligned_cased'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.cased_nopunct.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rejoined_aligned'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv'"
     ]
    }
   ],
   "source": [
    "ta_rom = dict()\n",
    "ta_rom['rejoined'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv', sep='\\t', header=None, error_bad_lines=False)\n",
    "ta_rom['rejoined_aligned_cased'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.cased_nopunct.tsv', sep='\\t', header=None, error_bad_lines=False) \n",
    "ta_rom['rejoined_aligned'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.tsv', sep='\\t', header=None, error_bad_lines=False)\n",
    "ta_rom['split'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.tsv', sep='\\t', header=None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alert-scott",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:55:39.030897Z",
     "iopub.status.busy": "2021-05-17T08:55:39.030063Z",
     "iopub.status.idle": "2021-05-17T08:55:39.033530Z",
     "shell.execute_reply": "2021-05-17T08:55:39.034038Z"
    },
    "id": "e-WGvG_RJqsr",
    "papermill": {
     "duration": 7.972717,
     "end_time": "2021-05-17T08:55:39.034185",
     "exception": false,
     "start_time": "2021-05-17T08:55:31.061468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rejoined'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-af0f954bd438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rejoined'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'rejoined'"
     ]
    }
   ],
   "source": [
    "list(ta_rom['rejoined'].iloc[0, 0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "vocal-country",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:55:56.010815Z",
     "iopub.status.busy": "2021-05-17T08:55:55.994924Z",
     "iopub.status.idle": "2021-05-17T08:55:56.013716Z",
     "shell.execute_reply": "2021-05-17T08:55:56.014093Z"
    },
    "id": "p75rYpZkNCJV",
    "papermill": {
     "duration": 8.672667,
     "end_time": "2021-05-17T08:55:56.014241",
     "exception": false,
     "start_time": "2021-05-17T08:55:47.341574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rejoined_aligned_cased'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-28368eb70736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rejoined_aligned_cased'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'rejoined_aligned_cased'"
     ]
    }
   ],
   "source": [
    "ta_rom['rejoined_aligned_cased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "tight-visit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:56:12.278350Z",
     "iopub.status.busy": "2021-05-17T08:56:12.277711Z",
     "iopub.status.idle": "2021-05-17T08:56:12.280858Z",
     "shell.execute_reply": "2021-05-17T08:56:12.281267Z"
    },
    "id": "O0E9hQuQMULO",
    "papermill": {
     "duration": 7.994235,
     "end_time": "2021-05-17T08:56:12.281418",
     "exception": false,
     "start_time": "2021-05-17T08:56:04.287183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rejoined_aligned'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-14e6d4754d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rejoined_aligned'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'rejoined_aligned'"
     ]
    }
   ],
   "source": [
    "ta_rom['rejoined_aligned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "checked-hundred",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:56:29.151552Z",
     "iopub.status.busy": "2021-05-17T08:56:29.137047Z",
     "iopub.status.idle": "2021-05-17T08:56:29.155376Z",
     "shell.execute_reply": "2021-05-17T08:56:29.154853Z"
    },
    "id": "7yAnW0rAKDY5",
    "papermill": {
     "duration": 8.685924,
     "end_time": "2021-05-17T08:56:29.155493",
     "exception": false,
     "start_time": "2021-05-17T08:56:20.469569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1aa2fe6e9390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mta_rom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'split'"
     ]
    }
   ],
   "source": [
    "ta_rom['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "outer-dictionary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T08:56:45.349066Z",
     "iopub.status.busy": "2021-05-17T08:56:45.346877Z",
     "iopub.status.idle": "2021-05-17T08:56:45.351363Z",
     "shell.execute_reply": "2021-05-17T08:56:45.350887Z"
    },
    "id": "wD7CedwSKaoS",
    "papermill": {
     "duration": 7.986712,
     "end_time": "2021-05-17T08:56:45.351475",
     "exception": false,
     "start_time": "2021-05-17T08:56:37.364763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True]\n"
     ]
    }
   ],
   "source": [
    "l1 = [1,4,2,3]\n",
    "l2 = [1,4,2,5]\n",
    "print(np.array(l1[1:-1])==np.array(l2[1:-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5904.958316,
   "end_time": "2021-05-17T08:56:56.004384",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-17T07:18:31.046068",
   "version": "2.3.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "028e93e2502147188bcc3acb266efcad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d129cd83bdc147cab72f4b4201f56414",
       "placeholder": "​",
       "style": "IPY_MODEL_8afc66a3f3c545598b16373c96530440",
       "value": " 6833/6833 [50:57&lt;00:00,  1.69it/s]"
      }
     },
     "06bc79b8b31a4f889dbaa69171e09ef2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "30adf46b785a4b1a9977d39d9f4b3286": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e32f9eb01b3a4222ba8fd61cb1dab691",
       "placeholder": "​",
       "style": "IPY_MODEL_774ba493b69b4550bcaecaf8a8ee4687",
       "value": "100%"
      }
     },
     "43ae874186644f6ca831fab46d688c9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e98858b80b44987aef28d90fea112c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_30adf46b785a4b1a9977d39d9f4b3286",
        "IPY_MODEL_ce99f3a1b6914a3396178ff8133a1ee8",
        "IPY_MODEL_028e93e2502147188bcc3acb266efcad"
       ],
       "layout": "IPY_MODEL_43ae874186644f6ca831fab46d688c9c"
      }
     },
     "774ba493b69b4550bcaecaf8a8ee4687": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8afc66a3f3c545598b16373c96530440": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ce99f3a1b6914a3396178ff8133a1ee8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d04f2aebcaa94d5997f8e3af4f466d57",
       "max": 6833.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_06bc79b8b31a4f889dbaa69171e09ef2",
       "value": 6833.0
      }
     },
     "d04f2aebcaa94d5997f8e3af4f466d57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d129cd83bdc147cab72f4b4201f56414": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e32f9eb01b3a4222ba8fd61cb1dab691": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
