{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1733.940301,
      "end_time": "2021-05-17T08:27:17.469327",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-05-17T07:58:23.529026",
      "version": "2.3.3"
    },
    "colab": {
      "name": "Copy of rnn-second (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramkamal2000/cs6910_assignment3/blob/main/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so1dZJS0GYJD"
      },
      "source": [
        "# Mount Drive"
      ],
      "id": "so1dZJS0GYJD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aAtygLPGbR6",
        "outputId": "4503ff2d-ec9b-4360-a617-4aae33a59f80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "-aAtygLPGbR6",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebofaXxJGdxw"
      },
      "source": [
        "# Installing Required Packages"
      ],
      "id": "ebofaXxJGdxw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:58:30.565905Z",
          "iopub.status.busy": "2021-05-17T07:58:30.555309Z",
          "iopub.status.idle": "2021-05-17T07:58:43.754049Z",
          "shell.execute_reply": "2021-05-17T07:58:43.752754Z"
        },
        "id": "boxed-david",
        "papermill": {
          "duration": 13.232379,
          "end_time": "2021-05-17T07:58:43.754273",
          "exception": false,
          "start_time": "2021-05-17T07:58:30.521894",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094c8025-09bf-4d3c-b8db-ed2aff69c35a"
      },
      "source": [
        "!pip install editdistance\n",
        "!pip install wandb"
      ],
      "id": "boxed-david",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.30)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (8.0.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.17)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_BXG5ejGwc5"
      },
      "source": [
        "# Importing Required Libraries"
      ],
      "id": "q_BXG5ejGwc5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:58:43.857723Z",
          "iopub.status.busy": "2021-05-17T07:58:43.854304Z",
          "iopub.status.idle": "2021-05-17T07:58:49.338897Z",
          "shell.execute_reply": "2021-05-17T07:58:49.336450Z"
        },
        "id": "removed-sucking",
        "papermill": {
          "duration": 5.537908,
          "end_time": "2021-05-17T07:58:49.339068",
          "exception": false,
          "start_time": "2021-05-17T07:58:43.801160",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import editdistance\n",
        "import keras\n",
        "import numpy as np\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import pickle\n",
        "from keras import layers\n",
        "from keras.layers import LSTM, Dense, Embedding, Input, TimeDistributed, Dropout\n",
        "from keras.models import Model, save_model, load_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tqdm.auto import tqdm\n",
        "from keras.layers import Lambda\n",
        "from keras import backend as K\n",
        "from math import ceil\n",
        "from pprint import pprint"
      ],
      "id": "removed-sucking",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlssnZaqG0Eq"
      },
      "source": [
        "# Setting Current Directory"
      ],
      "id": "SlssnZaqG0Eq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:58:49.398272Z",
          "iopub.status.busy": "2021-05-17T07:58:49.397457Z",
          "iopub.status.idle": "2021-05-17T07:58:49.400445Z",
          "shell.execute_reply": "2021-05-17T07:58:49.399842Z"
        },
        "id": "cognitive-browse",
        "papermill": {
          "duration": 0.033796,
          "end_time": "2021-05-17T07:58:49.400583",
          "exception": false,
          "start_time": "2021-05-17T07:58:49.366787",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "dir = '/content'\n",
        "# dir = '/kaggle/working'"
      ],
      "id": "cognitive-browse",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZQKCuu0G9WG"
      },
      "source": [
        "# Downloading Dataset"
      ],
      "id": "kZQKCuu0G9WG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:58:49.465782Z",
          "iopub.status.busy": "2021-05-17T07:58:49.464820Z",
          "iopub.status.idle": "2021-05-17T07:59:08.380796Z",
          "shell.execute_reply": "2021-05-17T07:59:08.379736Z"
        },
        "id": "peaceful-bridge",
        "papermill": {
          "duration": 18.953473,
          "end_time": "2021-05-17T07:59:08.380973",
          "exception": false,
          "start_time": "2021-05-17T07:58:49.427500",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9931f592-9ced-4349-c856-0ed93eb8ec97"
      },
      "source": [
        "!wget -nc https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "\n",
        "if not os.path.isdir(dir + '/dakshina_dataset_v1.0'):\n",
        "  tarfile.open(dir + '/dakshina_dataset_v1.0.tar').extractall()"
      ],
      "id": "peaceful-bridge",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘dakshina_dataset_v1.0.tar’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju2vZCrgHEai"
      },
      "source": [
        "# Logging Onto wandb"
      ],
      "id": "Ju2vZCrgHEai"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:08.895229Z",
          "iopub.status.busy": "2021-05-17T07:59:08.894398Z",
          "iopub.status.idle": "2021-05-17T07:59:09.629090Z",
          "shell.execute_reply": "2021-05-17T07:59:09.628621Z"
        },
        "id": "engaging-hunger",
        "papermill": {
          "duration": 0.840661,
          "end_time": "2021-05-17T07:59:09.629243",
          "exception": false,
          "start_time": "2021-05-17T07:59:08.788582",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d698d5-f3c1-4f9f-ff8b-5fd6ab05c064"
      },
      "source": [
        "wandb.login(key='14394907543f59ea21931529e34b4d80d2ca8c9c', force=True)"
      ],
      "id": "engaging-hunger",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mramkamal\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adverse-prospect",
        "papermill": {
          "duration": 2.257279,
          "end_time": "2021-05-17T07:59:13.316150",
          "exception": false,
          "start_time": "2021-05-17T07:59:11.058871",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Loading Data"
      ],
      "id": "adverse-prospect"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:13.515679Z",
          "iopub.status.busy": "2021-05-17T07:59:13.514711Z",
          "iopub.status.idle": "2021-05-17T07:59:13.546524Z",
          "shell.execute_reply": "2021-05-17T07:59:13.547683Z"
        },
        "id": "adjustable-radio",
        "papermill": {
          "duration": 0.130224,
          "end_time": "2021-05-17T07:59:13.547911",
          "exception": false,
          "start_time": "2021-05-17T07:59:13.417687",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class data_loader():\n",
        "\n",
        "  @staticmethod\n",
        "  def _load_raw_df(languages = ['ta']):\n",
        "    lex = dict()\n",
        "    lex['train'], lex['val'], lex['test'] = [], [], [] \n",
        "    column_names = ['output', 'input', 'count']\n",
        "    \n",
        "    for la in languages:\n",
        "      lex['train'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.train.tsv', sep='\\t', header=None, names=column_names))\n",
        "      lex['val'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.dev.tsv', sep='\\t', header=None, names=column_names))\n",
        "      lex['test'].append(pd.read_csv(dir + '/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.test.tsv', sep='\\t', header=None, names=column_names))\n",
        "\n",
        "    lex['train'] = pd.concat(lex['train'])\n",
        "    lex['val'] = pd.concat(lex['val'])\n",
        "    lex['test'] = pd.concat(lex['test'])\n",
        "\n",
        "    return lex    \n",
        "\n",
        "  @staticmethod\n",
        "  def _make_final_df(lex):\n",
        "    \n",
        "    for div in ['train', 'val']:\n",
        "    \n",
        "      # removing non max transliterations\n",
        "      idx = lex[div].groupby(['input'])['count'].transform(max) == lex[div]['count']\n",
        "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
        "\n",
        "      # calclulating difference in lengths of various transliterations\n",
        "      lex[div]['input_len'] = lex[div].apply(lambda x: len(str(x['input'])), axis=1)\n",
        "      lex[div]['output_len'] = lex[div].apply(lambda y: len(str(y['output'])), axis=1)\n",
        "      lex[div]['mod_dif'] = lex[div].apply(lambda z: abs(z['input_len'] - z['output_len']), axis=1) \n",
        "\n",
        "      # removing transliterations that vary by a lot in length\n",
        "      idx = lex[div].groupby(['input'])['mod_dif'].transform(min) == lex[div]['mod_dif']\n",
        "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
        "\n",
        "      # removing duplicates if any remain\n",
        "      lex[div].drop_duplicates(subset='input', keep='first', inplace=True)\n",
        "\n",
        "      # removing redundant columns\n",
        "      lex[div].drop(labels=['count', 'input_len', 'output_len', 'mod_dif'], inplace=True, axis=1)\n",
        "\n",
        "      # shuffling the dataset i.e. rows of the dataset\n",
        "      lex[div] = lex[div].sample(frac=1, random_state=6910)\n",
        "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
        "\n",
        "    lex['test'] = lex['test'].sample(frac=1, random_state=6910)\n",
        "    lex['test'].drop(labels=['count'], axis=1, inplace=True)\n",
        "    lex['test'] = lex['test'].reset_index(drop=True)\n",
        "    return lex\n",
        "\n",
        "  @staticmethod\n",
        "  def _generate_batch(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
        "\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            \n",
        "            # placeholder data structures\n",
        "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, data_dict['max_target_length']),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
        "\n",
        "            # assessing one batch at a time\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "\n",
        "                for t, word in enumerate(input_text):\n",
        "                  encoder_input_data[i, t] = word\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t<len(target_text)-1:\n",
        "                        # decoder input sequence\n",
        "                        # does not include the <EOW> token\n",
        "                        decoder_input_data[i, t] = word \n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the <SOW> token\n",
        "                        decoder_target_data[i, t - 1, word] = 1.\n",
        "                    \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
        "\n",
        "  @staticmethod\n",
        "  def _generate_batch_greedy(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
        "\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "\n",
        "            # placeholder data structures\n",
        "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, 1),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
        "            \n",
        "            # assessing one batch at a time\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text):\n",
        "                  encoder_input_data[i, t] = word\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t==0 :\n",
        "                        decoder_input_data[i, t] = 1 # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        decoder_target_data[i, t - 1, word] = 1.\n",
        "                    \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "id": "adjustable-radio",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:13.770624Z",
          "iopub.status.busy": "2021-05-17T07:59:13.769678Z",
          "iopub.status.idle": "2021-05-17T07:59:13.784726Z",
          "shell.execute_reply": "2021-05-17T07:59:13.785846Z"
        },
        "id": "supposed-nation",
        "papermill": {
          "duration": 0.127225,
          "end_time": "2021-05-17T07:59:13.786080",
          "exception": false,
          "start_time": "2021-05-17T07:59:13.658855",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class Tokenizer:\n",
        "\n",
        "  def __init__(self, df):\n",
        "\n",
        "    self.start_token = '<SOW>'\n",
        "    self.stop_token = '<EOW>'\n",
        "    self.unknown_token = '<UNK>'\n",
        "\n",
        "    self.input_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
        "    self.output_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
        "\n",
        "    input_words = df.input.tolist()\n",
        "    output_words = df.output.tolist()\n",
        "\n",
        "    for word in input_words:\n",
        "      tokens = str(word)\n",
        "      for token in tokens:\n",
        "        if token not in self.input_corpus:\n",
        "          self.input_corpus.append(token)\n",
        "\n",
        "    for word in output_words:\n",
        "      tokens = str(word)\n",
        "      for token in tokens:\n",
        "        if token not in self.output_corpus:\n",
        "          self.output_corpus.append(token)\n",
        "    \n",
        "    self.encode_dict_input = {self.input_corpus[i] : i+1 for i in range(len(self.input_corpus))}\n",
        "    self.decode_dict_input = {k:v for v,k in self.encode_dict_input.items()}\n",
        "    \n",
        "    \n",
        "    self.encode_dict_output = {self.output_corpus[i] : i+1 for i in range(len(self.output_corpus))}\n",
        "    self.decode_dict_output = {k:v for v,k in self.encode_dict_output.items()}\n",
        "    self.decode_dict_output.update({2:''})\n",
        "\n",
        "  # takes in lists of words and returns lists of integers\n",
        "  def encode(self, X, mode='input'):\n",
        "\n",
        "    if (mode=='input'):\n",
        "      input_list = []\n",
        "      for word in X:\n",
        "        word = str(word)\n",
        "        integer_list =np.array([self.encode_dict_input.get(token, self.encode_dict_input[self.unknown_token]) for token in word])\n",
        "        input_list.append(integer_list)\n",
        "      \n",
        "      return input_list\n",
        "    \n",
        "    if (mode=='output'):\n",
        "      output_list = []\n",
        "      for word in X:\n",
        "        word = str(word)\n",
        "        integer_list = np.array([self.encode_dict_output[self.start_token]] + [self.encode_dict_output.get(token, self.encode_dict_output[self.unknown_token]) for token in word] + [self.encode_dict_output[self.stop_token]])\n",
        "        output_list.append(integer_list)\n",
        "      \n",
        "      return output_list\n",
        "    \n",
        "  # takes in lists of integers and returns lists of words\n",
        "  def decode(self, X, mode='input'):\n",
        "\n",
        "    if (mode=='input'):\n",
        "      input_list = []\n",
        "      for integers in X:\n",
        "        token_list=[]\n",
        "        for integer in integers :\n",
        "          if integer == 2 :\n",
        "            break\n",
        "          token_list.append(self.decode_dict_input.get(integer, '')) \n",
        "        input_list.append(''.join(token_list))\n",
        "      \n",
        "      return input_list\n",
        "\n",
        "    if (mode=='output'):\n",
        "      output_list = []\n",
        "      for integers in X:\n",
        "        token_list=[]\n",
        "        for integer in integers :\n",
        "          if integer == 2 :\n",
        "            break\n",
        "          token_list.append(self.decode_dict_output.get(integer, '')) \n",
        "        output_list.append(''.join(token_list))\n",
        "      \n",
        "      return output_list"
      ],
      "id": "supposed-nation",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:26.209819Z",
          "iopub.status.busy": "2021-05-17T07:59:26.208208Z",
          "iopub.status.idle": "2021-05-17T07:59:26.210492Z",
          "shell.execute_reply": "2021-05-17T07:59:26.210885Z"
        },
        "id": "aerial-direction",
        "papermill": {
          "duration": 1.490287,
          "end_time": "2021-05-17T07:59:26.211017",
          "exception": false,
          "start_time": "2021-05-17T07:59:24.720730",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def return_data_dict(languages=['ta'], batch_size=32):\n",
        "\n",
        "  lex = data_loader._load_raw_df(languages)\n",
        "  lex = data_loader._make_final_df(lex)\n",
        "\n",
        "  data_dict = dict()\n",
        "\n",
        "  df_train = lex['train']\n",
        "  df_val = lex['val']\n",
        "  df_test = lex['test']\n",
        "\n",
        "  tk = Tokenizer(df_train)\n",
        "\n",
        "  data_dict['in_size'] = len(tk.input_corpus) + 1\n",
        "  data_dict['out_size'] = len(tk.output_corpus) + 1\n",
        "\n",
        "  X_train = tk.encode(df_train.input.tolist(), mode='input')\n",
        "  Y_train = tk.encode(df_train.output.tolist(), mode='output')\n",
        "  \n",
        "  X_val = tk.encode(df_val.input.tolist(), mode='input')\n",
        "  Y_val = tk.encode(df_val.output.tolist(), mode='output')\n",
        "\n",
        "  X_test = tk.encode(df_val.input.tolist(), mode='input')\n",
        "  Y_test = tk.encode(df_val.output.tolist(), mode='output')\n",
        "\n",
        "\n",
        "  data_dict['train'], data_dict['val'], data_dict['test']= dict(), dict(), dict()\n",
        "\n",
        "\n",
        "  data_dict['train']['df'] = df_train\n",
        "  data_dict['val']['df'] = df_val\n",
        "  data_dict['test']['df'] = df_test\n",
        "\n",
        "\n",
        "  data_dict['train']['max_source_length'] = np.max(np.array([len(x) for x in X_train]))\n",
        "  data_dict['train']['max_target_length'] = np.max(np.array([len(x) for x in Y_train]))\n",
        "  \n",
        "  data_dict['val']['max_source_length'] = np.max(np.array([len(x) for x in X_val]))\n",
        "  data_dict['val']['max_target_length'] = np.max(np.array([len(x) for x in Y_val]))\n",
        "\n",
        "  data_dict['test']['max_source_length'] = np.max(np.array([len(x) for x in X_test]))\n",
        "  data_dict['test']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
        "\n",
        "  data_dict['max_source_length'] = max(data_dict['train']['max_source_length'], data_dict['val']['max_source_length'])\n",
        "  data_dict['max_target_length'] = max(data_dict['train']['max_target_length'], data_dict['val']['max_target_length'])\n",
        "\n",
        "  data_dict['train']['batch'] = data_loader._generate_batch(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['train']['batch_greedy'] = data_loader._generate_batch_greedy(X_train, Y_train, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['train']['batch_greedy_big'] = data_loader._generate_batch_greedy(X_train, Y_train, data_dict, data_dict['out_size'], 1024)\n",
        "  \n",
        "  data_dict['val']['batch'] = data_loader._generate_batch(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['val']['batch_greedy'] = data_loader._generate_batch_greedy(X_val, Y_val, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['val']['batch_greedy_big'] = data_loader._generate_batch_greedy(X_val, Y_val, data_dict, data_dict['out_size'], 1024)\n",
        "\n",
        "  data_dict['test']['batch'] = data_loader._generate_batch(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['test']['batch_greedy'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], batch_size)\n",
        "  data_dict['test']['batch_greedy_big'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict, data_dict['out_size'], len(X_test))\n",
        "\n",
        "  data_dict['tokenizer'] = tk\n",
        "\n",
        "  return data_dict"
      ],
      "id": "aerial-direction",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:29.487914Z",
          "iopub.status.busy": "2021-05-17T07:59:29.482835Z",
          "iopub.status.idle": "2021-05-17T07:59:34.481820Z",
          "shell.execute_reply": "2021-05-17T07:59:34.482247Z"
        },
        "id": "determined-rouge",
        "papermill": {
          "duration": 6.65519,
          "end_time": "2021-05-17T07:59:34.482415",
          "exception": false,
          "start_time": "2021-05-17T07:59:27.827225",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8064c1-efe6-43c3-b6dd-33dca61aa66f"
      },
      "source": [
        "dict_data_dict = dict()\n",
        "\n",
        "for batch_size in [32]:\n",
        "  dict_data_dict.update({batch_size: return_data_dict(batch_size=batch_size)})\n",
        "\n",
        "data_dict = list(dict_data_dict.values())[0]"
      ],
      "id": "determined-rouge",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "recovered-things",
        "papermill": {
          "duration": 0.041762,
          "end_time": "2021-05-17T07:59:34.566554",
          "exception": false,
          "start_time": "2021-05-17T07:59:34.524792",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Question 1\n"
      ],
      "id": "recovered-things"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:34.672609Z",
          "iopub.status.busy": "2021-05-17T07:59:34.671296Z",
          "iopub.status.idle": "2021-05-17T07:59:34.673503Z",
          "shell.execute_reply": "2021-05-17T07:59:34.673988Z"
        },
        "id": "intermediate-vinyl",
        "papermill": {
          "duration": 0.065401,
          "end_time": "2021-05-17T07:59:34.674168",
          "exception": false,
          "start_time": "2021-05-17T07:59:34.608767",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class rnn():\n",
        "\n",
        "  def __init__(self, params):\n",
        "    \n",
        "    num_encode_layers = params['num_encode_layers']\n",
        "    num_decode_layers = params['num_decode_layers']\n",
        "    data_dict = params['data_dict']\n",
        "    in_size = params['data_dict']['in_size']\n",
        "    out_size = params['data_dict']['out_size']\n",
        "    cell_type = params['cell_type']\n",
        "    dropout = params['dropout']\n",
        "    embed_size = params['embed_size']\n",
        "    rep_size = params['rep_size']\n",
        "        \n",
        "    ###################### ENCODER NETWORK ######################\n",
        "    \n",
        "    encoder_inputs = Input(shape=(None,))\n",
        "    x = Embedding(in_size, embed_size ,mask_zero=True)(encoder_inputs)\n",
        "\n",
        "    encoder_layers = []\n",
        "    \n",
        "    for j in range(num_encode_layers-1) :   \n",
        "      curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_sequences=True)\n",
        "      encoder_layers.append(curr_layer)\n",
        "      x = curr_layer(x)\n",
        "\n",
        "    curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_state=True)\n",
        "    encoder_layers.append(curr_layer)\n",
        "    x, *encoder_states = curr_layer(x)\n",
        "\n",
        "    ###################### DECODER NETWORK ######################\n",
        "\n",
        "    decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "    decoder_embedding =  Embedding(out_size, embed_size, mask_zero=True)\n",
        "    x = decoder_embedding(decoder_inputs)\n",
        "\n",
        "    decoder_layers = []    \n",
        "    \n",
        "    for j in range(num_decode_layers) :\n",
        "      curr_layer = getattr(layers, cell_type)(rep_size,dropout=dropout,return_state=True, return_sequences=True)\n",
        "      decoder_layers.append(curr_layer)\n",
        "      x, *decoder_states = curr_layer(x, initial_state=encoder_states)\n",
        "\n",
        "    x = Dropout(dropout)(x)\n",
        "    decoder_dense = TimeDistributed(Dense(units=out_size, activation='softmax'))\n",
        "    decoder_outputs = decoder_dense(x)\n",
        "\n",
        "    # define the model that will turn `encoder_inputs` & `decoder_inputs` into `decoder_outputs`\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    self.model = model\n",
        "    self.encoder_inputs = encoder_inputs\n",
        "    # self.encoder_layers = encoder_layers\n",
        "    self.decoder_inputs = decoder_inputs\n",
        "    self.decoder_embedding = decoder_embedding\n",
        "    self.decoder_layers = decoder_layers\n",
        "    self.decoder_dense = decoder_dense\n",
        "    self.encoder_states = encoder_states\n",
        "    self.params = params\n",
        "    self.details = {\n",
        "        'model' : self.model,\n",
        "        'encoder_inputs' : self.encoder_inputs,\n",
        "        # 'encoder_layers' :self.encoder_layers ,\n",
        "        'decoder_inputs' :self.decoder_inputs ,\n",
        "        'decoder_embedding' : self.decoder_embedding,\n",
        "        'decoder_layers' : self.decoder_layers,\n",
        "        'decoder_dense' : self.decoder_dense,\n",
        "        'encoder_states' : self.encoder_states ,\n",
        "        'params' :self.params,\n",
        "    }\n",
        "\n",
        "  def compile_and_fit(self, data_dict, params):\n",
        "\n",
        "    # compiling the model\n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "    \n",
        "    # printing the summary of the model\n",
        "    summary = self.model.summary()\n",
        "\n",
        "    # plotting the model figure\n",
        "    plot = plot_model(self.model, show_shapes=True)\n",
        "    \n",
        "    # total training samples\n",
        "    train_samples = len(data_dict['train']['df'])\n",
        "\n",
        "    # total validation samples\n",
        "    val_samples = len(data_dict['val']['df'])    \n",
        "    \n",
        "    # batch size\n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    # number of epochs\n",
        "    num_epochs = params['num_epochs']\n",
        "\n",
        "    # training the model\n",
        "    run_details = self.model.fit_generator(generator = data_dict['train']['batch'],\n",
        "                                           steps_per_epoch = train_samples//batch_size,\n",
        "                                           epochs=num_epochs,\n",
        "                                           callbacks=[\n",
        "                                                      wandb.keras.WandbCallback()\n",
        "                                                      ],\n",
        "                                           validation_data = data_dict['val']['batch'], \n",
        "                                           validation_steps = val_samples//batch_size\n",
        "                                          )\n",
        "\n",
        "    return {\n",
        "        'run_details' : run_details\n",
        "    }\n",
        "\n",
        "    "
      ],
      "id": "intermediate-vinyl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:34.795265Z",
          "iopub.status.busy": "2021-05-17T07:59:34.794157Z",
          "iopub.status.idle": "2021-05-17T07:59:34.796989Z",
          "shell.execute_reply": "2021-05-17T07:59:34.796581Z"
        },
        "id": "divine-richmond",
        "papermill": {
          "duration": 0.075767,
          "end_time": "2021-05-17T07:59:34.797108",
          "exception": false,
          "start_time": "2021-05-17T07:59:34.721341",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class rnn_second() :\n",
        "  def __init__(self, details=None) :\n",
        "\n",
        "    if details is not None:\n",
        "      # copying required details\n",
        "      self.details = details\n",
        "\n",
        "      # copying decoder state input\n",
        "      decoder_state_input = self.details['encoder_states']\n",
        "\n",
        "      decoder_inputs = Input(shape=(1,))\n",
        "\n",
        "      # copying hidden representation size\n",
        "      rep_size = self.details['params']['rep_size']\n",
        "\n",
        "      # copying decoder inputs\n",
        "      # decoder_inputs = self.details['decoder_inputs']\n",
        "\n",
        "      # the decoder model\n",
        "      x = self.details['decoder_embedding'](decoder_inputs)\n",
        "    \n",
        "      all_outputs = []\n",
        "      for _ in range(self.details['params']['data_dict']['max_target_length']) :\n",
        "          for layer in self.details['decoder_layers'] :\n",
        "              x, *decoder_states = layer(x, initial_state=decoder_state_input)\n",
        "\n",
        "          x = self.details['decoder_dense'](x)\n",
        "\n",
        "          # appending the softmax output\n",
        "          all_outputs.append(x)\n",
        "\n",
        "          # taking the argmax to feed into the next time step\n",
        "          # print(\"Hello \",tf.math.argmax(x, 2))\n",
        "          # if int(tf.math.argmax(x, 2))==2:\n",
        "          #     x = 0\n",
        "          # else:\n",
        "          #     x = tf.math.argmax(x, 2)\n",
        "          x = tf.math.argmax(x, 2) \n",
        "          x = self.details['decoder_embedding'](x)\n",
        "          \n",
        "          # decoder state input for the next time step\n",
        "          decoder_state_input = decoder_states\n",
        "\n",
        "      ##### ????? ????? ????? ????? ????? ????? ????? ????? ????? ?????\n",
        "      # where do we evaluate stop condition?\n",
        "\n",
        "      decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "      model = Model([self.details['encoder_inputs'], decoder_inputs], decoder_outputs)\n",
        "      self.model = model\n",
        "    \n",
        "    else:\n",
        "      self.details = None \n",
        "      self.model = None\n",
        "\n",
        "  def compile_and_fit(self, data_dict, params) :\n",
        "\n",
        "    # compiling the model\n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "     # printing the summary of the model   \n",
        "    summary = self.model.summary()\n",
        "\n",
        "    # plotting the model figure\n",
        "    plot = plot_model(self.model, show_shapes=True)\n",
        "    \n",
        "    # total training samples\n",
        "    train_samples = len(data_dict['train']['df'])\n",
        "\n",
        "    # total validation samples \n",
        "    val_samples = len(data_dict['val']['df'])\n",
        "\n",
        "    # batch size   \n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    # number of epochs\n",
        "    num_epochs = params['num_epochs_2']\n",
        "\n",
        "    # training the model\n",
        "    run_details = self.model.fit_generator(generator = data_dict['train']['batch_greedy'],\n",
        "                                            steps_per_epoch = train_samples//batch_size,\n",
        "                                            epochs=num_epochs,\n",
        "                                            callbacks=[\n",
        "                                                      wandb.keras.WandbCallback()\n",
        "                                                      ],\n",
        "                                            validation_data = data_dict['val']['batch_greedy'],\n",
        "                                            validation_steps = val_samples//batch_size)\n",
        "   \n",
        "    return {\n",
        "        'run_details' : run_details\n",
        "    }\n",
        "\n",
        "  def evaluate(self, data_dict, train=False) :\n",
        "\n",
        "    if train :\n",
        "      test_gen = data_dict['train']['batch_greedy_big']\n",
        "    \n",
        "      # number of test samples\n",
        "      test_samples = len(data_dict['train']['df'])\n",
        "      # test_samples=100\n",
        "    \n",
        "      batch_size=1024\n",
        "\n",
        "      num_hits = 0\n",
        "      num_edits = 0\n",
        "\n",
        "      for i in tqdm(range(test_samples//batch_size)) :\n",
        "\n",
        "        (a,b),c = next(test_gen)\n",
        "        c = np.argmax(c, axis=2)\n",
        "        # print(c)\n",
        "        l1 = data_dict['tokenizer'].decode(c, mode='output')\n",
        "        out = self.model.predict([a,b])\n",
        "        out = np.argmax(out,axis=2) \n",
        "        l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
        "        num_hits += np.sum(np.array(l1)==np.array(l2))\n",
        "        num_edits += get_score(l1,l2)\n",
        "\n",
        "      print(\"Final Train Acc \", num_hits/test_samples)\n",
        "      print(\"Editdistance Train Avg \",num_edits/test_samples)\n",
        "      wandb.log({\"final_train_acc\":  num_hits/test_samples, \n",
        "               \"editdistance_train_acc\":  num_edits/test_samples})\n",
        "\n",
        "    # test batch generator\n",
        "    test_gen = data_dict['val']['batch_greedy_big']\n",
        "     \n",
        "    # number of test samples\n",
        "    test_samples = len(data_dict['val']['df'])\n",
        "    # test_samples=100\n",
        "    batch_size=1024\n",
        "    \n",
        "    num_hits = 0\n",
        "    num_edits = 0\n",
        "    for _ in tqdm(range(test_samples//batch_size)) :\n",
        "      (a,b),c = next(test_gen)\n",
        "      c = np.argmax(c, axis=2)\n",
        "      # print(c)\n",
        "      l1 = data_dict['tokenizer'].decode(c, mode='output')\n",
        "      out = self.model.predict([a,b])\n",
        "      out = np.argmax(out,axis=2) \n",
        "      l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
        "      num_hits += np.sum(np.array(l1)==np.array(l2))\n",
        "      num_edits += get_score(l1,l2)\n",
        "      # print(l1, l2)\n",
        "      # print(out)\n",
        "\n",
        "    print(\"Final Val Acc \", num_hits/test_samples)\n",
        "    print(\"Editdistance Val Avg \",num_edits/test_samples)\n",
        "    wandb.log({\"final_val_acc\":  num_hits/test_samples, \n",
        "               \"editdistance_val_acc\":  num_edits/test_samples})\n",
        "    \n",
        "  def evaluate_test(self, data_dict,filename):\n",
        "    test_gen = data_dict['test']['batch_greedy_big']\n",
        "     \n",
        "    # number of test samples\n",
        "    test_samples = len(data_dict['test']['df'])\n",
        "    # test_samples=100\n",
        "    batch_size=test_samples\n",
        "    \n",
        "    num_hits = 0\n",
        "    num_edits = 0\n",
        "\n",
        "    X = []\n",
        "    Y_true = []\n",
        "    Y_pred = []\n",
        "    outputs = []\n",
        "    \n",
        "    for _ in tqdm(range(test_samples//batch_size)) :\n",
        "      (a,b),c = next(test_gen)\n",
        "      c = np.argmax(c, axis=2)\n",
        "      # print(c)\n",
        "      l1 = data_dict['tokenizer'].decode(c, mode='output')\n",
        "      out = self.model.predict([a,b])\n",
        "      out = np.argmax(out,axis=2) \n",
        "      l2 = data_dict['tokenizer'].decode(out, mode='output')\n",
        "      \n",
        "      ###############################################################\n",
        "      <X.append(<INPUT STRING!>)>\n",
        "      Y_true.append(l1)\n",
        "      Y_pred.append(l2)\n",
        "      \n",
        "      num_hits += np.sum(np.array(l1)==np.array(l2))\n",
        "      num_edits += get_score(l1,l2)\n",
        "      # print(l1, l2)\n",
        "      # print(out)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "      'X': X,\n",
        "      'Y_true': Y_true,\n",
        "      'Y_pred': Y_pred\n",
        "    })\n",
        "\n",
        "    df.to_csv(filename)\n",
        "    try:\n",
        "      wandb.log({'rnn_greedy_csv': df})\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    '''\n",
        "    with open(filename, 'wb') as f:\n",
        "       pickle.dump([inputs,outputs], f)\n",
        "    '''\n",
        "    \n",
        "    print(\"Final Test Acc \", num_hits/test_samples)\n",
        "    print(\"Editdistance Test Avg \",num_edits/test_samples)\n",
        "    wandb.log({\"final_test_acc\":  num_hits/test_samples, \n",
        "               \"editdistance_test_acc\":  num_edits/test_samples})"
      ],
      "id": "divine-richmond",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrHGZ341Piiq"
      },
      "source": [
        "# Helper Function For Editdistance"
      ],
      "id": "xrHGZ341Piiq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:34.890447Z",
          "iopub.status.busy": "2021-05-17T07:59:34.889579Z",
          "iopub.status.idle": "2021-05-17T07:59:34.892115Z",
          "shell.execute_reply": "2021-05-17T07:59:34.891707Z"
        },
        "id": "personalized-festival",
        "papermill": {
          "duration": 0.051102,
          "end_time": "2021-05-17T07:59:34.892246",
          "exception": false,
          "start_time": "2021-05-17T07:59:34.841144",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def get_score(A,B) :\n",
        "  fin = 0\n",
        "  for a,b in zip(A,B) :\n",
        "    if len(a)>0 or len(b)>0:   \n",
        "      j = editdistance.eval(a,b)\n",
        "      fin += 1 - j/max(len(a),len(b))\n",
        "  return fin"
      ],
      "id": "personalized-festival",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWBXS9j9Ppb4"
      },
      "source": [
        "# Helper Function For Assigning Sweep Parameters"
      ],
      "id": "mWBXS9j9Ppb4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:35.340293Z",
          "iopub.status.busy": "2021-05-17T07:59:35.339348Z",
          "iopub.status.idle": "2021-05-17T07:59:35.343592Z",
          "shell.execute_reply": "2021-05-17T07:59:35.344341Z"
        },
        "id": "local-entertainment",
        "papermill": {
          "duration": 0.121081,
          "end_time": "2021-05-17T07:59:35.344574",
          "exception": false,
          "start_time": "2021-05-17T07:59:35.223493",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class tools:\n",
        "  def init_params(config,data_dict):\n",
        "  \n",
        "    # returning parameters\n",
        "    params = {\n",
        "        'num_encode_layers' : config.num_encode_layers,\n",
        "        'num_decode_layers' : config.num_decode_layers,\n",
        "        'cell_type' : config.cell_type,\n",
        "        'rep_size' : config.rep_size,\n",
        "        'embed_size' : config.embed_size,\n",
        "        'dropout' : config.dropout,\n",
        "        'num_epochs' : config.num_epochs,\n",
        "        'data_dict' : data_dict,\n",
        "        'batch_size' : config.batch_size\n",
        "    }\n",
        "    return params"
      ],
      "id": "local-entertainment",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:35.539499Z",
          "iopub.status.busy": "2021-05-17T07:59:35.537639Z",
          "iopub.status.idle": "2021-05-17T07:59:35.540053Z",
          "shell.execute_reply": "2021-05-17T07:59:35.540458Z"
        },
        "id": "addressed-dietary",
        "papermill": {
          "duration": 0.057882,
          "end_time": "2021-05-17T07:59:35.540589",
          "exception": false,
          "start_time": "2021-05-17T07:59:35.482707",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "sweep configuration\n",
        "sweep_config = {\n",
        "    \n",
        "    'method' : 'bayes',\n",
        "    'metric' : {\n",
        "        'name' : 'val_acc',\n",
        "        'goal' : 'maximize'\n",
        "    },\n",
        "    \n",
        "    'parameters': {\n",
        "        'cell_type' : {\n",
        "            'values': ['LSTM', 'GRU', 'SimpleRNN']  \n",
        "        },\n",
        "        'embed_size': {\n",
        "            'values': [2, 4, 8, 16]\n",
        "        },\n",
        "        'rep_size': {\n",
        "            'values': [32, 64, 128, 256]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32]\n",
        "        },\n",
        "        'num_epochs': {\n",
        "            'values': [5, 15, 25]\n",
        "        },\n",
        "        'num_encode_layers': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'num_decode_layers': {\n",
        "            'values': [1, 2, 3]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "id": "addressed-dietary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:35.631195Z",
          "iopub.status.busy": "2021-05-17T07:59:35.629754Z",
          "iopub.status.idle": "2021-05-17T07:59:35.632025Z",
          "shell.execute_reply": "2021-05-17T07:59:35.632476Z"
        },
        "id": "objective-moisture",
        "papermill": {
          "duration": 0.049119,
          "end_time": "2021-05-17T07:59:35.632609",
          "exception": false,
          "start_time": "2021-05-17T07:59:35.583490",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# sweep_id = wandb.sweep(sweep_config, project='dakshina_v6')"
      ],
      "id": "objective-moisture",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:35.724859Z",
          "iopub.status.busy": "2021-05-17T07:59:35.724062Z",
          "iopub.status.idle": "2021-05-17T07:59:35.726732Z",
          "shell.execute_reply": "2021-05-17T07:59:35.726346Z"
        },
        "id": "nutritional-madagascar",
        "papermill": {
          "duration": 0.051359,
          "end_time": "2021-05-17T07:59:35.726840",
          "exception": false,
          "start_time": "2021-05-17T07:59:35.675481",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class sweep_module:\n",
        "  @staticmethod\n",
        "  def train(config=None):\n",
        "\n",
        "    with wandb.init(config):\n",
        "      \n",
        "      # copying the config \n",
        "      config = wandb.config\n",
        " \n",
        "      # naming the run\n",
        "      wandb.run.name = 'typ:'+config['cell_type'][:4]+ '_' + 'dro:'+str(config['dropout'])+ '_' + 'enc:' + str(config['num_encode_layers'])+ '_' + 'dec:'+str(config['num_decode_layers'])\n",
        "      \n",
        "      # returning the data dictionairy\n",
        "      data_dict = dict_data_dict[config.batch_size]\n",
        "\n",
        "      # copying the parameters\n",
        "      params = tools.init_params(config,data_dict)\n",
        "\n",
        "      # creating and training the first model\n",
        "      network = rnn(params)\n",
        "      run_details = network.compile_and_fit(data_dict, params)\n",
        "\n",
        "      rnn_2 = rnn_second(network.details)\n",
        "      rnn_2.evaluate(data_dict,train=True)"
      ],
      "id": "nutritional-madagascar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:35.817639Z",
          "iopub.status.busy": "2021-05-17T07:59:35.816823Z",
          "iopub.status.idle": "2021-05-17T07:59:35.819395Z",
          "shell.execute_reply": "2021-05-17T07:59:35.818986Z"
        },
        "id": "passive-dispatch",
        "papermill": {
          "duration": 0.049495,
          "end_time": "2021-05-17T07:59:35.819508",
          "exception": false,
          "start_time": "2021-05-17T07:59:35.770013",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# sweep_id = '1gv485mq'"
      ],
      "id": "passive-dispatch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:35.909776Z",
          "iopub.status.busy": "2021-05-17T07:59:35.908973Z",
          "iopub.status.idle": "2021-05-17T07:59:35.911744Z",
          "shell.execute_reply": "2021-05-17T07:59:35.911345Z"
        },
        "id": "measured-fellowship",
        "papermill": {
          "duration": 0.049521,
          "end_time": "2021-05-17T07:59:35.911865",
          "exception": false,
          "start_time": "2021-05-17T07:59:35.862344",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# performing the sweep\n",
        "# wandb.agent(sweep_id, sweep_module.train)"
      ],
      "id": "measured-fellowship",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brutal-virus",
        "papermill": {
          "duration": 0.043263,
          "end_time": "2021-05-17T07:59:35.998604",
          "exception": false,
          "start_time": "2021-05-17T07:59:35.955341",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Best Model"
      ],
      "id": "brutal-virus"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:36.089949Z",
          "iopub.status.busy": "2021-05-17T07:59:36.089161Z",
          "iopub.status.idle": "2021-05-17T07:59:36.092002Z",
          "shell.execute_reply": "2021-05-17T07:59:36.091609Z"
        },
        "id": "rolled-banner",
        "papermill": {
          "duration": 0.050485,
          "end_time": "2021-05-17T07:59:36.092110",
          "exception": false,
          "start_time": "2021-05-17T07:59:36.041625",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "params = {\n",
        "    'num_encode_layers' : 3,\n",
        "    'num_decode_layers' : 1,\n",
        "    'cell_type' : 'LSTM', \n",
        "    'rep_size' : 128,\n",
        "    'embed_size' : 16,\n",
        "    'dropout' : 0.5,\n",
        "    'num_epochs' : 25,\n",
        "    'data_dict' : data_dict,\n",
        "    'batch_size' : 32\n",
        "}"
      ],
      "id": "rolled-banner",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:36.187064Z",
          "iopub.status.busy": "2021-05-17T07:59:36.186328Z",
          "iopub.status.idle": "2021-05-17T07:59:39.471697Z",
          "shell.execute_reply": "2021-05-17T07:59:39.472426Z"
        },
        "id": "equipped-discretion",
        "papermill": {
          "duration": 3.336961,
          "end_time": "2021-05-17T07:59:39.472585",
          "exception": false,
          "start_time": "2021-05-17T07:59:36.135624",
          "status": "completed"
        },
        "tags": [],
        "outputId": "78e4ab6b-60d8-4503-8b90-39c3fb5e3f89"
      },
      "source": [
        "wandb.init(project='final_rnn')"
      ],
      "id": "equipped-discretion",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mramkamal\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.26<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">gentle-thunder-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ramkamal/uncategorized\" target=\"_blank\">https://wandb.ai/ramkamal/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ramkamal/uncategorized/runs/2d83du1u\" target=\"_blank\">https://wandb.ai/ramkamal/uncategorized/runs/2d83du1u</a><br/>\n",
              "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210517_075936-2d83du1u</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<h1>Run(2d83du1u)</h1><iframe src=\"https://wandb.ai/ramkamal/uncategorized/runs/2d83du1u\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f69842cbb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T07:59:39.587626Z",
          "iopub.status.busy": "2021-05-17T07:59:39.586752Z",
          "iopub.status.idle": "2021-05-17T08:21:32.464771Z",
          "shell.execute_reply": "2021-05-17T08:21:32.464046Z"
        },
        "id": "awful-polish",
        "papermill": {
          "duration": 1312.945565,
          "end_time": "2021-05-17T08:21:32.464927",
          "exception": false,
          "start_time": "2021-05-17T07:59:39.519362",
          "status": "completed"
        },
        "tags": [],
        "outputId": "ed98f98b-16f5-4113-847c-7e1af1e09a3a"
      },
      "source": [
        "network = rnn(params)\n",
        "network.compile_and_fit(data_dict, params)"
      ],
      "id": "awful-polish",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 16)     480         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 128)    74240       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, None, 128)    131584      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 16)     800         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 128), (None, 131584      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 128),  74240       embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 50)     6450        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 419,378\n",
            "Trainable params: 419,378\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "2056/2056 [==============================] - 69s 26ms/step - loss: 0.8787 - acc: 0.3044 - val_loss: 0.5295 - val_acc: 0.5245\n",
            "Epoch 2/25\n",
            "2056/2056 [==============================] - 50s 24ms/step - loss: 0.5833 - acc: 0.5147 - val_loss: 0.3990 - val_acc: 0.6358\n",
            "Epoch 3/25\n",
            "2056/2056 [==============================] - 49s 24ms/step - loss: 0.4651 - acc: 0.6114 - val_loss: 0.3351 - val_acc: 0.6954\n",
            "Epoch 4/25\n",
            "2056/2056 [==============================] - 51s 25ms/step - loss: 0.4021 - acc: 0.6638 - val_loss: 0.2910 - val_acc: 0.7389\n",
            "Epoch 5/25\n",
            "2056/2056 [==============================] - 49s 24ms/step - loss: 0.3552 - acc: 0.7053 - val_loss: 0.2554 - val_acc: 0.7739\n",
            "Epoch 6/25\n",
            "2056/2056 [==============================] - 51s 25ms/step - loss: 0.3171 - acc: 0.7392 - val_loss: 0.2264 - val_acc: 0.8019\n",
            "Epoch 7/25\n",
            "2056/2056 [==============================] - 50s 24ms/step - loss: 0.2842 - acc: 0.7696 - val_loss: 0.2074 - val_acc: 0.8187\n",
            "Epoch 8/25\n",
            "2056/2056 [==============================] - 52s 25ms/step - loss: 0.2608 - acc: 0.7897 - val_loss: 0.1934 - val_acc: 0.8349\n",
            "Epoch 9/25\n",
            "2056/2056 [==============================] - 50s 24ms/step - loss: 0.2417 - acc: 0.8065 - val_loss: 0.1820 - val_acc: 0.8452\n",
            "Epoch 10/25\n",
            "2056/2056 [==============================] - 52s 25ms/step - loss: 0.2267 - acc: 0.8189 - val_loss: 0.1722 - val_acc: 0.8567\n",
            "Epoch 11/25\n",
            "2056/2056 [==============================] - 50s 24ms/step - loss: 0.2146 - acc: 0.8289 - val_loss: 0.1662 - val_acc: 0.8630\n",
            "Epoch 12/25\n",
            "2056/2056 [==============================] - 53s 26ms/step - loss: 0.2053 - acc: 0.8371 - val_loss: 0.1624 - val_acc: 0.8679\n",
            "Epoch 13/25\n",
            "2056/2056 [==============================] - 51s 25ms/step - loss: 0.1967 - acc: 0.8450 - val_loss: 0.1555 - val_acc: 0.8749\n",
            "Epoch 14/25\n",
            "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1891 - acc: 0.8503 - val_loss: 0.1510 - val_acc: 0.8781\n",
            "Epoch 15/25\n",
            "2056/2056 [==============================] - 51s 25ms/step - loss: 0.1821 - acc: 0.8564 - val_loss: 0.1503 - val_acc: 0.8794\n",
            "Epoch 16/25\n",
            "2056/2056 [==============================] - 54s 26ms/step - loss: 0.1768 - acc: 0.8614 - val_loss: 0.1473 - val_acc: 0.8832\n",
            "Epoch 17/25\n",
            "2056/2056 [==============================] - 52s 25ms/step - loss: 0.1703 - acc: 0.8666 - val_loss: 0.1439 - val_acc: 0.8855\n",
            "Epoch 18/25\n",
            "2056/2056 [==============================] - 54s 26ms/step - loss: 0.1660 - acc: 0.8695 - val_loss: 0.1416 - val_acc: 0.8878\n",
            "Epoch 19/25\n",
            "2056/2056 [==============================] - 50s 24ms/step - loss: 0.1621 - acc: 0.8732 - val_loss: 0.1419 - val_acc: 0.8873\n",
            "Epoch 20/25\n",
            "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1583 - acc: 0.8762 - val_loss: 0.1409 - val_acc: 0.8890\n",
            "Epoch 21/25\n",
            "2056/2056 [==============================] - 52s 25ms/step - loss: 0.1545 - acc: 0.8790 - val_loss: 0.1406 - val_acc: 0.8897\n",
            "Epoch 22/25\n",
            "2056/2056 [==============================] - 51s 25ms/step - loss: 0.1511 - acc: 0.8821 - val_loss: 0.1356 - val_acc: 0.8929\n",
            "Epoch 23/25\n",
            "2056/2056 [==============================] - 50s 25ms/step - loss: 0.1478 - acc: 0.8848 - val_loss: 0.1373 - val_acc: 0.8930\n",
            "Epoch 24/25\n",
            "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1461 - acc: 0.8859 - val_loss: 0.1368 - val_acc: 0.8916\n",
            "Epoch 25/25\n",
            "2056/2056 [==============================] - 53s 26ms/step - loss: 0.1428 - acc: 0.8886 - val_loss: 0.1358 - val_acc: 0.8931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'run_details': <tensorflow.python.keras.callbacks.History at 0x7f690046b890>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T08:21:42.632215Z",
          "iopub.status.busy": "2021-05-17T08:21:42.631345Z",
          "iopub.status.idle": "2021-05-17T08:24:05.431071Z",
          "shell.execute_reply": "2021-05-17T08:24:05.431596Z"
        },
        "id": "burning-absolute",
        "papermill": {
          "duration": 147.948201,
          "end_time": "2021-05-17T08:24:05.431753",
          "exception": false,
          "start_time": "2021-05-17T08:21:37.483552",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "737344194d9b42d0acb67e6c69706fd2",
            "04f426ad50e64db1a2fbe89195f5bfc5"
          ]
        },
        "outputId": "d961a4eb-346e-4c45-8999-12fa129c7ddf"
      },
      "source": [
        "rnn_2 = rnn_second(network.details)\n",
        "rnn_2.evaluate(data_dict, train=True)"
      ],
      "id": "burning-absolute",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "737344194d9b42d0acb67e6c69706fd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Train Acc  0.6351523806630002\n",
            "Editdistance Train Avg  0.8995018425035165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04f426ad50e64db1a2fbe89195f5bfc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Val Acc  0.42540055857709835\n",
            "Editdistance Val Avg  0.7645827045064213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T08:24:15.571419Z",
          "iopub.status.busy": "2021-05-17T08:24:15.570564Z",
          "iopub.status.idle": "2021-05-17T08:24:56.272461Z",
          "shell.execute_reply": "2021-05-17T08:24:56.271825Z"
        },
        "id": "incorporate-creation",
        "papermill": {
          "duration": 45.924549,
          "end_time": "2021-05-17T08:24:56.272618",
          "exception": false,
          "start_time": "2021-05-17T08:24:10.348069",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "1105be03debb432c8632e829b7f92812"
          ]
        },
        "outputId": "86a98bc5-4403-4861-8510-378130ee0633"
      },
      "source": [
        "rnn_2.evaluate_test(data_dict,'/kaggle/working/rnn_greedy.csv')"
      ],
      "id": "incorporate-creation",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1105be03debb432c8632e829b7f92812",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Test Acc  0.46813186813186813\n",
            "Editdistance Test Avg  0.8429676980387052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T08:25:27.198009Z",
          "iopub.status.busy": "2021-05-17T08:25:27.190415Z",
          "iopub.status.idle": "2021-05-17T08:25:27.201479Z",
          "shell.execute_reply": "2021-05-17T08:25:27.200895Z"
        },
        "id": "presidential-rochester",
        "papermill": {
          "duration": 4.901487,
          "end_time": "2021-05-17T08:25:27.201639",
          "exception": false,
          "start_time": "2021-05-17T08:25:22.300152",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def decode_sequence_beam(input_seq, k, encoder_model, decoder_model, tk, max_target_length=20, alpha=0.7,getall=False):\n",
        "    # encode the input as state vectors\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = 1 \n",
        "    run_condition = [True for i in range(k)]\n",
        "    # print(len(states_value))\n",
        "    # print([target_seq] + [states_value])\n",
        "    results, *states_values_temp = decoder_model.predict([target_seq] + [states_value])\n",
        "    output_tokens = results\n",
        "\n",
        "    states_values_k = [states_values_temp for i in range(k)]\n",
        "    #get topk indices\n",
        "    ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
        "    bestk_ind = ind\n",
        "    output_tokens = np.array(output_tokens[0, -1, :])\n",
        "    bestk_prob = np.log(output_tokens[ind])\n",
        "    bestk_tot = [[bestk_ind[i]] for i in range(k)]\n",
        "    # print(bestk_tot)\n",
        "\n",
        "    \n",
        "    while any(run_condition):\n",
        "        bestk_tot_new = []\n",
        "        bestk_prob_new = []\n",
        "        states_values_k_new = []\n",
        "        for i in range(k) :\n",
        "            if run_condition[i] :\n",
        "                a = bestk_tot[i]\n",
        "                b = bestk_prob[i]\n",
        "                target_seq[0,0] = a[-1]\n",
        "                results,*states_values_temp = decoder_model.predict([target_seq] + states_values_k[i],batch_size=1)\n",
        "                output_tokens = results\n",
        "\n",
        "                states_values_k_temp = [states_values_temp for m in range(k)]\n",
        "\n",
        "                states_values_k_new += states_values_k_temp\n",
        "                ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
        "                bestk_ind = ind\n",
        "                output_tokens = np.array(output_tokens[0, -1, :])\n",
        "                bestk_prob_temp = output_tokens[ind]\n",
        "                bestk_tot_temp = [a+[bestk_ind[j]] for j in range(k)]\n",
        "                bestk_prob_temp2 = [(b*(np.power(len(bestk_tot_temp[j])-1,alpha)) + np.log(bestk_prob_temp[j]))/(np.power(len(bestk_tot_temp[j]),alpha)) for j in range(k)]\n",
        "                bestk_prob_new += bestk_prob_temp2\n",
        "                bestk_tot_new += bestk_tot_temp\n",
        "            \n",
        "            else :\n",
        "                a = bestk_tot[i]\n",
        "                b = bestk_prob[i]\n",
        "                bestk_tot_new += [bestk_tot[i]]\n",
        "                bestk_prob_new += [b]\n",
        "                states_values_k_new += [states_values_k[i]]\n",
        "\n",
        "        bestk_prob_new = np.array(bestk_prob_new)\n",
        "        # print(len(bestk_prob_new),len(bestk_tot_new),len(states_values_k_new))\n",
        "        ind = np.argpartition(bestk_prob_new,-k)[-k:]\n",
        "        bestk_tot = [bestk_tot_new[i] for i in ind]\n",
        "        states_values_k = [states_values_k_new[i] for i in ind]\n",
        "        bestk_prob = bestk_prob_new[ind]\n",
        "        run_condition = []\n",
        "        for i in range(k) :\n",
        "            a = bestk_tot[i]\n",
        "            b = bestk_prob[i]\n",
        "            if a[-1]!= 2 and len(a)<=max_target_length :\n",
        "              run_condition.append(True)\n",
        "            else :\n",
        "              run_condition.append(False)\n",
        "\n",
        "    final_words = []\n",
        "    best_word = []\n",
        "    best = -5.0\n",
        "    for i in range(k) :\n",
        "      a = bestk_tot[i]\n",
        "      b = bestk_prob[i]\n",
        "      final_words += [a]\n",
        "      if b > best :\n",
        "        best_word = [a]\n",
        "        best = b\n",
        "\n",
        "    if getall :\n",
        "      return (tk.decode(final_words,'output'),best_word)\n",
        "    else :\n",
        "      return final_words,best_word"
      ],
      "id": "presidential-rochester",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T08:25:37.405668Z",
          "iopub.status.busy": "2021-05-17T08:25:37.404764Z",
          "iopub.status.idle": "2021-05-17T08:25:37.406549Z",
          "shell.execute_reply": "2021-05-17T08:25:37.407133Z"
        },
        "id": "boolean-rating",
        "papermill": {
          "duration": 5.059009,
          "end_time": "2021-05-17T08:25:37.407334",
          "exception": false,
          "start_time": "2021-05-17T08:25:32.348325",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def beam_search(details,tokenizer,test_data,out_size,beam,data_dict) :\n",
        "  encoder_model = Model(details['encoder_inputs'], details['encoder_states'])\n",
        "  rep_size = details['params']['rep_size']\n",
        "  decoder_state_input = []\n",
        "  for i in range(len(details['encoder_states'])) :\n",
        "      new_state = Input(shape=(rep_size,))\n",
        "      decoder_state_input.append(new_state)\n",
        "  decoder_inputs = details['decoder_inputs']\n",
        "  x = details['decoder_embedding'](decoder_inputs)\n",
        "\n",
        "  for layer in details['decoder_layers'] :\n",
        "    x, *decoder_states = layer(x,initial_state=decoder_state_input)\n",
        "\n",
        "  x = details['decoder_dense'](x)\n",
        "  decoder_model = Model(\n",
        "      [decoder_inputs] + decoder_state_input,\n",
        "      [x] + decoder_states )\n",
        "  inp = tokenizer.encode(test_data['df'].input.tolist())\n",
        "  out = tokenizer.encode(test_data['df'].output.tolist(),mode='output')\n",
        "  val_gen = data_loader._generate_batch(inp,out,data_dict,out_size)\n",
        "  acc = 0\n",
        "  acc_k = 0\n",
        "  num_val = len(inp)\n",
        "  \n",
        "  X = []\n",
        "  Y_true = []\n",
        "  Y_pred = []\n",
        "\n",
        "  for i in tqdm(range(num_val)) :\n",
        "    (input_seq,ans) , _ = next(val_gen)\n",
        "    K,best = decode_sequence_beam(input_seq,beam,encoder_model,decoder_model,tokenizer,data_dict['max_target_length'],getall=True)\n",
        "    w1 = tokenizer.decode(best,mode='output')\n",
        "    w2 = tokenizer.decode([ans[0][1:]],mode='output')\n",
        "    \n",
        "    ###############################################################\n",
        "    <X.append(<INPUT STRING!>)>\n",
        "    Y_true.append(w2[0])\n",
        "    Y_pred.append(w1[0])\n",
        "\n",
        "    comp = (w1[0]==w2[0])\n",
        "    if comp :\n",
        "      acc += 1    \n",
        "    if w2[0] in K :\n",
        "      acc_k += 1\n",
        "\n",
        "  acc /= num_val\n",
        "  acc_k /= num_val\n",
        "\n",
        "  filename = '/kaggle/working/rnn_beam.csv'\n",
        "\n",
        "  df = pd.DataFrame({\n",
        "      'X': X,\n",
        "      'Y_true': Y_true,\n",
        "      'Y_pred': Y_pred\n",
        "  })\n",
        "\n",
        "  df.to_csv(filename)\n",
        "    try:\n",
        "      wandb.log({'rnn_beam_csv': df})\n",
        "    except:\n",
        "      pass\n",
        "  '''\n",
        "  with open(filename, 'wb') as f:\n",
        "    pickle.dump([inputs,outputs], f)\n",
        "  '''\n",
        "\n",
        "  print(\"Val Accuracy : \"+str(acc))\n",
        "  print(\"Val Accuracy K : \"+str(acc_k))\n",
        "  \n",
        "  wandb.log({\"val_acc_rnn_beam\": acc,\n",
        "             \"val_acc_rnn_beam_K:\", acc_k})"
      ],
      "id": "boolean-rating",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-17T08:25:47.799466Z",
          "iopub.status.busy": "2021-05-17T08:25:47.797877Z",
          "iopub.status.idle": "2021-05-17T08:25:47.800345Z",
          "shell.execute_reply": "2021-05-17T08:25:47.801091Z"
        },
        "papermill": {
          "duration": 4.868164,
          "end_time": "2021-05-17T08:25:47.801309",
          "exception": false,
          "start_time": "2021-05-17T08:25:42.933145",
          "status": "completed"
        },
        "tags": [],
        "id": "abstract-wiring"
      },
      "source": [
        "beam_search(network.details,data_dict['tokenizer'], data_dict['test'], data_dict['out_size'], 10, data_dict)"
      ],
      "id": "abstract-wiring",
      "execution_count": null,
      "outputs": []
    }
  ]
}