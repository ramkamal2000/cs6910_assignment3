{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "v6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtcVxQrUVxtS"
      },
      "source": [
        "# TO DO\n",
        "1. Figure out dataset\n",
        "2. Break down into individual characters\n",
        "3. Form corpus from dataset for input and output characters\n",
        "4. Assign a number to each character\n",
        "5. Model will have an embedding so it will handle it\n",
        "6. Output will be a bunch of integers so we will have to decode it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRAUpzh1BLEB",
        "outputId": "61c9ec74-1878-4a0c-dba1-ebe1e5e05ef1"
      },
      "source": [
        "!pip install wandb\n",
        "# !pip install tensorflow\n",
        "# !pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ee/d755f9e5466df64c8416a2c6a860fb3aaa43ed6ea8e8e8e81460fda5788b/wandb-0.10.28-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.2MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 21.2MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 20.5MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=0db091a4323c65ca1de304c7b11cba9318dae05237b8d07d829e3b26f6a33b61\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=37adf774a423f925fd97464e14d422680973e15f201ab2a4b27b3573687bb9cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: docker-pycreds, configparser, shortuuid, sentry-sdk, pathtools, smmap, gitdb, GitPython, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bClAC3xAEhKS"
      },
      "source": [
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "from keras import layers\n",
        "from keras.layers import LSTM, Dense, Embedding, Input\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tqdm.auto import tqdm\n",
        "from keras.layers import Lambda\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs9sbR5xCVo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e73c745-7626-4d9c-ac5d-3c383c048db6"
      },
      "source": [
        "!wget -nc https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "\n",
        "if not os.path.isdir('/content/dakshina_dataset_v1.0'):\n",
        "  tarfile.open(\"/content/dakshina_dataset_v1.0.tar\").extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-01 16:56:23--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.128, 74.125.203.128, 74.125.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   120MB/s    in 26s     \n",
            "\n",
            "2021-05-01 16:56:49 (75.0 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0fMpPf_BUUK",
        "outputId": "cf244774-27cd-4f16-9f86-a9c469e2ce88"
      },
      "source": [
        "wandb.login(key='14394907543f59ea21931529e34b4d80d2ca8c9c')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BstzblcHmd5"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNDJrkl5EUHX"
      },
      "source": [
        "class data_loader():\n",
        "\n",
        "  @staticmethod\n",
        "  def _load_raw_df(languages = [\"hi\", \"mr\"]):\n",
        "    lex = dict()\n",
        "    lex['train'], lex['val'], lex['test'] = [], [], [] \n",
        "    column_names = ['input', 'output', 'count']\n",
        "    \n",
        "    for la in languages:\n",
        "      lex['train'].append(pd.read_csv('/content/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.train.tsv', sep='\\t', header=None, names=column_names))\n",
        "      lex['val'].append(pd.read_csv('/content/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.dev.tsv', sep='\\t', header=None, names=column_names))\n",
        "      lex['test'].append(pd.read_csv('/content/dakshina_dataset_v1.0/'+la+'/lexicons/'+la+'.translit.sampled.test.tsv', sep='\\t', header=None, names=column_names))\n",
        "\n",
        "    lex['train'] = pd.concat(lex['train'])\n",
        "    lex['val'] = pd.concat(lex['val'])\n",
        "    lex['test'] = pd.concat(lex['test'])\n",
        "\n",
        "    return lex    \n",
        "\n",
        "  @staticmethod\n",
        "  def _make_final_df(lex):\n",
        "    \n",
        "    for div in ['train', 'val', 'test']:\n",
        "    \n",
        "      # removing non max transliterations\n",
        "      idx = lex[div].groupby(['input'])['count'].transform(max) == lex[div]['count']\n",
        "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
        "\n",
        "      # calclulating difference in lengths of various transliterations\n",
        "      lex[div]['input_len'] = lex[div].apply(lambda x: len(str(x['input'])), axis=1)\n",
        "      lex[div]['output_len'] = lex[div].apply(lambda y: len(str(y['output'])), axis=1)\n",
        "      lex[div]['mod_dif'] = lex[div].apply(lambda z: abs(z['input_len'] - z['output_len']), axis=1) \n",
        "\n",
        "      # removing transliterations that vary by a lot in length\n",
        "      idx = lex[div].groupby(['input'])['mod_dif'].transform(min) == lex[div]['mod_dif']\n",
        "      lex[div] = lex[div][idx].reset_index(drop=True)\n",
        "\n",
        "      # removing duplicates if any remain\n",
        "      lex[div].drop_duplicates(subset='input', keep='first', inplace=True)\n",
        "\n",
        "      # removing redundant columns\n",
        "      lex[div].drop(labels=['count', 'input_len', 'output_len', 'mod_dif'], inplace=True, axis=1)\n",
        "\n",
        "    return lex\n",
        "\n",
        "  @staticmethod\n",
        "  def _generate_batch(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
        "    ''' Generate a batch of data '''\n",
        "    assert len(X)==len(y)\n",
        "    ind = np.random.permutation(len(X))\n",
        "    X,y = [X[j] for j in ind],[y[j] for j in ind]\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, data_dict['max_target_length']),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text):\n",
        "                  encoder_input_data[i, t] = word\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t<len(target_text)-1:\n",
        "                        decoder_input_data[i, t] = word # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        #print(word)\n",
        "                        decoder_target_data[i, t - 1, word] = 1.\n",
        "                    \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
        "\n",
        "  @staticmethod\n",
        "  def _generate_batch_greedy(X, y, data_dict, num_decoder_tokens, batch_size = 1):\n",
        "    ''' Generate a batch of data '''\n",
        "    assert len(X)==len(y)\n",
        "    ind = np.random.permutation(len(X))\n",
        "    X,y = [X[j] for j in ind],[y[j] for j in ind]\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, data_dict['max_source_length']),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, 1),dtype='float32')\n",
        "            # decoder_target_data = np.zeros((batch_size, data_dict['max_target_length'], num_decoder_tokens),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, 23, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text):\n",
        "                  encoder_input_data[i, t] = word\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t==0 :\n",
        "                        decoder_input_data[i, t] = 1 # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        #print(word)\n",
        "                        decoder_target_data[i, t - 1, word] = 1.\n",
        "                    \n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOo1m6s3vDaN"
      },
      "source": [
        "class Tokenizer:\n",
        "\n",
        "  def __init__(self, df):\n",
        "\n",
        "    self.start_token = '<STR>'\n",
        "    self.stop_token = '<STP>'\n",
        "    self.unknown_token = '<UNK>'\n",
        "\n",
        "    self.input_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
        "    self.output_corpus = [self.start_token, self.stop_token, self.unknown_token]\n",
        "\n",
        "    input_words = df.input.tolist()\n",
        "    output_words = df.output.tolist()\n",
        "\n",
        "    for word in input_words:\n",
        "      tokens = str(word)\n",
        "      for token in tokens:\n",
        "        if token not in self.input_corpus:\n",
        "          self.input_corpus.append(token)\n",
        "\n",
        "    for word in output_words:\n",
        "      tokens = str(word)\n",
        "      for token in tokens:\n",
        "        if token not in self.output_corpus:\n",
        "          self.output_corpus.append(token)\n",
        "    \n",
        "    self.encode_dict_input = {self.input_corpus[i] : i+1 for i in range(len(self.input_corpus))}\n",
        "    self.decode_dict_input = {k:v for v,k in self.encode_dict_input.items()}\n",
        "    \n",
        "    \n",
        "    self.encode_dict_output = {self.output_corpus[i] : i+1 for i in range(len(self.output_corpus))}\n",
        "    self.decode_dict_output = {k:v for v,k in self.encode_dict_output.items()}\n",
        "    self.decode_dict_output.update({2:''})\n",
        "\n",
        "  # takes in lists of words and returns lists of integers\n",
        "  def encode(self, X, mode='input'):\n",
        "\n",
        "    if (mode=='input'):\n",
        "      input_list = []\n",
        "      for word in X:\n",
        "        word = str(word)\n",
        "        # integer_list = [self.encode_dict_input[self.start_token]] + [self.encode_dict_input.get(token, self.encode_dict_input[self.unknown_token]) for token in word] + [self.encode_dict_input[self.stop_token]]\n",
        "        integer_list =np.array([self.encode_dict_input.get(token, self.encode_dict_input[self.unknown_token]) for token in word])\n",
        "        input_list.append(integer_list)\n",
        "      \n",
        "      return input_list\n",
        "    \n",
        "    if (mode=='output'):\n",
        "      output_list = []\n",
        "      for word in X:\n",
        "        word = str(word)\n",
        "        integer_list = np.array([self.encode_dict_output[self.start_token]] + [self.encode_dict_output.get(token, self.encode_dict_output[self.unknown_token]) for token in word] + [self.encode_dict_output[self.stop_token]])\n",
        "        output_list.append(integer_list)\n",
        "      \n",
        "      return output_list\n",
        "    \n",
        "\n",
        "  # takes in lists of integers and returns lists of words\n",
        "  def decode(self, X, mode='input'):\n",
        "\n",
        "    if (mode=='input'):\n",
        "      input_list = []\n",
        "      for integers in X:\n",
        "        token_list = [self.decode_dict_input.get(integer, '') for integer in integers] \n",
        "        input_list.append(''.join(token_list))\n",
        "      \n",
        "      return input_list\n",
        "\n",
        "    if (mode=='output'):\n",
        "      output_list = []\n",
        "      for integers in X:\n",
        "        token_list = [self.decode_dict_output.get(integer, '') for integer in integers[1:-1]] \n",
        "        output_list.append(''.join(token_list))\n",
        "      \n",
        "      return output_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1mzVsRdBa4x"
      },
      "source": [
        "def return_data_dict(languages=['hi', 'mr'], batch_size=32):\n",
        "\n",
        "  lex = data_loader._load_raw_df(languages)\n",
        "  lex = data_loader._make_final_df(lex)\n",
        "\n",
        "  data_dict = dict()\n",
        "\n",
        "  df_train = lex['train']\n",
        "  df_val = lex['val']\n",
        "  df_test = lex['test']\n",
        "\n",
        "  tk = Tokenizer(df_train)\n",
        "\n",
        "  data_dict['in_size'] = len(tk.input_corpus) + 1\n",
        "  data_dict['out_size'] = len(tk.output_corpus) + 1\n",
        "\n",
        "  X_train = tk.encode(df_train.input.tolist(), mode='input')\n",
        "  Y_train = tk.encode(df_train.output.tolist(), mode='output')\n",
        "  X_val = tk.encode(df_val.input.tolist(), mode='input')\n",
        "  Y_val = tk.encode(df_val.output.tolist(), mode='output')\n",
        "  X_test = tk.encode(df_test.input.tolist(), mode='input')\n",
        "  Y_test = tk.encode(df_test.output.tolist(), mode='output')\n",
        "\n",
        "  max_source_length = np.max(np.array([len(x) for x in X_train]))\n",
        "  max_target_length = np.max(np.array([len(x) for x in Y_train]))\n",
        "\n",
        "  data_dict['train'], data_dict['val'], data_dict['test']= dict(), dict(), dict()\n",
        "\n",
        "  data_dict['train']['df'] = df_train\n",
        "  data_dict['val']['df'] = df_val\n",
        "  data_dict['test']['df'] = df_test\n",
        "\n",
        "  \n",
        "\n",
        "  data_dict['train']['max_source_length'] = np.max(np.array([len(x) for x in X_train]))\n",
        "  data_dict['train']['max_target_length'] = np.max(np.array([len(x) for x in Y_train]))\n",
        "  data_dict['val']['max_source_length'] = np.max(np.array([len(x) for x in X_val]))\n",
        "  data_dict['val']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
        "  data_dict['test']['max_source_length'] = np.max(np.array([len(x) for x in X_test]))\n",
        "  data_dict['test']['max_target_length'] = np.max(np.array([len(x) for x in Y_test]))\n",
        "\n",
        "  data_dict['max_source_length'] = max(data_dict['train']['max_source_length'],data_dict['val']['max_source_length'])\n",
        "  data_dict['max_target_length'] = max(data_dict['train']['max_target_length'],data_dict['val']['max_target_length'])\n",
        "\n",
        "  data_dict['train']['batch'] = data_loader._generate_batch(X_train, Y_train, data_dict['train'], data_dict['out_size'], batch_size)\n",
        "  data_dict['train']['batch_greedy'] = data_loader._generate_batch_greedy(X_train, Y_train, data_dict['train'], data_dict['out_size'], batch_size)\n",
        "  data_dict['val']['batch_greedy'] = data_loader._generate_batch_greedy(X_val, Y_val, data_dict['val'], data_dict['out_size'], batch_size)\n",
        "  data_dict['val']['batch'] = data_loader._generate_batch(X_val, Y_val, data_dict['val'], data_dict['out_size'], batch_size)\n",
        "  data_dict['test']['batch'] = data_loader._generate_batch(X_test, Y_test, data_dict['test'], data_dict['out_size'], batch_size)  \n",
        "  data_dict['test']['batch_greedy'] = data_loader._generate_batch_greedy(X_test, Y_test, data_dict['test'], data_dict['out_size'], batch_size)    \n",
        "  data_dict['tokenizer'] = tk\n",
        "\n",
        "  return data_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwJozmDWedfG"
      },
      "source": [
        "data_dict = return_data_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgbuaQneKjwg"
      },
      "source": [
        "data_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQhr5hA6xJxv"
      },
      "source": [
        "# data = dict()\n",
        "# data['train'] = dict()\n",
        "# data['train']['X'] = X_train\n",
        "# data['train']['Y'] = Y_train\n",
        "# data['in_size'] = len(tk.input_corpus) + 1\n",
        "# data['out_size'] = len(tk.output_corpus) + 1\n",
        "# num_decoder_tokens = data['out_size'] \n",
        "# max_source_length = np.max(np.array([len(x) for x in X_train]))\n",
        "# max_target_length = np.max(np.array([len(x) for x in Y_train]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV_63arXtzSt"
      },
      "source": [
        "# Question 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwQl8eh2y35p"
      },
      "source": [
        "class BeamSearchCallBack(keras.callbacks.Callback):\n",
        "  def __init__(self,details,test_data,tokenizer,out_size,num_val=200,beam=3) :\n",
        "    self.details = details\n",
        "    self.test_data = test_data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.out_size = out_size\n",
        "    self.num_val = num_val\n",
        "    self.beam = beam\n",
        "\n",
        "  def on_epoch_end(self,epoch,logs=None) :\n",
        "    \n",
        "    encoder_model = Model(self.details['encoder_inputs'], self.details['encoder_states'])\n",
        "    rep_size = self.details['params']['rep_size']\n",
        "    decoder_state_input = []\n",
        "    for i in range(len(self.details['encoder_states'])) :\n",
        "        new_state = Input(shape=(rep_size,))\n",
        "        decoder_state_input.append(new_state)\n",
        "    decoder_inputs = self.details['decoder_inputs']\n",
        "    x = self.details['decoder_embedding'](decoder_inputs)\n",
        "    \n",
        "    for layer in self.details['decoder_layers'] :\n",
        "      x, *decoder_states = layer(x,initial_state=decoder_state_input)\n",
        "\n",
        "    x = self.details['decoder_dense'](x)\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_state_input,\n",
        "        [x] + decoder_states )\n",
        "    inp = self.tokenizer.encode(self.test_data['df'].input.tolist())\n",
        "    out = self.tokenizer.encode(self.test_data['df'].output.tolist(),mode='output')\n",
        "    out_size = self.out_size\n",
        "    val_gen = data_loader._generate_batch(inp,out,self.test_data,self.out_size)\n",
        "    acc = 0\n",
        "    for i in tqdm(range(self.num_val)) :\n",
        "      (input_seq,ans) , _ = next(val_gen)\n",
        "      _,best = decode_sequence_beam(input_seq,self.beam,encoder_model,decoder_model,self.tokenizer,self.test_data['max_target_length'])\n",
        "      w1 = self.tokenizer.decode(best,mode='output')\n",
        "      w2 = self.tokenizer.decode(ans,mode='output')\n",
        "      comp = (w1==w2)\n",
        "      if comp :\n",
        "        acc += 1    \n",
        "\n",
        "    acc /= len(inp)\n",
        "    print(\"Val Accuracy : \"+str(acc))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-cdgAqTLyAr"
      },
      "source": [
        "def decode_sequence_beam(input_seq,k,encoder_model,decoder_model,tk,max_target_length=20,getall=False):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq,batch_size=1,use_multiprocessing=True)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of \n",
        "    #target sequence with the start character.\n",
        "    target_seq[0, 0] = 1 \n",
        "    run_condition = [True for i in range(k)]\n",
        "    # print(len(states_value))\n",
        "    # print([target_seq] + [states_value])\n",
        "    results, *states_values_temp = decoder_model.predict([target_seq] + [states_value])\n",
        "    output_tokens = results\n",
        "\n",
        "    states_values_k = [states_values_temp for i in range(k)]\n",
        "    #get topk indices\n",
        "    ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
        "    bestk_ind = ind\n",
        "    output_tokens = np.array(output_tokens[0, -1, :])\n",
        "    bestk_prob = output_tokens[ind]\n",
        "    bestk_tot = [[1,bestk_ind[i]] for i in range(k)]\n",
        "    # print(bestk_tot)\n",
        "\n",
        "    \n",
        "    while any(run_condition):\n",
        "        bestk_tot_new = []\n",
        "        bestk_prob_new = []\n",
        "        states_values_k_new = []\n",
        "        for i in range(k) :\n",
        "            if run_condition[i] :\n",
        "                a = bestk_tot[i]\n",
        "                b = bestk_prob[i]\n",
        "                target_seq[0,0] = a[-1]\n",
        "                results,*states_values_temp = decoder_model.predict([target_seq] + states_values_k[i],batch_size=1)\n",
        "                output_tokens = results\n",
        "\n",
        "                states_values_k_temp = [states_values_temp for m in range(k)]\n",
        "\n",
        "                states_values_k_new += states_values_k_temp\n",
        "                ind = np.argpartition(np.array(output_tokens[0, -1, :]), -k)[-k:]\n",
        "                bestk_ind = ind\n",
        "                output_tokens = np.array(output_tokens[0, -1, :])\n",
        "                bestk_prob_temp = output_tokens[ind]\n",
        "                bestk_tot_temp = [a+[bestk_ind[j]] for j in range(k)]\n",
        "                bestk_prob_temp2 = [b*bestk_prob_temp[j] for j in range(k)]\n",
        "                bestk_prob_new += bestk_prob_temp2\n",
        "                bestk_tot_new += bestk_tot_temp\n",
        "            \n",
        "            else :\n",
        "                a = bestk_tot[i]\n",
        "                b = bestk_prob[i]\n",
        "                bestk_tot_new += [bestk_tot[i]]\n",
        "                bestk_prob_new += [b]\n",
        "                states_values_k_new += [states_values_k[i]]\n",
        "\n",
        "        bestk_prob_new = np.array(bestk_prob_new)\n",
        "        # print(len(bestk_prob_new),len(bestk_tot_new),len(states_values_k_new))\n",
        "        ind = np.argpartition(bestk_prob_new,-k)[-k:]\n",
        "        bestk_tot = [bestk_tot_new[i] for i in ind]\n",
        "        states_values_k = [states_values_k_new[i] for i in ind]\n",
        "        bestk_prob = bestk_prob_new[ind]\n",
        "        run_condition = []\n",
        "        for i in range(k) :\n",
        "            a = bestk_tot[i]\n",
        "            b = bestk_prob[i]\n",
        "            if a[-1]!= 2 and len(a)<=max_target_length :\n",
        "              run_condition.append(True)\n",
        "            else :\n",
        "              run_condition.append(False)\n",
        "\n",
        "        # print(bestk_tot)\n",
        "\n",
        "    final_words = []\n",
        "    best_word = []\n",
        "    best = 0.0\n",
        "    for i in range(k) :\n",
        "      a = bestk_tot[i]\n",
        "      b = bestk_prob[i]\n",
        "      final_words += [a]\n",
        "      if b > best :\n",
        "        best_word = [a]\n",
        "\n",
        "    if getall :\n",
        "      return (tk.decode(final_words,'output'),best_word)\n",
        "    else :\n",
        "      return final_words,best_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpJm8eZrt5mA"
      },
      "source": [
        "class rnn():\n",
        "\n",
        "  def __init__(self, params):\n",
        "    \n",
        "    num_encode_layers = params['num_encode_layers']\n",
        "    num_decode_layers = params['num_decode_layers']\n",
        "    data_dict = params['data_dict']\n",
        "    in_size = params['data_dict']['in_size']\n",
        "    out_size = params['data_dict']['out_size']\n",
        "    cell_type = params['cell_type']\n",
        "    dropout = params['dropout']\n",
        "    embed_size = params['embed_size']\n",
        "    rep_size = params['rep_size']\n",
        "        \n",
        "    ###################### ENCODER NETWORK ######################\n",
        "    \n",
        "    encoder_inputs = Input(shape=(None,))\n",
        "    x = Embedding(in_size, embed_size ,mask_zero=True)(encoder_inputs)\n",
        "\n",
        "    encoder_layers = []\n",
        "    \n",
        "    for j in range(num_encode_layers-1) :   \n",
        "      curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_sequences=True)\n",
        "      encoder_layers.append(curr_layer)\n",
        "      x = curr_layer(x)\n",
        "\n",
        "    curr_layer = getattr(layers, cell_type)(rep_size, dropout=dropout, return_state=True)\n",
        "    encoder_layers.append(curr_layer)\n",
        "    x, *encoder_states = curr_layer(x)\n",
        "\n",
        "    ###################### DECODER NETWORK ######################\n",
        "\n",
        "    decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "    decoder_embedding =  Embedding(out_size, embed_size, mask_zero=True)\n",
        "    x = decoder_embedding(decoder_inputs)\n",
        "\n",
        "    decoder_layers = []    \n",
        "    \n",
        "    for j in range(num_decode_layers) :\n",
        "      curr_layer = getattr(layers, cell_type)(rep_size,dropout=dropout,return_state=True, return_sequences=True)\n",
        "      decoder_layers.append(curr_layer)\n",
        "      x, *decoder_states = curr_layer(x, initial_state=encoder_states)\n",
        "\n",
        "    decoder_dense = Dense(units=out_size, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(x)\n",
        "\n",
        "    # Define the model that will turn\n",
        "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    self.model = model\n",
        "    self.encoder_inputs = encoder_inputs\n",
        "    self.encoder_layers = encoder_layers\n",
        "    self.decoder_inputs = decoder_inputs\n",
        "    self.decoder_embedding = decoder_embedding\n",
        "    self.decoder_layers = decoder_layers\n",
        "    self.decoder_dense = decoder_dense\n",
        "    self.encoder_states = encoder_states\n",
        "    self.params = params\n",
        "    self.details = {\n",
        "        'model' : self.model,\n",
        "        'encoder_inputs' : self.encoder_inputs,\n",
        "        'encoder_layers' :self.encoder_layers ,\n",
        "        'decoder_inputs' :self.decoder_inputs ,\n",
        "        'decoder_embedding' : self.decoder_embedding,\n",
        "        'decoder_layers' : self.decoder_layers,\n",
        "        'decoder_dense' : self.decoder_dense,\n",
        "        'encoder_states' : self.encoder_states ,\n",
        "        'params' :self.params\n",
        "    }\n",
        "  def compile_and_fit(self, data_dict, params):\n",
        "\n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "    \n",
        "    summary = self.model.summary()\n",
        "    plot = plot_model(self.model, show_shapes=True)\n",
        "    \n",
        "    train_samples = len(data_dict['train']['df']) # Total Training samples\n",
        "    val_samples = len(data_dict['val']['df'])    # Total validation or test samples\n",
        "    batch_size = params['batch_size']\n",
        "    num_epochs = params['num_epochs']\n",
        "    run_details = self.model.fit_generator(generator = data_dict['train']['batch'],\n",
        "                                            steps_per_epoch = train_samples//batch_size,\n",
        "                                            epochs=num_epochs,\n",
        "                                            # callbacks=[BeamSearchCallBack(self.details,data_dict['val'],data_dict['tokenizer'],data_dict['out_size'],num_val=num_val_samples,beam=beam)\n",
        "                                            #             #,wandb.keras.WandbCallback()\n",
        "                                            #             ]\n",
        "                                           validation_data = data_dict['val']['batch'],\n",
        "                    validation_steps = val_samples//batch_size\n",
        "                                            )\n",
        "\n",
        "    # train_ds, val_ds = data['train'], data['val']\n",
        "    # optimizer, epochs = params['optimizer'], params['num_epochs']\n",
        "    \n",
        "    return {\n",
        "        'run_details' : run_details\n",
        "    }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0m1582SU6W8"
      },
      "source": [
        "class rnn_second() :\n",
        "  def __init__(self,details) :\n",
        "\n",
        "    self.details = details\n",
        "    decoder_state_input = self.details['encoder_states']\n",
        "    decoder_inputs = Input(shape=(1,))\n",
        "    rep_size = self.details['params']['rep_size']\n",
        "    decoder_inputs = self.details['decoder_inputs']\n",
        "    x = self.details['decoder_embedding'](decoder_inputs)\n",
        "    all_outputs = []\n",
        "    for _ in range(self.details['params']['data_dict']['max_target_length']) :\n",
        "        for layer in self.details['decoder_layers'] :\n",
        "            x, *decoder_states = layer(x,initial_state=decoder_state_input)\n",
        "\n",
        "        x = self.details['decoder_dense'](x)\n",
        "        all_outputs.append(x)\n",
        "        x = tf.math.argmax(x,2)  \n",
        "        x = self.details['decoder_embedding'](x)\n",
        "        decoder_state_input = decoder_states\n",
        "\n",
        "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    model = Model([self.details['encoder_inputs'], decoder_inputs], decoder_outputs)\n",
        "    self.model = model\n",
        "\n",
        "  def compile_and_fit(self,data_dict,params) :\n",
        "    self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "    \n",
        "    summary = self.model.summary()\n",
        "    plot = plot_model(self.model, show_shapes=True)\n",
        "    \n",
        "    train_samples = len(data_dict['train']['df']) # Total Training samples\n",
        "    val_samples = len(data_dict['val']['df'])    # Total validation or test samples\n",
        "    batch_size = params['batch_size']\n",
        "    num_epochs = params['num_epochs2']\n",
        "    run_details = self.model.fit_generator(generator = data_dict['train']['batch_greedy'],\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data = data_dict['val']['batch_greedy'],\n",
        "                    validation_steps = val_samples//batch_size)\n",
        "\n",
        "    # train_ds, val_ds = data['train'], data['val']\n",
        "    # optimizer, epochs = params['optimizer'], params['num_epochs']\n",
        "    \n",
        "    return {\n",
        "        'run_details' : run_details\n",
        "    }\n",
        "\n",
        "  def evaluate(self,data_dict) :\n",
        "    test_gen = data_dict['test']['batch_greedy']\n",
        "    test_samples = len(data_dict['test']['df'])\n",
        "    batch_size=32\n",
        "    acc = 0\n",
        "    for _ in range(test_samples//batch_size) :\n",
        "      (a,b),c = next(test_gen)\n",
        "      l1 = data_dict['tokenizer'].decode(np.argmax(c,axis=2),mode='output')\n",
        "      out = rnn2.model.predict([a,b])\n",
        "      out = np.argmax(out,axis=2)\n",
        "      l2 = data_dict['tokenizer'].decode(out,mode='output')\n",
        "      acc += np.sum(np.array(l1)==np.array(l2))\n",
        "\n",
        "    wandb.log({\"Val Accuracy\" : acc/test_samples})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDLMoTWfBn86"
      },
      "source": [
        "class tools:\n",
        "  def init_params(config,data_dict):\n",
        "  \n",
        "    \n",
        "    # returning parameters\n",
        "    params = {\n",
        "        'num_encode_layers' : config.num_encode_layers,\n",
        "        'num_decode_layers' : config.num_decode_layers,\n",
        "        'cell_type' : config.cell_type,\n",
        "        'rep_size' : config.rep_size,\n",
        "        'embed_size' : config.embed_size,\n",
        "        'dropout' : config.dropout,\n",
        "        'num_epochs' : config.num_epochs,\n",
        "        'data_dict' : data_dict,\n",
        "        'batch_size' : config.batch_size\n",
        "    }\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AWE1lLSDDXh"
      },
      "source": [
        "# sweep configuration\n",
        "sweep_config = {\n",
        "    'method' : 'bayes',\n",
        "    'metric' : {\n",
        "        'name' : 'Val_acc',\n",
        "        'goal' : 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'cell_type' : {\n",
        "            'values': ['LSTM','GRU','SimpleRNN']  \n",
        "        },\n",
        "        'beam': {\n",
        "            'values': [2,3,4,5]\n",
        "        },\n",
        "        'num_val_samples': {\n",
        "            'values': [200]\n",
        "        },\n",
        "        'embed_size': {\n",
        "            'values': [16,32,64]\n",
        "        },\n",
        "        'rep_size': {\n",
        "            'values': [32,64,128,256]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0,0.2,0.4,0.5]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32]\n",
        "        },\n",
        "        'num_epochs': {\n",
        "            'values': [25]\n",
        "        },\n",
        "        'num_encode_layers': {\n",
        "            'values': [1,2,3,4,5]\n",
        "        },\n",
        "        'num_decode_layers': {\n",
        "            'values': [1,2,3,4,5]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqDamLUoDQWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7536cc5b-d84f-4792-ff51-0d9cfe0e8ad6"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='dakshina_v1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 5to80pdt\n",
            "Sweep URL: https://wandb.ai/ramkamal/dakshina_v1/sweeps/5to80pdt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez3f-pjxDTU8"
      },
      "source": [
        "class sweep_module:\n",
        "  @staticmethod\n",
        "  def train(config=None):\n",
        "\n",
        "    with wandb.init(config):\n",
        "      \n",
        "      config = wandb.config\n",
        " \n",
        "      #wandb.run.name = 'fil:'+str(config['num_filters_'])+'_type:'+config['type_of_filters'][0]+'_aug:'+str(config['augmentation'])[0]+'_dro:'+str(config['dropout'])[0]\n",
        "      data_dict = return_data_dict(batch_size=config.batch_size)\n",
        "      params = tools.init_params(config,data_dict)\n",
        "      network = rnn(params)\n",
        "      run_details = network.compile_and_fit(data_dict, params)\n",
        "      rnn2 = rnn_second(network.details)\n",
        "      run_details2 = rnn2.compile_and_fit(data_dict)\n",
        "      rnn2.evaluate(data_dict)\n",
        "\n",
        "      if os.path.isdir('/content/wandb'): \n",
        "        shutil.rmtree('/content/wandb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6QBd1gJDV-R"
      },
      "source": [
        "sweep_id = '7g0porer'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCq49t4zDZod"
      },
      "source": [
        "# performing the sweep\n",
        "wandb.agent(sweep_id, sweep_module.train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBotvdIuDczo"
      },
      "source": [
        "# Run One Model separate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBfaOoDTt-Zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0278b0a6-e53b-44c9-c3e3-a8ea3ced32d7"
      },
      "source": [
        "params = {\n",
        "    'num_encode_layers' : 2,\n",
        "    'num_decode_layers' : 2,\n",
        "    'cell_type' : 'LSTM', # SimpleRNN, GRU\n",
        "    'rep_size' : 20,\n",
        "    'embed_size' : 20,\n",
        "    'dropout' : 0,\n",
        "    'num_epochs' : 25,\n",
        "    'num_epochs2' : 25,\n",
        "    'data_dict' : data_dict,\n",
        "    'batch_size' : 32\n",
        "}\n",
        "network = rnn(params)\n",
        "plot_model(network.model, show_shapes=True)\n",
        "network.compile_and_fit(data_dict, params)\n",
        "rnn2 = rnn_second(network.details)\n",
        "run_details2 = rnn2.compile_and_fit(data_dict,params)\n",
        "rnn2.evaluate(data_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 20)     1440        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 20)     3280        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 20)     600         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 20), (None,  3280        lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 20), ( 3280        embedding_1[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 20), ( 3280        lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 30)     630         lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 15,790\n",
            "Trainable params: 15,790\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1420/1420 [==============================] - 71s 22ms/step - loss: 1.0506 - acc: 0.2753 - val_loss: 0.7985 - val_acc: 0.3639\n",
            "Epoch 2/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.8149 - acc: 0.3820 - val_loss: 0.6670 - val_acc: 0.4474\n",
            "Epoch 3/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.6877 - acc: 0.4587 - val_loss: 0.5861 - val_acc: 0.5116\n",
            "Epoch 4/30\n",
            "1420/1420 [==============================] - 26s 19ms/step - loss: 0.6106 - acc: 0.5161 - val_loss: 0.5302 - val_acc: 0.5602\n",
            "Epoch 5/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.5482 - acc: 0.5649 - val_loss: 0.4795 - val_acc: 0.6001\n",
            "Epoch 6/30\n",
            "1420/1420 [==============================] - 26s 19ms/step - loss: 0.4972 - acc: 0.6064 - val_loss: 0.4382 - val_acc: 0.6394\n",
            "Epoch 7/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.4548 - acc: 0.6430 - val_loss: 0.4034 - val_acc: 0.6698\n",
            "Epoch 8/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.4215 - acc: 0.6715 - val_loss: 0.3835 - val_acc: 0.6849\n",
            "Epoch 9/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.3930 - acc: 0.6946 - val_loss: 0.3587 - val_acc: 0.7070\n",
            "Epoch 10/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.3688 - acc: 0.7149 - val_loss: 0.3336 - val_acc: 0.7306\n",
            "Epoch 11/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.3486 - acc: 0.7319 - val_loss: 0.3148 - val_acc: 0.7470\n",
            "Epoch 12/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.3321 - acc: 0.7460 - val_loss: 0.3013 - val_acc: 0.7602\n",
            "Epoch 13/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.3181 - acc: 0.7577 - val_loss: 0.2921 - val_acc: 0.7689\n",
            "Epoch 14/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.3066 - acc: 0.7666 - val_loss: 0.2837 - val_acc: 0.7749\n",
            "Epoch 15/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2963 - acc: 0.7745 - val_loss: 0.2763 - val_acc: 0.7812\n",
            "Epoch 16/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2874 - acc: 0.7816 - val_loss: 0.2697 - val_acc: 0.7864\n",
            "Epoch 17/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2796 - acc: 0.7879 - val_loss: 0.2618 - val_acc: 0.7918\n",
            "Epoch 18/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2724 - acc: 0.7936 - val_loss: 0.2563 - val_acc: 0.7973\n",
            "Epoch 19/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2660 - acc: 0.7989 - val_loss: 0.2535 - val_acc: 0.7990\n",
            "Epoch 20/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2599 - acc: 0.8037 - val_loss: 0.2483 - val_acc: 0.8047\n",
            "Epoch 21/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2539 - acc: 0.8088 - val_loss: 0.2424 - val_acc: 0.8103\n",
            "Epoch 22/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2481 - acc: 0.8141 - val_loss: 0.2372 - val_acc: 0.8143\n",
            "Epoch 23/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2431 - acc: 0.8185 - val_loss: 0.2355 - val_acc: 0.8136\n",
            "Epoch 24/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2384 - acc: 0.8222 - val_loss: 0.2352 - val_acc: 0.8130\n",
            "Epoch 25/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2337 - acc: 0.8263 - val_loss: 0.2339 - val_acc: 0.8134\n",
            "Epoch 26/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2294 - acc: 0.8293 - val_loss: 0.2289 - val_acc: 0.8183\n",
            "Epoch 27/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2254 - acc: 0.8324 - val_loss: 0.2257 - val_acc: 0.8207\n",
            "Epoch 28/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2219 - acc: 0.8350 - val_loss: 0.2215 - val_acc: 0.8249\n",
            "Epoch 29/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2190 - acc: 0.8374 - val_loss: 0.2146 - val_acc: 0.8320\n",
            "Epoch 30/30\n",
            "1420/1420 [==============================] - 27s 19ms/step - loss: 0.2161 - acc: 0.8400 - val_loss: 0.2083 - val_acc: 0.8386\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 20)     1440        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 20)     3280        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 20)     600         input_2[0][0]                    \n",
            "                                                                 tf.math.argmax[0][0]             \n",
            "                                                                 tf.math.argmax_1[0][0]           \n",
            "                                                                 tf.math.argmax_2[0][0]           \n",
            "                                                                 tf.math.argmax_3[0][0]           \n",
            "                                                                 tf.math.argmax_4[0][0]           \n",
            "                                                                 tf.math.argmax_5[0][0]           \n",
            "                                                                 tf.math.argmax_6[0][0]           \n",
            "                                                                 tf.math.argmax_7[0][0]           \n",
            "                                                                 tf.math.argmax_8[0][0]           \n",
            "                                                                 tf.math.argmax_9[0][0]           \n",
            "                                                                 tf.math.argmax_10[0][0]          \n",
            "                                                                 tf.math.argmax_11[0][0]          \n",
            "                                                                 tf.math.argmax_12[0][0]          \n",
            "                                                                 tf.math.argmax_13[0][0]          \n",
            "                                                                 tf.math.argmax_14[0][0]          \n",
            "                                                                 tf.math.argmax_15[0][0]          \n",
            "                                                                 tf.math.argmax_16[0][0]          \n",
            "                                                                 tf.math.argmax_17[0][0]          \n",
            "                                                                 tf.math.argmax_18[0][0]          \n",
            "                                                                 tf.math.argmax_19[0][0]          \n",
            "                                                                 tf.math.argmax_20[0][0]          \n",
            "                                                                 tf.math.argmax_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 20), (None,  3280        lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 20), ( 3280        embedding_1[1][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "                                                                 embedding_1[2][0]                \n",
            "                                                                 lstm_3[1][1]                     \n",
            "                                                                 lstm_3[1][2]                     \n",
            "                                                                 embedding_1[3][0]                \n",
            "                                                                 lstm_3[2][1]                     \n",
            "                                                                 lstm_3[2][2]                     \n",
            "                                                                 embedding_1[4][0]                \n",
            "                                                                 lstm_3[3][1]                     \n",
            "                                                                 lstm_3[3][2]                     \n",
            "                                                                 embedding_1[5][0]                \n",
            "                                                                 lstm_3[4][1]                     \n",
            "                                                                 lstm_3[4][2]                     \n",
            "                                                                 embedding_1[6][0]                \n",
            "                                                                 lstm_3[5][1]                     \n",
            "                                                                 lstm_3[5][2]                     \n",
            "                                                                 embedding_1[7][0]                \n",
            "                                                                 lstm_3[6][1]                     \n",
            "                                                                 lstm_3[6][2]                     \n",
            "                                                                 embedding_1[8][0]                \n",
            "                                                                 lstm_3[7][1]                     \n",
            "                                                                 lstm_3[7][2]                     \n",
            "                                                                 embedding_1[9][0]                \n",
            "                                                                 lstm_3[8][1]                     \n",
            "                                                                 lstm_3[8][2]                     \n",
            "                                                                 embedding_1[10][0]               \n",
            "                                                                 lstm_3[9][1]                     \n",
            "                                                                 lstm_3[9][2]                     \n",
            "                                                                 embedding_1[11][0]               \n",
            "                                                                 lstm_3[10][1]                    \n",
            "                                                                 lstm_3[10][2]                    \n",
            "                                                                 embedding_1[12][0]               \n",
            "                                                                 lstm_3[11][1]                    \n",
            "                                                                 lstm_3[11][2]                    \n",
            "                                                                 embedding_1[13][0]               \n",
            "                                                                 lstm_3[12][1]                    \n",
            "                                                                 lstm_3[12][2]                    \n",
            "                                                                 embedding_1[14][0]               \n",
            "                                                                 lstm_3[13][1]                    \n",
            "                                                                 lstm_3[13][2]                    \n",
            "                                                                 embedding_1[15][0]               \n",
            "                                                                 lstm_3[14][1]                    \n",
            "                                                                 lstm_3[14][2]                    \n",
            "                                                                 embedding_1[16][0]               \n",
            "                                                                 lstm_3[15][1]                    \n",
            "                                                                 lstm_3[15][2]                    \n",
            "                                                                 embedding_1[17][0]               \n",
            "                                                                 lstm_3[16][1]                    \n",
            "                                                                 lstm_3[16][2]                    \n",
            "                                                                 embedding_1[18][0]               \n",
            "                                                                 lstm_3[17][1]                    \n",
            "                                                                 lstm_3[17][2]                    \n",
            "                                                                 embedding_1[19][0]               \n",
            "                                                                 lstm_3[18][1]                    \n",
            "                                                                 lstm_3[18][2]                    \n",
            "                                                                 embedding_1[20][0]               \n",
            "                                                                 lstm_3[19][1]                    \n",
            "                                                                 lstm_3[19][2]                    \n",
            "                                                                 embedding_1[21][0]               \n",
            "                                                                 lstm_3[20][1]                    \n",
            "                                                                 lstm_3[20][2]                    \n",
            "                                                                 embedding_1[22][0]               \n",
            "                                                                 lstm_3[21][1]                    \n",
            "                                                                 lstm_3[21][2]                    \n",
            "                                                                 embedding_1[23][0]               \n",
            "                                                                 lstm_3[22][1]                    \n",
            "                                                                 lstm_3[22][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 20), ( 3280        lstm_2[1][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "                                                                 lstm_2[2][0]                     \n",
            "                                                                 lstm_3[1][1]                     \n",
            "                                                                 lstm_3[1][2]                     \n",
            "                                                                 lstm_2[3][0]                     \n",
            "                                                                 lstm_3[2][1]                     \n",
            "                                                                 lstm_3[2][2]                     \n",
            "                                                                 lstm_2[4][0]                     \n",
            "                                                                 lstm_3[3][1]                     \n",
            "                                                                 lstm_3[3][2]                     \n",
            "                                                                 lstm_2[5][0]                     \n",
            "                                                                 lstm_3[4][1]                     \n",
            "                                                                 lstm_3[4][2]                     \n",
            "                                                                 lstm_2[6][0]                     \n",
            "                                                                 lstm_3[5][1]                     \n",
            "                                                                 lstm_3[5][2]                     \n",
            "                                                                 lstm_2[7][0]                     \n",
            "                                                                 lstm_3[6][1]                     \n",
            "                                                                 lstm_3[6][2]                     \n",
            "                                                                 lstm_2[8][0]                     \n",
            "                                                                 lstm_3[7][1]                     \n",
            "                                                                 lstm_3[7][2]                     \n",
            "                                                                 lstm_2[9][0]                     \n",
            "                                                                 lstm_3[8][1]                     \n",
            "                                                                 lstm_3[8][2]                     \n",
            "                                                                 lstm_2[10][0]                    \n",
            "                                                                 lstm_3[9][1]                     \n",
            "                                                                 lstm_3[9][2]                     \n",
            "                                                                 lstm_2[11][0]                    \n",
            "                                                                 lstm_3[10][1]                    \n",
            "                                                                 lstm_3[10][2]                    \n",
            "                                                                 lstm_2[12][0]                    \n",
            "                                                                 lstm_3[11][1]                    \n",
            "                                                                 lstm_3[11][2]                    \n",
            "                                                                 lstm_2[13][0]                    \n",
            "                                                                 lstm_3[12][1]                    \n",
            "                                                                 lstm_3[12][2]                    \n",
            "                                                                 lstm_2[14][0]                    \n",
            "                                                                 lstm_3[13][1]                    \n",
            "                                                                 lstm_3[13][2]                    \n",
            "                                                                 lstm_2[15][0]                    \n",
            "                                                                 lstm_3[14][1]                    \n",
            "                                                                 lstm_3[14][2]                    \n",
            "                                                                 lstm_2[16][0]                    \n",
            "                                                                 lstm_3[15][1]                    \n",
            "                                                                 lstm_3[15][2]                    \n",
            "                                                                 lstm_2[17][0]                    \n",
            "                                                                 lstm_3[16][1]                    \n",
            "                                                                 lstm_3[16][2]                    \n",
            "                                                                 lstm_2[18][0]                    \n",
            "                                                                 lstm_3[17][1]                    \n",
            "                                                                 lstm_3[17][2]                    \n",
            "                                                                 lstm_2[19][0]                    \n",
            "                                                                 lstm_3[18][1]                    \n",
            "                                                                 lstm_3[18][2]                    \n",
            "                                                                 lstm_2[20][0]                    \n",
            "                                                                 lstm_3[19][1]                    \n",
            "                                                                 lstm_3[19][2]                    \n",
            "                                                                 lstm_2[21][0]                    \n",
            "                                                                 lstm_3[20][1]                    \n",
            "                                                                 lstm_3[20][2]                    \n",
            "                                                                 lstm_2[22][0]                    \n",
            "                                                                 lstm_3[21][1]                    \n",
            "                                                                 lstm_3[21][2]                    \n",
            "                                                                 lstm_2[23][0]                    \n",
            "                                                                 lstm_3[22][1]                    \n",
            "                                                                 lstm_3[22][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 30)     630         lstm_3[1][0]                     \n",
            "                                                                 lstm_3[2][0]                     \n",
            "                                                                 lstm_3[3][0]                     \n",
            "                                                                 lstm_3[4][0]                     \n",
            "                                                                 lstm_3[5][0]                     \n",
            "                                                                 lstm_3[6][0]                     \n",
            "                                                                 lstm_3[7][0]                     \n",
            "                                                                 lstm_3[8][0]                     \n",
            "                                                                 lstm_3[9][0]                     \n",
            "                                                                 lstm_3[10][0]                    \n",
            "                                                                 lstm_3[11][0]                    \n",
            "                                                                 lstm_3[12][0]                    \n",
            "                                                                 lstm_3[13][0]                    \n",
            "                                                                 lstm_3[14][0]                    \n",
            "                                                                 lstm_3[15][0]                    \n",
            "                                                                 lstm_3[16][0]                    \n",
            "                                                                 lstm_3[17][0]                    \n",
            "                                                                 lstm_3[18][0]                    \n",
            "                                                                 lstm_3[19][0]                    \n",
            "                                                                 lstm_3[20][0]                    \n",
            "                                                                 lstm_3[21][0]                    \n",
            "                                                                 lstm_3[22][0]                    \n",
            "                                                                 lstm_3[23][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax (TFOpLambda)     (None, None)         0           dense[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_1 (TFOpLambda)   (None, None)         0           dense[2][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_2 (TFOpLambda)   (None, None)         0           dense[3][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_3 (TFOpLambda)   (None, None)         0           dense[4][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_4 (TFOpLambda)   (None, None)         0           dense[5][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_5 (TFOpLambda)   (None, None)         0           dense[6][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_6 (TFOpLambda)   (None, None)         0           dense[7][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_7 (TFOpLambda)   (None, None)         0           dense[8][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_8 (TFOpLambda)   (None, None)         0           dense[9][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_9 (TFOpLambda)   (None, None)         0           dense[10][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_10 (TFOpLambda)  (None, None)         0           dense[11][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_11 (TFOpLambda)  (None, None)         0           dense[12][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_12 (TFOpLambda)  (None, None)         0           dense[13][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_13 (TFOpLambda)  (None, None)         0           dense[14][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_14 (TFOpLambda)  (None, None)         0           dense[15][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_15 (TFOpLambda)  (None, None)         0           dense[16][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_16 (TFOpLambda)  (None, None)         0           dense[17][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_17 (TFOpLambda)  (None, None)         0           dense[18][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_18 (TFOpLambda)  (None, None)         0           dense[19][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_19 (TFOpLambda)  (None, None)         0           dense[20][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_20 (TFOpLambda)  (None, None)         0           dense[21][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.argmax_21 (TFOpLambda)  (None, None)         0           dense[22][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, None, 30)     0           dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[19][0]                     \n",
            "                                                                 dense[20][0]                     \n",
            "                                                                 dense[21][0]                     \n",
            "                                                                 dense[22][0]                     \n",
            "                                                                 dense[23][0]                     \n",
            "==================================================================================================\n",
            "Total params: 15,790\n",
            "Trainable params: 15,790\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "1420/1420 [==============================] - 423s 201ms/step - loss: 0.9045 - acc: 0.1377 - val_loss: 0.5988 - val_acc: 0.1878\n",
            "Epoch 2/30\n",
            "1420/1420 [==============================] - 242s 170ms/step - loss: 0.5963 - acc: 0.1925 - val_loss: 0.5429 - val_acc: 0.2006\n",
            "Epoch 3/30\n",
            "1420/1420 [==============================] - 240s 169ms/step - loss: 0.5422 - acc: 0.2051 - val_loss: 0.5066 - val_acc: 0.2094\n",
            "Epoch 4/30\n",
            "1420/1420 [==============================] - 241s 170ms/step - loss: 0.5092 - acc: 0.2136 - val_loss: 0.4763 - val_acc: 0.2175\n",
            "Epoch 5/30\n",
            "1420/1420 [==============================] - 239s 168ms/step - loss: 0.4823 - acc: 0.2212 - val_loss: 0.4552 - val_acc: 0.2234\n",
            "Epoch 6/30\n",
            "1420/1420 [==============================] - 238s 168ms/step - loss: 0.4641 - acc: 0.2266 - val_loss: 0.4416 - val_acc: 0.2279\n",
            "Epoch 7/30\n",
            "1420/1420 [==============================] - 240s 169ms/step - loss: 0.4517 - acc: 0.2306 - val_loss: 0.4306 - val_acc: 0.2322\n",
            "Epoch 8/30\n",
            "1420/1420 [==============================] - 240s 169ms/step - loss: 0.4418 - acc: 0.2338 - val_loss: 0.4230 - val_acc: 0.2346\n",
            "Epoch 9/30\n",
            "1420/1420 [==============================] - 240s 169ms/step - loss: 0.4339 - acc: 0.2363 - val_loss: 0.4190 - val_acc: 0.2356\n",
            "Epoch 10/30\n",
            "1420/1420 [==============================] - 239s 168ms/step - loss: 0.4266 - acc: 0.2388 - val_loss: 0.4136 - val_acc: 0.2372\n",
            "Epoch 11/30\n",
            "1420/1420 [==============================] - 239s 169ms/step - loss: 0.4202 - acc: 0.2408 - val_loss: 0.4080 - val_acc: 0.2385\n",
            "Epoch 12/30\n",
            "1420/1420 [==============================] - 239s 168ms/step - loss: 0.4152 - acc: 0.2428 - val_loss: 0.4009 - val_acc: 0.2412\n",
            "Epoch 13/30\n",
            "1420/1420 [==============================] - 238s 168ms/step - loss: 0.4103 - acc: 0.2444 - val_loss: 0.3986 - val_acc: 0.2420\n",
            "Epoch 14/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.4058 - acc: 0.2461 - val_loss: 0.3995 - val_acc: 0.2416\n",
            "Epoch 15/30\n",
            "1420/1420 [==============================] - 238s 168ms/step - loss: 0.4020 - acc: 0.2476 - val_loss: 0.3973 - val_acc: 0.2423\n",
            "Epoch 16/30\n",
            "1420/1420 [==============================] - 238s 167ms/step - loss: 0.3980 - acc: 0.2489 - val_loss: 0.3922 - val_acc: 0.2441\n",
            "Epoch 17/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3947 - acc: 0.2495 - val_loss: 0.3876 - val_acc: 0.2455\n",
            "Epoch 18/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3909 - acc: 0.2509 - val_loss: 0.3807 - val_acc: 0.2480\n",
            "Epoch 19/30\n",
            "1420/1420 [==============================] - 238s 167ms/step - loss: 0.3871 - acc: 0.2522 - val_loss: 0.3767 - val_acc: 0.2497\n",
            "Epoch 20/30\n",
            "1420/1420 [==============================] - 238s 168ms/step - loss: 0.3841 - acc: 0.2532 - val_loss: 0.3751 - val_acc: 0.2504\n",
            "Epoch 21/30\n",
            "1420/1420 [==============================] - 238s 167ms/step - loss: 0.3805 - acc: 0.2540 - val_loss: 0.3730 - val_acc: 0.2513\n",
            "Epoch 22/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3774 - acc: 0.2548 - val_loss: 0.3735 - val_acc: 0.2505\n",
            "Epoch 23/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3747 - acc: 0.2557 - val_loss: 0.3711 - val_acc: 0.2514\n",
            "Epoch 24/30\n",
            "1420/1420 [==============================] - 238s 168ms/step - loss: 0.3718 - acc: 0.2568 - val_loss: 0.3661 - val_acc: 0.2532\n",
            "Epoch 25/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3687 - acc: 0.2579 - val_loss: 0.3628 - val_acc: 0.2543\n",
            "Epoch 26/30\n",
            "1420/1420 [==============================] - 236s 166ms/step - loss: 0.3665 - acc: 0.2586 - val_loss: 0.3593 - val_acc: 0.2558\n",
            "Epoch 27/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3640 - acc: 0.2594 - val_loss: 0.3562 - val_acc: 0.2565\n",
            "Epoch 28/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3614 - acc: 0.2602 - val_loss: 0.3549 - val_acc: 0.2568\n",
            "Epoch 29/30\n",
            "1420/1420 [==============================] - 237s 167ms/step - loss: 0.3591 - acc: 0.2612 - val_loss: 0.3534 - val_acc: 0.2573\n",
            "Epoch 30/30\n",
            "1420/1420 [==============================] - 236s 166ms/step - loss: 0.3571 - acc: 0.2619 - val_loss: 0.3531 - val_acc: 0.2575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YHfKL5_YTKk",
        "outputId": "f1615b5a-446a-49e7-ef0d-9d0b038a2000"
      },
      "source": [
        "!pip install editdistance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtqXB5sXLLYV",
        "outputId": "f0c9bad7-1772-4c58-a542-142ed618b7a8"
      },
      "source": [
        "test_gen = data_dict['test']['batch_greedy']\n",
        "test_samples = len(data_dict['test']['df'])\n",
        "batch_size=32\n",
        "acc = 0\n",
        "for _ in range(test_samples//batch_size) :\n",
        "  (a,b),c = next(test_gen)\n",
        "  l1 = data_dict['tokenizer'].decode(np.argmax(c,axis=2),mode='output')\n",
        "  out = rnn2.model.predict([a,b])\n",
        "  out = np.argmax(out,axis=2)\n",
        "  l2 = data_dict['tokenizer'].decode(out,mode='output')\n",
        "  acc += np.sum(np.array(l1)==np.array(l2))\n",
        "\n",
        "print(\"Val Accuracy : \",acc/test_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['andiranchi', 'ake', 'irangula', 'ndha', 'ulakhatee', 'alal', 'urvajanche', 'urunath', 'amjhunga', 'maging', 'tutya', 'stitvachi', 'nudit', 'addhtipeksha', 'aam', 'uloos', 'eneth', 'eevandan', 'ndreas', 'ugnata', 'alvon', 'stitvatil', 'anchyabaddal', 'otipeksha', 'umak', 'haktte', 'ubhati', 'hhavi', 'ang', 'azipur', 'illi', 'hodi']\n",
            "['andyyaachi', 'ake', 'irnngda', 'ndha', 'ulakatii', 'alalt', 'urvajaache', 'urunach', 'amaaaaagt', 'minangt', 'tutya', 'sttyaache', 'nduit', 'adhititaassh', 'amttt', 'ulustt', 'anich', 'ivanaaa', 'ndyiiist', 'uganta', 'alvoo', 'stttaaaii', 'anthaaaaaadd', 'otipissha', 'umak', 'hakttt', 'ubhate', 'hhali', 'ang', 'ajiprrt', 'hlll', 'hodit']\n",
            "['rut', 'eat', 'abin', 'icharakon', 'alavarun', 'rantamadhye', 'artha', 'arnayasathi', 'puri', 'hachakhach', 'arabola', 'ausa', 'ehsana', 'olanyatun', 'arlata', 'ardarala', 'uniti', 'arabai', 'emo', 'nti', 'agh', 'harge', 'yasanmuktee', 'anti', 'hambhar', 'haginee', 'anshil', 'uryadev', 'eeta', 'unaf', 'eg', 'iya']\n",
            "['ret', 'it', 'abin', 'icharaontt', 'alavroon', 'rantamadhye', 'artha', 'iranaaaahhi', 'puri', 'hachakahh', 'arimaaa', 'ausa', 'ihaaan', 'olnyruron', 'araaat', 'araaaana', 'uniti', 'arabait', 'emo', 'nti', 'agh', 'hanat', 'yaganpatti', 'anti', 'hambhar', 'haliii', 'anshil', 'urveda', 'etaa', 'unaptt', 'egt', 'iya']\n",
            "['est', 'ithehi', 'ounga', 'uebec', 'ayathyashi', 'urat', 'ktis', 'si', 'harts', 'vum', 'kshamya', 'akarmanacha', 'isheshadhikar', 'halanvadh', 'aiche', 'dyogpati', 'ast', 'oksabhet', 'umchya', 'lind', 'ranayachya', 'pyogasathi', 'apka', 'esident', 'amasyevar', 'ace', 'plabdh', 'imicry', 'hukamp', 'yapit', 'ayamch', 'evsthanchi']\n",
            "['est', 'ithhii', 'ounaa', 'hibsktt', 'ayathaachi', 'urat', 'tiisttt', 'si', 'hartst', 'vmmtt', 'kshana', 'akarmanacha', 'ishsshhhahaa', 'halnvndd', 'eiche', 'dyanaatt', 'ast', 'oksabsht', 'umchya', 'lind', 'rananachya', 'nhanaaaahhi', 'apaa', 'ebiiaaa', 'amaiaaaa', 'estttt', 'paabdh', 'imitti', 'hokpaptt', 'yapti', 'aimach', 'evasaaaachi']\n",
            "['arpancha', 'ranit', 'ihava', 'ells', 'ishayavarachi', 'ochar', 'anapur', 'rymaa', 'arabhav', 'nkon', 'akshidar', 'au', 'urtee', 'reece', 'aratha', 'pf', 'tsavala', 'anstheshi', 'aithni', 'hudai', 'aksal', 'zbek', 'oriya', 'arsanharon', 'xy', 'arafin', 'ani', 'aram', 'unega', 'ola', 'ahan', 'anshodhakanchya']\n",
            "['arpanch', 'ranit', 'ihava', 'alistt', 'ishavaaaachi', 'ochar', 'anppur', 'ryam', 'arabhaa', 'nkon', 'akshiaaa', 'aut', 'urti', 'reistt', 'aratha', 'pss', 'tkavala', 'ansthishi', 'athaanit', 'hudai', 'aksal', 'jesstt', 'oriya', 'arasaaaaon', 'ksit', 'aripuin', 'nnitt', 'armmt', 'uneaa', 'ola', 'ahan', 'anshaaaaaachha']\n",
            "['vaigyanic', 'akdi', 'liminator', 'klahoma', 'aulyavan', 'anmansavar', 'si', 'irjaghar', 'hugol', 'varupat', 'aranachya', 'ratapgadavaril', 'anglo', 'arpatri', 'asanyachya', 'adh', 'aori', 'albharav', 'arghe', 'urghatna', 'angate', 'efada', 'hip', 'rahlad', 'pagrahachi', 'evsthananchya', 'rema', 'aina', 'alala', 'aranara', 'ee', 'anyojak']\n",
            "['vaiinaani', 'akalit', 'lininirn', 'chaaaaktt', 'anlvvvan', 'anammaaaar', 's', 'irajahar', 'huogl', 'harppatt', 'arnnachya', 'ratapagaaadiri', 'angaln', 'arppttii', 'asnnyacha', 'adh', 'aorit', 'albhhaan', 'ardae', 'urkhaaaa', 'angate', 'issda', 'hipttt', 'rahaaad', 'paaaaachi', 'evasaaanncchya', 'rema', 'enaa', 'alala', 'aranaa', 'ett', 'anvamaktt']\n",
            "['arkon', 'alakanchya', 'irodh', 'ibhaganna', 'ciencemadhye', 'bhimat', 'evatanche', 'k', 'onvention', 'ankatamule', 'ohani', 'inta', 'irsan', 'okopayogi', 'akkyanni', 'earson', 'atiyon', 'arrackpore', 'ahagranth', 'hogte', 'hevanyas', 'ajuranvar', 'weccha', 'arji', 'ani', 'saka', 'ajaretun', 'antar', 'olka', 'ederal', 'oya', 'aitarana']\n",
            "['arkont', 'alaanchya', 'irodh', 'ibhananaa', 'aynmaaadhye', 'bhimat', 'evaaanche', 'iket', 'annaisaan', 'ankanaanl', 'ohanit', 'inta', 'irsan', 'oktamuun', 'aktaanni', 'iyaaaant', 'atiyont', 'arappur', 'ahanaaath', 'hogtt', 'havyanas', 'ajuraaaar', 'wechhha', 'arjitt', 'anit', 'smaa', 'ajrrtuon', 'antrr', 'olak', 'eiaaln', 'haa', 'ettaana']\n",
            "['aktabh', 'olicy', 'rushna', 'em', 'aranjiya', 'ulchadi', 'asi', 'aata', 'yakhya', 'odrej', 'ajkiy', 'pear', 'addhati', 'ethehi', 'hagane', 'eiparyant', 'jinkyapad', 'alali', 'ontahi', 'hamma', 'amtat', 'hai', 'ttar', 'nutsuk', 'akhdumpur', 'lonso', 'aden', 'ultan', 'enducha', 'lasson', 'onit', 'arawal']\n",
            "['akaaah', 'alisi', 'uckaaa', 'emttt', 'arnmjiy', 'ulchhddd', 'asittt', 'ata', 'yakhaa', 'ovaemt', 'asster', 'peyen', 'hadhati', 'athhhi', 'hagane', 'eipranaat', 'jiraiaaakt', 'alalit', 'ontahhi', 'hamma', 'amatt', 'hha', 'ttar', 'nutukkt', 'adhaamppur', 'lonkot', 'adentt', 'ultan', 'endecha', 'lakont', 'onit', 'araval']\n",
            "['aandanichi', 'anthon', 'uchity', 'ujale', 'ayathyapasun', 'rijesh', 'obinson', 'own', 'indadan', 'ratibhutiyan', 'rahanchi', 'hula', 'ajalyavar', 'm', 'pc', 'agich', 'cootaron', 'ussia', 'arshavte', 'andarbh', 'atehgarh', 'ashtun', 'unkeshvar', 'atn', 'hauguni', 'hallee', 'idhaaon', 'rayogancha', 'utlery', 'hasak', 'olanyasathi', 'ecreation']\n",
            "['andhanachi', 'anthont', 'uchitya', 'ujale', 'ayattaaaamo', 'rimesh', 'ubiinaatt', 'unet', 'indaaan', 'ratibhhitrnn', 'rahanchi', 'hula', 'ajlvvvaa', 'em', 'pss', 'agich', 'cuttoon', 'ashiya', 'arshaate', 'angaash', 'ithaaaad', 'ashrunt', 'unmsshhar', 'ata', 'honguni', 'halli', 'idyaant', 'ravaaaacha', 'atalii', 'hasaktt', 'ulannaashh', 'itiiiiiao']\n",
            "['ametati', 'umarchya', 'irdharit', 'ablet', 'weet', 'igaretton', 'hrant', 'ohimes', 'ml', 'enduche', 'ethale', 'ahkhana', 'irnayanantar', 'ikaneri', 'ele', 'rahala', 'ambandhanchi', 'hikshanachi', 'evgharat', 'yavahargat', 'aksaliyon', 'arna', 'ricketer', 'awamahal', 'hhura', 'ala', 'hogile', 'uesday', 'ruthvichya', 'ulae', 'eterche', 'alabgar']\n",
            "['amrttti', 'umanccha', 'irdharii', 'ableet', 'witt', 'ulrrtoon', 'hrant', 'eniisst', 'ee', 'endeche', 'ethale', 'ahhkaan', 'irannananar', 'ikannii', 'ele', 'rahala', 'amgaaaaachii', 'hikshanachi', 'evaharat', 'yavahanaaa', 'aksainonn', 'aran', 'ritktrr', 'avamaal', 'hhur', 'ala', 'holiye', 'inbdd', 'rithiichya', 'ulaee', 'itaache', 'adbaaar']\n",
            "['iketan', 'remi', 'eneva', 'ora', 'alakanchi', 'alameeveer', 'hararat', 'asavanchee', 'rupaprasadane', 'adnarya', 'ritani', 'akade', 'atishilata', 'onal', 'omposer', 'avalkar', 'amalakar', 'odo', 'ikherati', 'tan', 'elp', 'aryakartyanche', 'ipra', 'aloo', 'handpith', 'host', 'avpech', 'aksar', 'endut', 'eshil', 'ikhaai', 'ratinidhitv']\n",
            "['iktaan', 'remit', 'iniva', 'ora', 'alaaaaci', 'alamiirr', 'hararat', 'asanaachi', 'rupppaaaaaaln', 'adanraya', 'ritrnit', 'akade', 'atisiiaaa', 'hangl', 'opmaaar', 'avaaaar', 'amaaaar', 'odo', 'ikhratti', 'tanntt', 'elnptt', 'aryataraaachhe', 'ipaa', 'alut', 'handaitt', 'host', 'antasc', 'oksar', 'endutt', 'eshil', 'ikhai', 'ratiiiiiiiv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yd31nMSSdxh",
        "outputId": "0edb6eb3-e568-4f8a-8e4d-4b1ce0a76430"
      },
      "source": [
        "l1 = ['andiranchi', 'ake', 'irangula', 'ndha', 'ulakhatee', 'alal', 'urvajanche', 'urunath', 'amjhunga', 'maging', 'tutya', 'stitvachi', 'nudit', 'addhtipeksha', 'aam', 'uloos', 'eneth', 'eevandan', 'ndreas', 'ugnata', 'alvon', 'stitvatil', 'anchyabaddal', 'otipeksha', 'umak', 'haktte', 'ubhati', 'hhavi', 'ang', 'azipur', 'illi', 'hodi']\n",
        "l2 = ['andyyaachi', 'ake', 'irnngda', 'ndha', 'ulakatii', 'alalt', 'urvajaache', 'urunach', 'amaaaaagt', 'minangt', 'tutya', 'sttyaache', 'nduit', 'adhititaassh', 'amttt', 'ulustt', 'anich', 'ivanaaa', 'ndyiiist', 'uganta', 'alvoo', 'stttaaaii', 'anthaaaaaadd', 'otipissha', 'umak', 'hakttt', 'ubhate', 'hhali', 'ang', 'ajiprrt', 'hlll', 'hodit']\n",
        "np.sum(np.array(l1)==np.array(l2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OzbbHG-33UB"
      },
      "source": [
        "from keras.layers import Lambda\n",
        "from keras import backend as K\n",
        "num_encoder_tokens = data_dict['in_size']\n",
        "latent_dim = 256\n",
        "num_decoder_tokens = data_dict['out_size']\n",
        "batch_size=32\n",
        "epochs=20\n",
        "val_samples = 4981\n",
        "train_samples = 45444\n",
        "\n",
        "# The first part is unchanged\n",
        "encoder_inputs1 = Input(shape=(None,))\n",
        "encoder_inputs=Embedding(data_dict['in_size'], 64,mask_zero=True)(encoder_inputs1)\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, which will only process one timestep at a time.\n",
        "decoder_inputs1 = Input(shape=(1,))\n",
        "decoder_embedding =  Embedding(data_dict['out_size'], 64,mask_zero=True)\n",
        "decoder_inputs = decoder_embedding(decoder_inputs1)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "\n",
        "all_outputs = []\n",
        "inputs = decoder_inputs\n",
        "for _ in range(23):\n",
        "    # Run the decoder on one timestep\n",
        "    outputs, state_h, state_c = decoder_lstm(inputs,\n",
        "                                             initial_state=states)\n",
        "    outputs = decoder_dense(outputs)\n",
        "    # Store the current prediction (we will concatenate all predictions later)\n",
        "    all_outputs.append(outputs)\n",
        "    # Reinject the outputs as inputs for the next loop iteration\n",
        "    # as well as update the states\n",
        "    outputs1 = tf.math.argmax(outputs,2)\n",
        "    inputs = decoder_embedding(outputs1)\n",
        "    states = [state_h, state_c]\n",
        "\n",
        "# Concatenate all predictions\n",
        "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "\n",
        "# Define and compile model as previously\n",
        "model = Model([encoder_inputs1, decoder_inputs1], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Prepare decoder input data that just contains the start character\n",
        "# Note that we could have made it a constant hard-coded in the model\n",
        "\n",
        "# # Train model as previously\n",
        "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           validation_split=0.2)\n",
        "\n",
        "model.fit_generator(generator = data_dict['train']['batch_greedy'],\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = data_dict['val']['batch_greedy'],\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjtrtMiHDbiy",
        "outputId": "c8e2da9a-f081-4a65-891a-2216ac94853f"
      },
      "source": [
        "generator=data_dict['test']['batch_greedy']\n",
        "(a,b),c = next(generator)\n",
        "print(a,b,np.argmax(c,axis=2))\n",
        "out = model.predict([a,b])\n",
        "out = np.argmax(out,axis=2)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[26. 40. 12. 41. 20. 15.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [33. 13. 18. 30. 21.  6. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [35. 16. 26. 16. 26.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [11. 20. 10. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [28. 12. 49. 11.  9. 37. 21.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [35. 20.  6.  9. 37. 18. 10. 20. 15.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 7. 12. 13. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [37.  5. 17. 18. 13. 20.  5. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [37. 18. 45. 11. 15.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [41. 24. 15. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [37.  9. 28. 29. 10. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [11. 16. 41. 11. 24.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [35. 18. 13. 14. 20. 37. 15. 20. 31. 13.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [13. 20. 26. 18. 23. 20. 28. 38. 21. 11.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [29.  6. 18.  6. 11.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [28. 12. 11. 20.  5. 35. 39.  6. 21.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [35. 12. 10. 11. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 4. 13. 34. 20. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [10. 20. 35. 28. 20. 15. 20. 35. 16.  6. 18. 19. 20.  0.  0.  0.  0.]\n",
            " [49.  9. 49. 20. 27. 18. 23. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [34. 16. 14.  6. 20. 11.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [15. 20.  7. 20.  5. 27. 18. 23. 20.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [15. 41. 18. 26. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [26. 12. 58.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [27. 20. 13. 18. 11. 18. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [27. 24. 13. 24.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 7. 13. 18. 34. 21. 10. 25. 15.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [41. 37. 31. 20. 31. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [35. 11. 18. 28. 24. 15. 13. 21.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [28. 20. 37. 16. 28. 20. 13. 21. 27. 18. 23. 20.  0.  0.  0.  0.  0.]\n",
            " [27. 20.  5.  7. 11. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [28. 24. 22.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] [[20 10 17  4  4  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [16  4 14 22  8  6  4 14  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [25  4  7 13 15  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [12  4  4  9  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [21 10 27 12  8 15  8  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [25  4  6  8 15  9 16  4  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 7 10 14 13  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [15  4 21 17 16 14  4  5  9  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [15  6 16  4 12  4  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [17 19  5  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [15  8 21  4  9  9  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [12  4 17 13 12 19  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [25 14  4 15 16  4 15  4  5  4 23  4 14  2  0  0  0  0  0  0  0  0  0]\n",
            " [14  4 20 18  4 21  4 22 16  8 12  2  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 9  4  6  6  4 12  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [21 10 12  4  5 25  4  8  6  8  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [25 10  9 12  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 4 14 22  4 15  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 9  4 25  4 21  4  5  4 25 13  6 15 16  4  2  0  0  0  0  0  0  0  0]\n",
            " [27  8 27  4 11 16 18  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [22 13 15 16  6  4  4 12  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  4  7  4  5 11 16 18  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  4 17 20  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [20 10  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [11 16  4 14 12 15  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [11 16 19 14 19  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 7  4 14 22  8  9 10  5  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [17  4 15 23  4 23  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [25  4 12 21 19  5  4 14  8  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [21  4 15 13 21  4 14  8 11 16 18  4  2  0  0  0  0  0  0  0  0  0  0]\n",
            " [11 16  4  5  7  4 12  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [21 19  9 16  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[20 10 17  4  4  5  2  2  2  2  2  2  2  2  2  2  2  2 18 18 13 13 13]\n",
            " [16  4 14 22  8  6  4 14  2  2  2  2  2  2  2 12 22 12 22 23 18  4 22]\n",
            " [25  4 20 13 15  2  2  2  2  2  2  2  2  7 18 19 19 13 13 14 21 16 13]\n",
            " [12  4  9  4  2  2  2  2  2  2  2  2  2  2 12 10 14 18 13 13 22 22 22]\n",
            " [21 10 27 12  8 11  8  2  2  2  2  2  2  2  2  2 18 19 18 19 19 13 22]\n",
            " [25  4  6  8 15  9  4  5  2  2  2  2  2  2  2  2  2  2 18 18 18  4  2]\n",
            " [ 7 10 14 13  2  2  2  2  2  2  2  2  2 18 19 22 13 13 22 18  2  2  2]\n",
            " [15  4 21 17 16 14  4  5  9  2  2  2  2  2  2  2  2  2 18 18  4  4 18]\n",
            " [15  6 16  4 12  4  5  2  2  2  2  2  2  2  2  2  2  2 18 19 14 13 13]\n",
            " [17 19  5  4  2  2  2  2  2  2  2  2  2 18 18 19 22 13 13 28  8  2  2]\n",
            " [15  8 21  4  9  4  9  4  2  2  2  2  2  2  2  2  2  2  2 12 12 18 13]\n",
            " [12  4 17 12 12 19  5  2  2  2  2  2  2  2  2 27 27 18  4 18 18 13 20]\n",
            " [25 14  4 15 16  4  5  4 23  4 23  4 14  2  2  2  2  2  2  2  2  2 23]\n",
            " [14  4 20 18  4 21  4 22 16  8 12  2  2  2  2  2  2  2  2  2  2  2 18]\n",
            " [ 9  4  6  6  4 12  2  2  2  2  2  2  2  2  2  2 18 19 19 13 13 13 13]\n",
            " [21 10 12  4  5 25  4  8  6  8  2  2  2  2  2  2  2  2  2  2  2  2  2]\n",
            " [25 10  9  4 12  4  2  2  2  2  2  2  2  2  2  2  2  2 27 27 18 13 13]\n",
            " [ 4 14 22 22  4 15  2  2  2  2  2  2  2  2  2 27 18  4  4  4  2  2  2]\n",
            " [ 9  4 25 21  4  5  4 13 13 15 15 16  4  2  2  2  2  2  2  2  2  2  2]\n",
            " [27  8 27  4 11 16 18  4  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2]\n",
            " [22 13 15 16  6  4 12  2  2  2  2  2  2  2  2  2  2 18 18 13 22  2  2]\n",
            " [ 5  4  7  4  5 11 16 18  4  2  2  2  2  2  2  2  2  2  2  2  2  2  2]\n",
            " [ 5  4 17 17  4  2  2  2  2  2  2  2  2  2 18  4  2 21 13 13 28 12 13]\n",
            " [20 10 13 13  2  2  2  2  2  2  2  2  2  2 18  2 19 22 13 13 13 22 22]\n",
            " [11 16  4 14 12 13 15  2  2  2  2  2  2  2  2  2 22 18 19  4 24 14 24]\n",
            " [11 16 19 14 19  5  2  2  2  2  2  2  2  2  2 18 18 18 19 22  4  4 29]\n",
            " [ 7  4 22 22  8  9 10  5  2  2  2  2  2  2  2  2  2  2  2 18 18  4 18]\n",
            " [17  4 15 23 23  4  2  2  2  2  2  2  2  2  2  2  2  2 18 18 22 18 28]\n",
            " [25  4 12 21 19  5  4 14 18  2  2  2  2  2  2  2  2  2  2  2 19 28 12]\n",
            " [21  4 15 13 21  4  9 13 11 16 18  4  2  2  2  2  2  2  2  2  2  2  2]\n",
            " [11 16  4  5  7  4 12  4  2  2  2  2  2  2  2  2  2  2 18 22 22 13 13]\n",
            " [21 19  9 16 19  2  2  2  2  2  2  2  2  2  2  2 18 19 23  4 13 22 18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7o9Y_NBzelI"
      },
      "source": [
        "plot_model(model,to_file='model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viovwIYlks_f"
      },
      "source": [
        "encoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(data_dict['in_size'], 64,mask_zero=True)(encoder_inputs)\n",
        "x = LSTM(units=256,return_sequences=True)(x)\n",
        "x, *encoder_states = LSTM(units=256,\n",
        "                           return_state=True)(x)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "decoder_embedding =  Embedding(data_dict['out_size'], 64,mask_zero=True)\n",
        "x = decoder_embedding(decoder_inputs)\n",
        "\n",
        "decoder_LSTM = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "x, *decoder_states = decoder_LSTM(x, initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(units=data_dict['out_size'], activation='softmax')\n",
        "decoder_outputs = decoder_dense(x)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBE6qh5T-xCi"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2 = decoder_embedding(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs_2, *decoder_states_2 = decoder_LSTM(dec_emb2\n",
        "                                                    ,initial_state=decoder_state_input\n",
        "                                                    )\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs_2 = decoder_dense(decoder_outputs_2)\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_state_input,\n",
        "    [decoder_outputs_2] + decoder_states_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpIBCBmmxqa5"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of \n",
        "    #target sequence with the start character.\n",
        "    target_seq[0, 0] = 1\n",
        "# Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    chars = [1]\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "# Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 2 :\n",
        "          stop_condition = True\n",
        "        chars.append(sampled_token_index)\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "# Update states\n",
        "        states_value = [h, c]\n",
        "    return tk.decode([chars],'output')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWVDjxxrLhhH"
      },
      "source": [
        "plot_model(decoder_model,show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8wpmBFk-Bzd"
      },
      "source": [
        "test_gen = generate_batch(X_test, Y_test, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u014_k7MS48"
      },
      "source": [
        "x1 = tk.encode(['टोप्पर​'])\n",
        "x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtQr3YImNO7W"
      },
      "source": [
        "decode_sequence(x1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9nFZEzPQ3uL"
      },
      "source": [
        "lex['test'].input.tolist()[k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b5L3BteyEHT"
      },
      "source": [
        "k += 1\n",
        "(input_seq, actual_output), _ = next(test_gen)\n",
        "# print(input_seq)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input Source sentence:', tk.decode([X_test[k]])[0] )\n",
        "print('Actual Target Translation:', tk.decode([Y_test[k]],mode='output')[0])\n",
        "print('Predicted Target Translation:', decoded_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItqoHkE2JTO1"
      },
      "source": [
        "# Romanized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O8dFDOHGbEb"
      },
      "source": [
        "ta_rom = dict()\n",
        "ta_rom['rejoined'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv', sep='\\t', header=None, error_bad_lines=False)\n",
        "ta_rom['rejoined_aligned_cased'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.cased_nopunct.tsv', sep='\\t', header=None, error_bad_lines=False) \n",
        "ta_rom['rejoined_aligned'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.tsv', sep='\\t', header=None, error_bad_lines=False)\n",
        "ta_rom['split'] = pd.read_csv('/content/dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.tsv', sep='\\t', header=None, error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-WGvG_RJqsr"
      },
      "source": [
        "list(ta_rom['rejoined'].iloc[0, 0])[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p75rYpZkNCJV"
      },
      "source": [
        "ta_rom['rejoined_aligned_cased']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0E9hQuQMULO"
      },
      "source": [
        "ta_rom['rejoined_aligned']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yAnW0rAKDY5"
      },
      "source": [
        "ta_rom['split']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD7CedwSKaoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84677de7-0a8a-42b2-d53b-cce635ced12a"
      },
      "source": [
        "l1 = [1,4,2,3]\n",
        "l2 = [1,4,2,5]\n",
        "print(np.array(l1[1:-1])==np.array(l2[1:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}